<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Bigtable</title>
    <link href="/2024/05/11/Bigtable/"/>
    <url>/2024/05/11/Bigtable/</url>
    
    <content type="html"><![CDATA[<h1 id="Bigtable：结构化数据的分布式存储系统"><a href="#Bigtable：结构化数据的分布式存储系统" class="headerlink" title="Bigtable：结构化数据的分布式存储系统"></a><a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/bigtable-osdi06.pdf">Bigtable：结构化数据的分布式存储系统</a></h1><h2 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h2><p>Bigtable是一个用于管理结构化数据的分布式存储系统，旨在扩展到非常大的尺寸：数千台商用服务器上的PB级数据。Google 的许多项目都将数据存储在 Bigtable 中，包括网络索引、Google Earth 和 Google Finance。这些应用程序对 Bigtable 提出了截然不同的要求，无论是在数据大小（从 URL 到网页到卫星图像）还是延迟要求（从后端批量处理到实时数据服务）方面。尽管存在这些不同的需求，Bigtable 仍然成功地为所有这些 Google 产品提供了灵活的高性能解决方案。在本文中，我们描述了 Bigtable 提供的简单数据模型，该模型使客户端能够动态控制数据布局和格式，并描述了 Bigtable 的设计和实现。</p><h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a>1 介绍</h2><p>在过去的两年半中，我们设计、实现和部署了一个分布式存储系统，用于管理 Google 的结构化数据，称为 Bigtable。Bigtable 旨在可靠地扩展到 PB 级数据和数千台机器。Bigtable 实现了多个目标：广泛适用性、可扩展性、高性能和高可用性。Bigtable 被 60 多个 Google 产品和项目使用，包括 Google Analytics、Google Finance、Orkut、个性化搜索、Writely 和 Google Earth。这些产品将 Bigtable 用于各种要求苛刻的工作负载，从面向吞吐量的批处理作业到向最终用户提供对延迟敏感的数据。这些产品使用的 Bigtable 集群涵盖范围广泛的服务器，从少量到数千台服务器，并存储多达数百 TB 的数据。</p><p>在许多方面，Bigtable 类似于一个数据库：它与数据库共享许多实现策略。Parallel 数据库和主内存数据库已经实现了可扩展性和高性能，但 Bigtable 提供了与此类系统不同的接口。Bigtable不支持完整的关系数据模型；相反，它为客户端提供了一个简单的数据模型，支持对数据布局和格式的动态控制，并允许客户端推断底层存储中表示的数据的局部性属性。使用行名和列名（可以是任意字符串）对数据进行索引。Bigtable 还将数据视为未解释的字符串，尽管客户端经常将各种形式的结构化和半结构化数据序列化到这些字符串中。客户可以通过仔细选择其模式来控制数据的位置。最后，Bigtable模式参数允许客户端动态控制是从内存还是从磁盘提供数据。</p><p>第 2 节更详细地描述了数据模型，第 3 节提供了客户端 API 的概述。第4节简述了Bigtable所依赖的底层Google基础设施。第5节描述了Bigtable实现的基础知识，第6节描述了我们为提高Bigtable性能所做的一些改进。我们在第 7 节中描述了 Google 如何使用 Bigtable 的几个示例，并在第 8 节中讨论了我们在设计和支持 Bigtable 时学到的一些经验教训。最后，第9节描述了相关工作，第10节介绍了我们的结论。</p><h2 id="2-数据模型"><a href="#2-数据模型" class="headerlink" title="2 数据模型"></a>2 数据模型</h2><p>Bigtable是一个稀疏的、分布式的、持久的多维排序映射。该映射通过行键、列键和时间戳进行索引；映射中的每个值都是未解释的字节数组。</p><p><code>(row:string, column:string, time:int64) -&gt; string </code></p><p><img src="/../imgs/Bigtable/image-20240511210040299.png" alt="图 1：存储网页的示例表的切片。行名是反转的 URL。内容列族包含页面内容，锚点列族包含引用该页面的任何锚点的文本。CNN的主页被《体育画报》和MY-look主页引用，因此该行包含名为anchor:cnnsi.com和anchor：my.look.ca的列。每个锚单元格都有一个版本;内容列有三个版本，时间戳为 T3、T5 和 T6。"></p><p>在检查了类似 Bigtable 的系统的各种潜在用途后，我们决定采用这个数据模型。作为推动我们的一些设计决策的一个具体示例，假设我们向阳保留大量网页和相关信息的副本，供许多不同的项目使用；让我们将这个特定的表称为Webtable。在Webtable中，我们将使用URL作为行键，使用网页的各个方面作为列名称，并将网页内容存储在抓取时的时间戳下的contents：column中，如图1所示。</p><h3 id="行"><a href="#行" class="headerlink" title="行"></a>行</h3><p>在一个表中行键值是任意的字符串（目前最大大小为64kb，尽管10-100字节时我们大多数用户的典型大小）。在单个行键下读取或写入数据的每次都是原子的（无论行中读取或写入的不同列的数量如何），这种设计决策使客户端更容易在同一行存在并发更新的情况下推理系统的行为。</p><p>Bigtable按行键的字典顺序维护数据。一个表的行范围是动态分区的。每一个行范围称为一个tablet，它是分配和负载均衡的单位。因此，短行范围的读取是有效的，并且通常只需要与少量机器进行通信。客户端可以通过选择行键来利用此属性，以便获得良好的数据访问局部性。例如，在Webtable中，通过反转URL的主机名部分，同一域中的页面被分组为连续的行。例如，我们将maps.google.com&#x2F;index.html的数据存储在com.google.maps&#x2F;index.htm键下。将来自同一域的页面彼此靠近存储可以使某些主机和域分析更加有效。</p><h3 id="列族"><a href="#列族" class="headerlink" title="列族"></a>列族</h3><p>列键被分组为称为列族的集合，它们构成访问控制的基本单元。存储在了列族中的所有数据通常都是相同的类型（我们将同一列族中的数据压缩在一起）。必须先创建列族，然后才能将数据存储在该族中的任何一个列键下；创建族后，可以使用族内的任何列键。我们的目的是表中不同列族的数量很小（最多数百个），并且列族在操作过程中很少发生变化。相反，表可以具有无限数量的列。</p><p>列键使用以下语法命名：family：qualifier。列族名称必须是可打印的，但限定符可以是任意字符串。Webtable的一个示例列族是language，它存储编写网页所用的语言。我们只使用language族中的一个列键，它存储每个网页的语言ID。该表的另一个有用的列族是锚；该族中的每个列键代表一个锚点，如图1所示。限定符是引用站点的名称；单元格内容是链接文本。</p><p>访问控制以及磁盘和内存和酸都是在列族级别执行的。在我们Webtable示例中，这些控件使我们能够管理几种不同类型的应用程序：有些添加新的基础数据，有些读取基础数据并创建派生列族，有些只允许查看现有数据（处于隐私原因甚至可能不允许查看所有现有列族）。</p><h3 id="时间戳"><a href="#时间戳" class="headerlink" title="时间戳"></a>时间戳</h3><p>Bigtable中的每个单元格可以包含相同数据的多个版本；这些版本按时间戳索引。Bigtable时间戳是64位整数。它们可以由 Bigtable 签名，在这种情况下，它们以微秒为单位表示“实时”，也可以由客户端应用程序显式分配。需要避免冲突的应用程序必须自己生成唯一的时间戳。单元的不同版本按时间戳降序存储，以便可以首先读取最新版本。</p><p><strong><code>写入Bigtable</code></strong></p><figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs pf">// Open the <span class="hljs-built_in">table</span> <br>Table *T = OpenOrDie(<span class="hljs-string">&quot;/bigtable/web/webtable&quot;</span>); <br>// Write a new <span class="hljs-built_in">anchor</span> and delete an old <span class="hljs-built_in">anchor</span> <br>RowMutation r1(T, <span class="hljs-string">&quot;com.cnn.www&quot;</span>); <br>r1.Set(<span class="hljs-string">&quot;anchor:www.c-span.org&quot;</span>, <span class="hljs-string">&quot;CNN&quot;</span>); <br>r1.Delete(<span class="hljs-string">&quot;anchor:www.abc.com&quot;</span>); <br>Operation op; <br>Apply(&amp;op, &amp;r1); <br></code></pre></td></tr></table></figure><p>为了减轻版本数据的管理负担，我们支持两个每列族设置，告诉Bigtable自动垃圾收集单元版本。客户端可以指定仅保留单元的最后 n 个版本，或者仅保留足够新的版本（例如，仅保留最近 7 天内写入的值）。</p><p>在我们的 Webtable 示例中，我们将存储在 content：column中的已爬网页的时间戳设置为实际爬取这些页面版本的时间。上面描述的垃圾回收机制允许我们只保留每个页面的最新三个版本。</p><h2 id="3-API"><a href="#3-API" class="headerlink" title="3 API"></a>3 API</h2><p>Bigtable API 提供了创建和删除表和列族的功能。它还提供更改集群、表和列族元数据的功能，例如访问控制权限。</p><p>客户端应用程序可以在 Bigtable 中写入或删除值、从各个行查找值或迭代表中的数据子集。图 2 显示了使用 RowMutation 抽象来按形式进行一系列更新的 C++ 代码。（省略了不相关的细节，以保持示例简短。对 Apply 的调用对 Webtable 执行原子突变：它向 <a href="http://www.cnn.com/">www.cnn.com</a> 添加一个锚点并删除另一个锚点。</p><p>图 3 显示了使用 Scanner 抽象遍历特定行中所有定位点的 C++ 代码。客户端可以遍历多个列族，并且有多种机制可用于限制扫描生成的行、列和时间戳。例如，我们可以将上面的扫描限制为仅生成其列与正则表达式锚点匹配的锚点：*.cnn.com，或者仅生成时间戳落在当前时间十天内的锚点。</p><p>从Bigtable读取：</p><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs xl">Scanner scanner(T); <br><br>ScanStream *stream; <br><br>stream = scanner.FetchColumnFamily(<span class="hljs-string">&quot;anchor&quot;</span>); <br><br><span class="hljs-function"><span class="hljs-title">stream</span>-&gt;</span>SetReturnAllVersions(); <br><br>scanner.Lookup(<span class="hljs-string">&quot;com.cnn.www&quot;</span>); <br><br><span class="hljs-function"><span class="hljs-title">for</span> (; !stream-&gt;</span>D<span class="hljs-function"><span class="hljs-title">one</span>(); stream-&gt;</span>Next()) &#123; <br><br>printf(<span class="hljs-string">&quot;%s %s %lld %s\n&quot;</span>, <br><br>scanner.RowName(), <br><br><span class="hljs-function"><span class="hljs-title">stream</span>-&gt;</span>ColumnName(), <br><br><span class="hljs-function"><span class="hljs-title">stream</span>-&gt;</span>MicroTimestamp(), <br><br><span class="hljs-function"><span class="hljs-title">stream</span>-&gt;</span>Value()); <br><br>&#125;<br></code></pre></td></tr></table></figure><p>Bigtable 支持其他几个功能，允许用户以更复杂的方式操作数据。首先，Bigtable 支持单行事务，可用于对存储在单行键下的数据执行原子读取-修改-写入序列。Bigtable 目前不支持跨行键的一般事务，尽管它提供了一个用于在客户端跨行键批量写入的接口。其次，Bigtable 允许将单元格用作整数计数器。最后，Bigtable 支持在服务器的地址空间中执行客户端提供的脚本。这些脚本是用 Google 开发的一种名为 Sawzall 的数据处理语言编写的。目前，我们基于 Sawzall 的 API 不允许客户端脚本写回 Bigtable，但它允许各种形式的数据转换、基于任意表达式的过滤以及通过各种运算符进行汇总。</p><p>Bigtable 可以与 MapReduce 一起使用，MapReduce 是 Google 开发的运行大规模并行计算的框架。我们编写了一组包装器，允许将 Bigtable 用作 MapReduce 作业的输入源和输出目标。</p><h2 id="4-建筑模块"><a href="#4-建筑模块" class="headerlink" title="4 建筑模块"></a>4 建筑模块</h2><p>Bigtable是建立在Google基础架构的其他几个部分之上的。Bigtable使用分布式Google文件系统（GFS）来存储日志和数据文件。Bigtable集群通常在运行各种其他分布式应用程序的计算机共享池中运行，并且Bigtable进程通常与其他应用程序的进程共享同一台计算机。Bigtable依赖于集群管理系统来调度作业、管理共享机器上的资源、处理机器故障以及监视机器状态。</p><p>Google SSTable文件格式在内部使用来存储Bigtable数据。SSTable提供了从键到值的持久的、有序的不可变映射，其中键和值都是任意字节字符串。提供了一些操作来查找与指定键关联的值，并循环访问指定键范围内的所有键&#x2F;值对。在内部，每个SSTable包含一系列块（通常每个块的大小为64KB，但这是可配置的）。块索引（存储在SSTable的末尾）用于定位块；当SSTable打开时，索引被加载到内存中。可以通过单个磁盘查找来执行查找：我们首先通过在内存索引中执行二分搜索来找到适当的块，然后从磁盘中读取适当的块。或者，SSTable可以完全映射到内存中，这使我们能够在不接触磁盘的情况下执行查找和扫描。</p><p>Bigtable依赖于一个名为Chubby的高可用且持久的分布式锁服务。一个Chubby服务由5个活动副本组成，其中一个被选举为主副本并主动服务请求。当大多数副本正在运行并且可以相互通信时，该服务处于活动状态。Chubby使用Paxos算法在出现故障时保持其副本的一致性。Chubby提供了一个由目录和小文件组成的命名空间。每个目录或文件都可以用作锁，并且对文件的读取和写入是原子的。Chubby客户端库提供了Chubby文件的一致缓存。每个Chubby客户端都维护与Chubby服务的会话。如果客户端无法在租约到期时间内续订其会话租约，则客户端的会话将到期。当客户端的会话过期时，它会丢失所有锁和打开的句柄。Chubby客户端还可以在Chubby文件和目录上注册回调，以通知更改或会话过期。</p><p>Bigtable使用Chubby执行各种任务：确保在任何时候最多有一个活动主节点;存储 Bigtable 数据的引导位置（参见第 5.1 节）;发现tablet服务器并确定tablet服务器死亡（请参阅第 5.2 节）;存储 Bigtable 架构信息（每个 table 的列族信息）;并存储访问控制列表。如果 Chubby 在很长一段时间内不可用，则 Bigtable 将不可用。我们最近在跨越 11 个 Chubby 实例的 14 个 Bigtable 集群中检验了这种效果。由于 Chubby 不可用（由 Chubby 中断或网络问题引起）而导致存储在 Bigtable 中的某些数据不可用的 Bigtable 服务器时间的平均百分比为 0.0047%。受 Chubby 不可用性影响最大的单个集群的百分比为 0.0326%。</p><h2 id="5-实现"><a href="#5-实现" class="headerlink" title="5 实现"></a>5 实现</h2><p>Bigtable实现具有三个主要组件：链接到每个客户端的库、一台主服务器和许多tablet服务器。可以从集群中动态添加或删除tablet服务器，以适应工作负载的变化。</p><p>master负责将tablet分配给tablet服务器、检测tablet服务器的添加和过期、平衡tablet服务器负载以及GFS中文件的垃圾收集。此外，它还处理架构更改，例如表和列族的创建。</p><p>每个tablet服务器管理一组tablet（通常每个tablet服务器有十到一千个tablet）。tablet服务器处理对其已加载到table的读写请求，并且分割内存已经变得太大的tablet。</p><p>与许多单主机分布式存储系统一样，客户端数据不通过主机移动：客户端直接与tablet服务器通信以进行读取和写入。由于Bigtable客户端不依赖主服务器获取tablet位置信息，因此大多数客户端从不与主服务器通信。因此，master在实践中的负载很轻。</p><p>Bigtable集群存储许多表。每个表由一组tablet组成，每个tablet包含与行范围相关联的所有数据。最初，每个表仅包含一个tablet，随着表的增长，它会自动拆分为多个片，默认情况下每个片的大小约为100-200MB。</p><h3 id="5-1-Tablet位置"><a href="#5-1-Tablet位置" class="headerlink" title="5.1 Tablet位置"></a>5.1 Tablet位置</h3><p>我们使用类似于B+树的三级层次结构来存储tablet的位置信息（图4）。</p><p><img src="/../imgs/Bigtable/image-20240511210136031.png" alt="图4"></p><p>第一层是存储在Chubby中的文件，其中包含根数据块的位置。根tablet包含所有tablet在特殊METADATA表中的位置。每个元数据tablet都包含一组用户tablet的位置。根tablet只是METADATA表中的第一个tablet，但经过特殊处理——它永远不会被分割——以确保tablet位置层次结构不超过三个级别。METADATA 表将tablet的位置存储在行键下，该行键是tablet的表标识符及其结束行的编码。每个METADATA行在内存中存储大约1KB的数据。由于128MB元数据tablet的适度限制，我们的三级定位方案足以寻址2<sup>34</sup>个tablet（或者128MBtablet中的2<sup>61</sup>个字节)。</p><p>客户端库缓存tablet位置。如果客户端不知道tablet的位置，或者发现缓存的位置信息不正确，则它会递归地向上移动tablet位置层次结构。如果客户端的缓存为空，则定位算法需要3次网络往返，其中一次从Chubby读取。如果客户端的缓存已过时，则定位算法可能需要最多6次往返，因为过时的缓存条目仅在未命中时才会发现（假设METADATA tablet不经常移动）。尽管tablet位置存储在内存中，因此不需要 GFS 访问，但在常见情况下，我们通过让客户端库预取tablet位置来进一步降低此成本：每当它读取 METADATA 表时，它都会读取多个tablet的元数据。</p><p>我们还在元数据表中存储辅助信息，包括与每个tablet相关的所有事件的日志（例如服务器何时开始为其提供服务）。这些信息有助于调试和性能分析。</p><h3 id="5-2-tablet分配"><a href="#5-2-tablet分配" class="headerlink" title="5.2 tablet分配"></a>5.2 tablet分配</h3><p>每个tablet一次分配给一台tablet服务器。主服务器跟踪一组活动的tablet服务器，以及tbalet到tablet服务器的当前分配，包括哪些tablet未分配。当一个tablet未被分配，并且有足够空间容纳该tablet的tablet服务器可用时，master通过向tablet服务器发送一个tablet加载请求来分配该tablet。</p><p>Bigtable 使用 Chubby 来跟踪tablet服务器。当 Tablet 服务器启动时，它会在特定的 Chubby 目录中创建一个唯一命名的文件，并获取该文件的独占锁。主服务器监视此目录（服务器目录）以发现tablet服务器。如果 Tablet 服务器失去其独占锁，则它会停止为其 Tablet 提供服务：例如，由于网络分区导致服务器丢失其 Chubby 会话。（Chubby 提供了一种有效的机制，允许 Tablet 服务器检查它是否仍然持有锁定，而不会产生网络流量。）只要文件仍然存在，tablet 服务器就会尝试重新获取其文件上的独占锁。如果该文件不再存在，那么tablet服务器将永远无法再次提供服务，因此它会自毁进程。每当tablet服务器终止时（例如，因为集群管理系统正在从集群中删除tablet服务器的机器），它会尝试释放其锁，以便主服务器更快地重新分配其tablet。</p><p>主服务器负责检测tablet服务器何时不再为其tablet提供服务，并尽快重新分配这些tablet。为了检测某个tablet服务器何时不再为其tablet提供服务，master会定期向每个tablet服务器询问其锁的状态。如果一个tablet服务器报告它已经失去了锁，或者如果主服务器在最后几次尝试期间无法到达服务器，则主服务器会尝试获取服务器文件上的独占锁。如果master能够获取锁，那么Chubby是活的，而tablet服务器要么死了，要么无法到达Chubby，所以master通过删除他的服务器文件来确保tablet服务器永远不会再次提供服务。一旦服务器的文件被删除，master就可以将先前分配给该服务器的所有tablet移动到未分配的tablet组中。为了确保Bigtable集群不会受到master和Chubby之间网络问题的影响，如果Chubby会话过期，master就会自毁。然而，如上述所说，主节点故障不会改变tablet到tablet服务器的分配。</p><p>当集群管理系统启动master时，它需要先发现当前的tablet分配，然后才能更改它们。master在启动时执行以下步骤。</p><ol><li>主节点在Chubby中获取唯一的主锁，这可以防止并发主节点实例化。</li><li>主服务器扫描Chubby中的服务器目录以查找活动服务器。</li><li>主服务器与每个活动的tablet服务器进行通信，以发现哪些tablet已分配给每个服务器。</li><li>主服务器扫描元数据表以了解tablet组。</li></ol><p>每当此扫描遇到尚未分配的tablet时，主设备都会将该tablet添加到未分配的tablet集合中，这使得该tablet有资格进行tablet分配。</p><p>一个复杂的情况是，在分配METADATA片之前无法扫描METADATA表。因此，在开始扫描（步骤4）之前，如果在步骤3期间未发现根tablet的分配，则主设备会将根tablet添加到未分配的tablet集合中。此添加可确保分配根tablet。因为根tablet包含所有METADATA tablet的名称，所以master在扫描根tablet后就知道所有这些信息。</p><p>仅当创建或删除表、合并两个现有tablet以形成一个较大的tablet或将现有tablet拆分为两个较小的tablet时，现有tablet集才会发生变化。主设备能够跟踪这些更改，因为它启动了除最后一个之外的所有更改。tablet拆分会被特殊处理，因为它们是由tablet服务器发起的。tabelt服务器通过在METADATA表中记录新tablet的信息来提交拆分。当拆分提交后，它会通知master。为了防止拆分通知丢失（因为tablet服务器或主节点宕机），当master请求tablet服务器加载现在已经分裂的tablet时，它会检测到新的tablet。tablet服务器将通知master拆分的信息，因为它在元数据表中找到的tablet条目将仅指定master要求其加载的tablet的一部分。</p><h3 id="5-3-tablet服务"><a href="#5-3-tablet服务" class="headerlink" title="5.3 tablet服务"></a>5.3 tablet服务</h3><p>tablet的持久状态存储在GFS中，如图5所示。更新被提交到存储重做记录的提交日志中。在这些更新中，最近提交的更新存储在内存中一个称为memtable的排序缓冲区中；较旧的更新存储在一系列SSTable中。为了恢复tablet，tablet服务器从 METADATA 表中读取其元数据。</p><p><img src="/../imgs/Bigtable/image-20240511210159571.png" alt="图5"></p><p>该元数据包含SSTable列表，该列表包含一个tablet和一组重做点，这些重做点是指向可能包含tablet数据的任何提交日志的指针。服务器将SSTable的索引读取到内存中，并通过应用自重做点以来已提交的所有更新来重建内存表。</p><p>当写操作到达tablet服务器时，服务器会检查它的格式是否正确，以及发送者是否有权执行突变。授权是通过从Chubby文件（几乎总是在Chubby客户端缓存中命中）读取允许的写入者列表来执行的。有效的变更将写入提交日志。组提交用于提高大量小突变的吞吐量。提交写入后，其内容将插入到内存表中。</p><p>当读取操作到达tablet服务器时，同样会检查其格式正确性和正确的授权。在SSTable序列和内存表的合并视图上执行有效的读取操作。由于SSTable和memtable时按字典序排序的数据结构，因此可以有效地形成合并视图。</p><p>当tablet被拆分和合并时，传入的读取和写入操作可以继续。</p><h3 id="5-4-压缩"><a href="#5-4-压缩" class="headerlink" title="5.4 压缩"></a>5.4 压缩</h3><p>随着写操作的执行，内存表的大小会增加。当memtable大小达到阈值时，memtable被冻结，创建新的memtable，并将冻结的memtable转换为SSTable并写入GFS。这个次要压缩过程有两个目标：它减少了tablet服务器的内存使用量，并且减少了如果该服务器挂掉时在恢复期间必须从提交日志中读取的数据量。当压缩发生时，传入的读和写操作可以继续。</p><p>每次较小的压缩都会创建一个新的 SSTable。如果这种行为继续不加控制，读取操作可能需要合并来自任意数量的 SSTable 的更新。相反，我们通过在后台定期执行合并压缩来限制此类文件的数量。合并压缩读取几个SSTable和memtable的内容，并写出一个新的SSTable。压缩完成后，输入的SSTable和memtable就可以被丢弃。</p><p>将所有SSTable重写为一个SSTable的合并压缩称为主要压缩。非主要压缩生成的SSTable可以包含特殊的删除条目，这些条目会抑制仍然存在的旧SSTable中已删除的数据。另一方面，主要压缩会生成不包含删除信息或已删除数据的SSTable。Bigtable循环遍历其所有tablet，并定期对它们应用主要压缩。这些主要压缩使Bigtable能够回收已删除数据所使用的资源，并确保已删除数据及时从系统中消失，这对于存储敏感数据的服务非常重要。</p><h2 id="6-改进"><a href="#6-改进" class="headerlink" title="6 改进"></a>6 改进</h2><p>上一节中描述的实现需要进行大量改进才能实现用户所需的高性能、可用性和可靠性。本节更详细地描述了部分实现，以突出这些改进。</p><h3 id="位置组"><a href="#位置组" class="headerlink" title="位置组"></a>位置组</h3><p>客户端可以将多个列族组合到一个位置组中。为每个tablet中的每个位置组生成一个单独的SSTable。将通常不一起访问的列族分离到单独的位置组中可以实现更高效的读取。例如，Webtable中的页面元数据（例如语言和校验和）可以位于一个位置组中，而页面的内容可以位于不同的组中：想要读取元数据的应用程序不需要读取所有页面内容。</p><p>此外，还可以在每个位置组的基础上指定一些有用的优化参数。例如，可以将位置组声明为内存中。内存中位置组的 SSTable 将延迟加载到 Tablet 服务器的内存中。加载后，可以在不访问磁盘的情况下读取属于此类位置组的列名称。此功能对于经常访问的小块数据非常有用：我们在内部将其用于 METADATA 表中的位置列系列。</p><h3 id="压缩"><a href="#压缩" class="headerlink" title="压缩"></a>压缩</h3><p>客户端可以控制是否压缩位置组的 SSTable，如果是，则使用哪种压缩格式。用户指定的压缩格式应用于每个 SSTable 块（其大小可通过局部组特定调整参数进行控制）。虽然我们通过单独压缩每个块而损失了一些空间，但我们受益于可以读取 SSTable 的一小部分，而无需解压缩整个文件。许多客户端使用两遍自定义压缩方案。第一遍使用 Bentley 和 McIlroy 的方案，该方案在一个大窗口中压缩长的公共字符串。第二遍使用快速压缩算法，在数据的 16 KB 小窗口中查找重复项。两种压缩过程都非常快，在现代机器上，它们的编码速度为 100-200 MB&#x2F;s，解码速度为 400-1000 MB&#x2F;s。</p><p>尽管我们在选择压缩算法时强调速度而不是空间减少，但这种两遍压缩方案的表现却出奇的好。例如，在Webtable中，我们使用这种压缩方案来存储网页内容。在一项实验中，我们将大量文档存储在压缩的位置组中。出于实验目的，我们将自己限制为每个文档的一个版本，而不是存储我们可用的所有版本。该方案实现了10比1的空间缩减。由于 Webtable 行的布局方式，这比 HTML 页面上典型的 Gzip 压缩（3 比 1 或 4 比 1）要好得多：来自单个主机的所有页面都彼此靠近存储。这允许 Bentley-McIlroy 算法识别来自同一主机的页面中的大量共享样板。许多应用程序（不仅仅是 Webtable）选择它们的行名，以便类似的数据最终聚集起来，从而实现非常好的压缩比。当我们在Bigtable中存储相同值的多个版本时，压缩率会变得更好。</p><h3 id="缓存以提高读取性能"><a href="#缓存以提高读取性能" class="headerlink" title="缓存以提高读取性能"></a>缓存以提高读取性能</h3><p>为了提高读取性能，tablet服务器使用两个级别的缓存。扫描缓存是一种更高级别的缓存，用于缓存 SSTable 接口返回的键值对到tablet服务器代码。块缓存是一种较低级别的缓存，用于缓存从 GFS 读取的 SSTables 块。扫描缓存对于倾向于重复读取相同数据的应用程序最有用。块缓存对于倾向于读取接近其最近读取的数据（例如，顺序读取或对热行中同一位置组中的不同列的随机读取）的应用程序非常有用。</p><h3 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h3><p>如第 5.3 节所述，读取操作必须从构成tablet状态的所有 SSTable 中读取。如果这些 SSTable 不在内存中，我们最终可能会进行许多磁盘访问。我们通过允许客户端指定应为特定位置组中的 SSTables 创建 Bloom 过滤器来减少访问次数。Bloom lter 允许我们询问 SSTable 是否可能包含指定行&#x2F;列对的任何数据。对于某些应用程序，用于存储 Bloom 过滤器的少量tablet服务器内存可大大减少读取操作所需的磁盘寻道次数。我们使用 Bloom 过滤器还意味着大多数对不存在的行或列的查找不需要接触磁盘。</p><h3 id="提交日志实现"><a href="#提交日志实现" class="headerlink" title="提交日志实现"></a>提交日志实现</h3><p>如果我们将每个 tablet 的提交日志保存在一个单独的日志文件中，那么 GFS 中将同时写入大量文件。根据每个 GFS 服务器上的底层文件系统实现，这些写入可能会导致大量磁盘寻求写入不同的物理日志。此外，每个tablet都有单独的日志 les 也会降低组提交优化的有效性，因为组往往会更小。为了解决这些问题，我们将突变附加到每个tablet服务器的单个提交日志中，将不同tablet的突变混合在同一物理日志中。</p><p>在正常操作期间使用一个日志可以提供显著的性能优势，但它会使恢复变得复杂。当一个tablet服务器挂掉时，它所服务的tablet将被转移到大量其他tablet服务器上：每个服务器通常加载少量原始服务器的tablet。为了恢复tablet的状态，新的tablet服务器需要从原始tablet服务器写入的提交日志中重新应用该tablet的突变。然而，这些tablet的突变混合在同一个物理日志文件中。一种方法是让每个新的tablet服务器读取此完整的提交日志，并仅应用它需要恢复的tablet所需的条目。但是，在这种方案下，如果 100 台计算机从发生故障的tablet服务器中为每台计算机分配一台tablet，则日志文件将被读取 100 次（每台服务器读取一次）。</p><p>我们通过首先按键&lt;表，行名，日志序列号&gt;的顺序对提交日志条目进行排序来避免重复读取日志。在排序的输出中，特定tablet的所有突变都是连续的，因此可以通过一次磁盘查找和顺序读取来有效地读取。为了并行排序，我们将日志文件划分为64MB的段，并在不同的Tablet服务器上并行对每个段进行排序。此排序过程由主服务器协调，并在Tablet服务器指示它需要从某些提交日志文件中恢复突变时启动。</p><p>将提交日志写入 GFS 有时会导致性能中断，原因有多种（例如，写入崩溃时涉及的 GFS 服务器计算机，或者为到达特定的三台 GFS 服务器而遍历的网络路径遭受网络拥塞，或者负载过重）。为了保护突变免受 GFS 延迟峰值的影响，每个 Tablet 服务器实际上有两个日志写入线程，每个线程写入自己的日志文件；一次只有这两个线程之一处于活动状态。如果对活动日志文件的写入性能不佳，则日志文件写入将切换到另一个线程，并且提交日志队列中的突变将由新的活动日志写入线程写入。日志条目包含序列号，以允许恢复过程消除由该日志切换过程产生的重复条目。</p><h3 id="加速tablet恢复"><a href="#加速tablet恢复" class="headerlink" title="加速tablet恢复"></a>加速tablet恢复</h3><p>如果主服务器将一个tablet从一个tablet服务器移动到另一个tablet服务器，则源tablet服务器首先对该tablet进行次要压缩。这种压缩通过减少tablet服务器提交日志中未压缩状态的数量来减少恢复时间。关闭此操作后，tablet服务器将停止为tablet提供服务。在实际卸载tablet之前，tablet服务器会执行其他（通常非常快）的次要压缩，以消除在执行第一次小型压缩时到达的tablet服务器日志中任何剩余的未压缩状态。在第二次较小的压缩完成后，该tablet可以加载到另一个tablet服务器上，而不需要恢复任何日志条目。</p><h3 id="利用不变性"><a href="#利用不变性" class="headerlink" title="利用不变性"></a>利用不变性</h3><p>除了SSTable缓存之外，我们生成的所有SSTable都是不可变的，这一事实也简化了Bigtbale系统的各个其他部分。例如，从 SSTable 读取时，我们不需要对文件系统的访问进行任何同步。因此，可以非常有效地实现行的并发控制。唯一可通过读取和写入访问的可变数据结构是内存表。为了减少读取内存表期间的争用，我们使每个内存表行进行写时复制，并允许读取和写入并行进行。</p><p>由于 SSTable 是不可变的，永久删除已删除数据的问题就转化为垃圾收集过时的 SSTable。每个tablet的SSTables都注册在METADATA表中。主节点删除过时的 SSTable，作为 SSTable 集合上的标记和清除垃圾收集，其中 METADATA 表包含根集合。</p><p>最后，SSTables 的不变性使我们能够快速拆分平板电脑。我们让子tablet 共享父tablet 的SSTable，而不是为每个子tablet 生成一组新的SSTable。</p><h2 id="7-经验教训"><a href="#7-经验教训" class="headerlink" title="7 经验教训"></a>7 经验教训</h2><p>在设计、实现、维护和支持Bigtable的过程中，我们获得了有用的经验，并学到了一些有趣的教训。</p><p>我们学到的一个教训是，大型分布式系统容易遭受多种类型的故障，而不仅仅是许多分布式协议中所设想的标准网络分区和故障停止故障。例如，我们已经见到由于下列原因造成的问题：内存和网络损坏，大时钟偏差，挂机，扩展和对称网络分区，使用其他系统中的错误（比如Chubby），GFS配额溢出，以及计划内和计划外的硬件维护。随着我们在解决这些问题方面获得了更多经验，我们通过更改各种协议来解决这些问题。例如，我们向我们的RPC机制添加了校验和。我们还通过删除系统的一部分对另一部分所做的假设来处理一些问题。例如，我们不再假设给定的 Chubby 操作只能返回一组固定错误中的一个。</p><p>我们学到的另一个教训是，在明确如何使用新功能之前，推迟添加新功能非常重要。例如，我们最初计划在 API 中支持通用交易。因为我们没有立即使用它们，无论如何，我们没有实施它们。现在，我们在 Bigtable 上运行了许多实际应用程序，我们已经能够检查它们的实际需求，并且已经发现大多数应用程序只需要单行反转操作。当人们要求分布式交易时，最重要的用途是维护二级索引，我们计划添加专门的机制来满足这一需求。新机制将不如分布式事务那么通用，但会更高效（特别是对于跨越数百行或更多行的更新），并且还将与我们的乐观跨数据中心复制方案更好地交互。</p><p>我们从支持 Bigtable 中学到的一个实际教训是适当的系统级监控的重要性（即监控 Bigtable 本身以及使用 Bigtable 的客户端进程）。例如，我们扩展了 RPC 系统，以便对于 RPC 样本，它可以保留代表该 RPC 执行的重要操作的详细跟踪。此功能使我们能够检测和解决许多问题，例如 Tablet 数据结构上的锁争用、提交 Bigtable 突变时向 GFS 写入缓慢，以及当 METADATA Tablet 不可用时对 METADATA 表的访问卡住。另一个有用的监控示例是，每个 Bigtable 集群都在 Chubby 中注册。这使我们能够跟踪所有集群，发现它们有多大，查看它们正在运行的软件版本，它们接收了多少传输，以及是否存在任何问题，例如意外的大延迟。</p><p>我们学到的最重要的一课是简单设计的价值。考虑到我们系统的规模（大约 100,000 行非测试代码），以及代码随着时间的推移以意想不到的方式演变的事实，我们发现代码和设计的清晰度对代码维护和调试有很大帮助。其中一项检查是我们的平板电脑-服务器会员协议。我们的第一个协议很简单：主服务器定期向平板电脑服务器发出租约，如果他们的租约到期，平板电脑服务器就会杀死他们自己。不幸的是，在存在网络问题的情况下，这种原型会显著降低可用性，并且对主重新存储时间也很敏感。我们多次重新设计协议，直到我们有一个表现良好的协议。然而，最终的协议过于复杂，并且依赖于其他应用程序很少使用的 Chubby 功能的行为。我们发现我们花费了大量的时间来调试模糊的极端情况，不仅在 Bigtable 代码中，而且在 Chubby 代码中也是如此。最终，我们放弃了这个协议，转而采用一个更新的、更简单的协议，该协议仅依赖于广泛使用的 Chubby 功能。</p><h2 id="8-相关工作"><a href="#8-相关工作" class="headerlink" title="8 相关工作"></a>8 相关工作</h2><p>Boxwood 项目的组件在某些方面与 Chubby、GFS 和 Bigtable 重叠，因为它提供了分布式协议、锁定、分布式块存储和分布式 B 树存储。在每种有重叠的情况下，Box-wood 的组件似乎都比相应的 Google 服务低一些。Boxwood 项目的目标是为构建更高级别的服务（如文件系统或数据库）提供基础设施，而 Bigtable 的目标是直接支持希望存储数据的客户端应用程序。</p><p>最近的许多项目都解决了在广域网上提供分布式存储或更高级别的服务的问题，通常是在“互联网”规模上。这些系统解决了 Bigtable 不会出现的问题，例如高度可变的带宽、不受信任的参与者或频繁的重新协调;去中心化控制和拜占庭式容错不是 Bigtable 的目标。</p><p>就可能提供给应用程序开发人员的分布式数据存储模型而言，我们认为分布式 B 树或分布式哈希表提供的键值对模型过于局限。键值对是一个有用的构建块，但它们不应该是提供给开发人员的唯一构建块。我们选择的模型比简单的键值对更丰富，并且支持稀疏的半结构化数据。尽管如此，它仍然足够简单，以至于它适合于非常有效的平面文件表示，并且它足够透明（通过位置组），允许我们的用户调整系统的重要行为。</p><p>一些数据库供应商已经开发了可以存储大量数据的并行数据库。Oracle 的 Real Application Cluster 数据库 [27] 使用共享磁盘来存储数据（Bigtable 使用 GFS）和分布式锁管理器（Bigtable 使用 Chubby）。IBM 的 DB2 Parallel Edition [4] 基于类似于 Bigtable 的无共享 [33] 架构。每个 DB2 服务器负责表中行的子集，该行存储在本地关系数据库中。这两种产品都提供了一个完整的事务关系模型。</p><p>对于使用基于列而不是基于行的存储在磁盘上组织数据的其他系统，包括 C-Store [1， 34] 和商业产品，如 Sybase IQ [15， 36]、SenSage [31]、KDB+ [22] 和 MonetDB&#x2F;X100 中的 ColumnBM 存储层 [38]，Bigtable 局部组实现了类似的压缩和磁盘读取性能。另一个将垂直和水平数据划分为atles并实现良好数据压缩比的系统是AT&amp;T的Day-tona数据库[19]。局部组不支持 CPU 缓存级别的优化，例如 Ailamaki [2] 所描述的优化。</p><p>Bigtable 使用 memtables 和 SSTables 来存储平板电脑更新的方式类似于日志结构化合并树 [26] 存储更新以索引数据的方式。在这两种系统中，排序后的数据在写入磁盘之前都会在内存中缓冲，并且读取必须合并内存和磁盘中的数据。</p><p>C-Store 和 Bigtable 有许多共同的特点：这两个系统都使用无共享架构，并具有两种不同的数据结构，一种用于存储最近的写入，另一种用于存储长期数据，并具有将数据从一种形式移动到另一种形式的机制。这些系统在其 API 中存在显着差异：C-Store 的行为类似于关系数据库，而 Bigtable 提供较低级别的读写接口，旨在支持每台服务器每秒数千次此类操作。C-Store 也是一个“读取优化的关系 DBMS”，而 Bigtable 在读取密集型和写入密集型应用程序上都提供了良好的性能。</p><p>Bigtable 的负载均衡器必须解决一些与无共享数据库相同的负载和内存平衡问题（例如，[11， 35]）。我们的问题稍微简单一些：（1）我们没有考虑同一数据的多个副本的可能性，由于视图或索引，可能以不同的形式出现;（2）我们让用户告诉我们哪些数据属于内存，哪些数据应该保留在磁盘上，而不是试图动态地确定这一点;（3）我们没有复杂的查询来执行或优化。</p><h2 id="9-总结"><a href="#9-总结" class="headerlink" title="9 总结"></a>9 总结</h2><p>我们已经描述了 Bigtable，这是一个用于在 Google 存储结构化数据的分布式系统。Bigtable 集群自 2005 年 4 月以来一直在生产中使用，在此之前，我们花了大约 7 个人年的时间进行设计和实施。截至 2006 年 8 月，已有 60 多个项目在使用 Bigtable。我们的用户喜欢 Bigtable 组件提供的性能和高可用性，并且随着资源需求的变化，他们只需向系统添加更多计算机即可扩展集群的容量。</p><p>鉴于 Bigtable 的不寻常界面，一个有趣的问题是我们的用户适应使用它的难度有多大。新用户有时不确定如何最好地使用 Bigtable 界面，特别是如果他们习惯于使用支持通用事务的关系数据库。尽管如此，许多 Google 产品成功使用 Bigtable 的事实表明，我们的设计在实践中运行良好。</p><p>我们正在实现一些附加的 Bigtable 功能，例如支持二级索引和基础设施，用于构建具有多个主副本的跨数据中心复制的 Bigtable。我们还开始将 Bigtable 作为服务部署到 产品组，这样各个组就不需要维护自己的集群。随着服务集群的扩展，我们将需要在 Bigtable 内部处理更多的资源共享问题 [3， 5]。</p><p>最后，我们发现在 Google 构建我们自己的存储解决方案具有重要的优势。我们从为 Bigtable 设计自己的数据模型中获得了大量的灵活性。此外，我们对 Bigtable 的实施以及 Bigtable 所依赖的其他 Google 基础设施的控制意味着我们可以在出现瓶颈和缺陷时消除它们。</p><h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><p>[1] ABADI, D. J., MADDEN, S. R., AND FERREIRA, </p><p>M. C. Integrating compression and execution in column-</p><p>oriented database systems. Proc. of SIGMOD (2006). </p><p>[2] AILAMAKI, A., DEWITT, D. J., HILL, M. D., AND SK-</p><p>OUNAKIS, M. Weaving relations for cache performance. </p><p>In The VLDB Journal (2001), pp. 169ñ180. </p><p>[3] BANGA, G., DRUSCHEL, P., AND MOGUL, J. C. Re-</p><p>source containers: A new facility for resource manage-</p><p>ment in server systems. In Proc. of the 3rd OSDI (Feb. </p><p>1999), pp. 45ñ58. </p><p>[4] BARU, C. K., FECTEAU, G., GOYAL, A., HSIAO, </p><p>H., JHINGRAN, A., PADMANABHAN, S., COPELAND, </p><p>G. P., AND WILSON, W. G. DB2 parallel edition. IBM </p><p>Systems Journal 34, 2 (1995), 292ñ322. </p><p>[5] BAVIER, A., BOWMAN, M., CHUN, B., CULLER, D., </p><p>KARLIN, S., PETERSON, L., ROSCOE, T., SPALINK, T., </p><p>AND WAWRZONIAK, M. Operating system support for </p><p>planetary-scalenetworkservices. InProc.of the1stNSDI </p><p>(Mar. 2004), pp. 253ñ266. </p><p>[6] BENTLEY, J. L., AND MCILROY, M. D. Data compres-</p><p>sion using long common strings. In Data Compression </p><p>Conference (1999), pp. 287ñ295. </p><p>[7] BLOOM, B. H. Space&#x2F;timetrade-offs inhashcodingwith </p><p>allowable errors. CACM 13, 7 (1970), 422ñ426. </p><p>[8] BURROWS, M. The Chubby lock service for loosely-</p><p>coupled distributed systems. In Proc. of the 7th OSDI </p><p>(Nov. 2006). </p><p>[9] CHANDRA, T., GRIESEMER, R., AND REDSTONE, J. </p><p>Paxos made live ó An engineering perspective. In Proc. </p><p>of PODC (2007). </p><p>[10] COMER, D. Ubiquitous B-tree. Computing Surveys 11, 2 </p><p>(June 1979), 121ñ137. </p><p>[11] COPELAND, G. P., ALEXANDER, W., BOUGHTER, </p><p>E. E., AND KELLER, T. W. Dataplacement in Bubba. In </p><p>Proc. of SIGMOD (1988), pp. 99ñ108. </p><p>[12] DEAN, J., AND GHEMAWAT, S. MapReduce: Simplied </p><p>dataprocessingonlargeclusters. InProc.of the6thOSDI </p><p>(Dec. 2004), pp. 137ñ150. </p><p>[13] DEWITT, D., KATZ, R., OLKEN, F., SHAPIRO, L., </p><p>STONEBRAKER, M., AND WOOD, D. Implementation </p><p>techniques for main memory database systems. In Proc. </p><p>of SIGMOD (June 1984), pp. 1ñ8. </p><p>[14] DEWITT, D. J., AND GRAY, J. Parallel database sys-</p><p>tems: The future of high performance database systems. </p><p>CACM 35, 6 (June 1992), 85ñ98. </p><p>[15] FRENCH, C. D. One size ts all database architectures </p><p>do not work for DSS. In Proc. of SIGMOD (May 1995), </p><p>pp. 449ñ450. </p><p>[16] GAWLICK, D., AND KINKADE, D. Varieties of concur-</p><p>rency controlin IMS&#x2F;VSfastpath. Database Engineering </p><p>Bulletin 8, 2 (1985), 3ñ10. </p><p>[17] GHEMAWAT, S., GOBIOFF, H., AND LEUNG, S.-T. The </p><p>Googlelesystem. InProc.of the19thACMSOSP(Dec. </p><p>2003), pp. 29ñ43. </p><p>[18] GRAY, J. Notes on database operating systems. In Oper-</p><p>ating Systems ó An Advanced Course, vol. 60 of Lecture </p><p>Notes in Computer Science. Springer-Verlag, 1978. </p><p>[19] GREER, R. Daytona and the fourth-generation language </p><p>Cymbal. In Proc. of SIGMOD (1999), pp. 525ñ526. </p><p>[20] HAGMANN, R. Reimplementing the Cedar le system </p><p>using logging and group commit. In Proc. of the 11th </p><p>SOSP (Dec. 1987), pp. 155ñ162. </p><p>[21] HARTMAN, J. H., AND OUSTERHOUT, J. K. The Zebra </p><p>striped network le system. In Proc. of the 14th SOSP </p><p>(Asheville, NC, 1993), pp. 29ñ43. </p><p>[22] KX.COM. kx.com&#x2F;products&#x2F;database.php. Product page. </p><p>[23] LAMPORT, L. The part-time parliament. ACM TOCS 16, </p><p>2 (1998), 133ñ169. </p><p>[24] MACCORMICK, J., MURPHY, N., NAJORK, M., </p><p>THEKKATH, C. A., AND ZHOU, L. Boxwood: Abstrac-</p><p>tionsasthefoundation forstorage infrastructure. InProc. </p><p>of the 6th OSDI (Dec. 2004), pp. 105ñ120. </p><p>[25] MCCARTHY, J. Recursive functions of symbolic expres-</p><p>sionsandtheircomputationbymachine. CACM3, 4 (Apr. </p><p>1960), 184ñ195. </p><p>[26] O’NEIL, P., CHENG, E., GAWLICK, D., AND O’NEIL, </p><p>E. The log-structured merge-tree (LSM-tree). Acta Inf. </p><p>33, 4 (1996), 351ñ385. </p><p>[27] ORACLE.COM. <a href="http://www.oracle.com/technology/products/-">www.oracle.com/technology/products/-</a></p><p>database&#x2F;clustering&#x2F;index.html. Product page. </p><p>[28] PIKE, R., DORWARD, S., GRIESEMER, R., AND QUIN-</p><p>LAN, S. Interpreting the data: Parallel analysis with </p><p>Sawzall. Scientic Programming Journal 13, 4 (2005), </p><p>227ñ298. </p><p>[29] RATNASAMY, S., FRANCIS, P., HANDLEY, M., KARP, </p><p>R., AND SHENKER, S. A scalable content-addressable </p><p>network. In Proc. of SIGCOMM (Aug. 2001), pp. 161ñ </p><p>172. </p><p>[30] ROWSTRON, A., AND DRUSCHEL, P. Pastry: Scal-</p><p>able, distributed object location and routing for large-</p><p>scale peer-to-peer systems. In Proc. of Middleware 2001 </p><p>(Nov. 2001), pp. 329ñ350. </p><p>[31] SENSAGE.COM. sensage.com&#x2F;products-sensage.htm. </p><p>Product page. </p><p>[32] STOICA, I., MORRIS, R., KARGER, D., KAASHOEK, </p><p>M. F., AND BALAKRISHNAN, H. Chord: A scalable </p><p>peer-to-peer lookup service for Internet applications. In </p><p>Proc. of SIGCOMM (Aug. 2001), pp. 149ñ160. </p><p>[33] STONEBRAKER, M. The case for shared nothing. </p><p>Database Engineering Bulletin 9, 1 (Mar. 1986), 4ñ9. </p><p>[34] STONEBRAKER, M., ABADI, D. J., BATKIN, A., CHEN, </p><p>X., CHERNIACK, M., FERREIRA, M., LAU, E., LIN, </p><p>A., MADDEN, S., O’NEIL, E., O’NEIL, P., RASIN, </p><p>A., TRAN, N., AND ZDONIK, S. C-Store: A column-</p><p>oriented DBMS. InProc.ofVLDB(Aug.2005), pp. 553ñ </p><p>564. </p><p>[35] STONEBRAKER, M., AOKI, P. M., DEVINE, R., </p><p>LITWIN, W., AND OLSON, M. A. Mariposa: A new ar-</p><p>chitecturefordistributeddata. InProc.oftheTenthICDE </p><p>(1994), IEEEComputer Society, pp. 54ñ65. </p><p>[36] SYBASE.COM. <a href="http://www.sybase.com/products/database-">www.sybase.com/products/database-</a></p><p>servers&#x2F;sybaseiq. Product page. </p><p>[37] ZHAO, B. Y., KUBIATOWICZ, J., AND JOSEPH, A. D. </p><p>Tapestry: An infrastructure for fault-tolerant wide-area </p><p>location and routing. Tech. Rep. UCB&#x2F;CSD-01-1141, CS </p><p>Division, UC Berkeley, Apr. 2001. </p><p>[38] ZUKOWSKI, M., BONCZ, P. A., NES, N., AND HEMAN, </p><p>S. MonetDB&#x2F;X100 óA DBMSin the CPUcache. IEEE </p><p>Data Eng. Bull. 28, 2 (2005), 17ñ22. </p>]]></content>
    
    
    <categories>
      
      <category>mit6.824</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式系统</tag>
      
      <tag>mit6.824</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ZooKeeper</title>
    <link href="/2024/05/02/ZooKeeper/"/>
    <url>/2024/05/02/ZooKeeper/</url>
    
    <content type="html"><![CDATA[<h1 id="ZooKeeper：互联网规模的无等待协调"><a href="#ZooKeeper：互联网规模的无等待协调" class="headerlink" title="ZooKeeper：互联网规模的无等待协调"></a>ZooKeeper：互联网规模的无等待协调</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>在本文中，我们介绍ZooKeeper，一个用于协调分布式应用程序过程的服务。由于ZooKeeper时关键基础架构的一部分，它旨在为客户建立更复杂的协调基础提供一个简单而高性能的内核。它在复制的集中式服务中结合了小组消息传递，共享寄存器和分布式锁服务的元素。ZooKeeper暴露的接口具有共享寄存器的无等待方面，其事件驱动的机制类似于分布式文件系统的缓存无效，以提供简单但功能可行的协调服务。</p><p>ZooKeeper接口可以实现高性能服务。除了无等待属性外，ZooKeeper还为所有更改ZooKeeper状态的重新审查的请求执行和线性化提供了每个客户的保障。这些设计决定促进了高性能处理管道的实现，并在本地服务器满足读取请求。我们显示目标工作负载2：1至100：1读取比例，Zookeeper可以处理数十万到数十万每秒的交易。该性能使Zookeeper可以通过客户端应用程序进行广泛的使用。</p><h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1.介绍"></a>1.介绍</h2><p>大型分布式应用需要不同形式的协调。配置是协调的最基本形式之一。以最简单的形式，配置只是系统调用的操作参数列表，而更复杂的系统具有动态配置参数。小组成员和领导者选举在分布式系统中也很常见：通常，操作需要知道哪些其他操作还活着以及这些操作负责什么。锁构成了强大的协调原语，该原语可实施对关键资源的相互排斥访问。</p><p>协调的一种方法是为每个不同的协调需求开发服务。比如说Amazon Simple Queue Service专门针对队列，其他services是专门针对领导者选举和配置开发的。比如说Chubby是一个有强一致性保障的锁服务。然后可以使用锁来实施领导者选举，小组成员资格等。</p><p>在设计协调服务时，我们不再在服务器端实施特定的原始图，而是选择了使应用程序开发人员能够实现自己的基础的API。这样的选择导致了协调内核的实现，该内核可以使新的原始素无需更改服务核心。该AP搜索实现了适合应用程序要求的多种形式的协调，而不是将开发人员限制为一组固定的原语。在设计ZooKeeper的API时，我们避开了阻塞原语（例如锁）。除其他问题外，锁协调服务的原语可能会导致客户速度缓慢或有缺陷的客户，从而对更快的客户的表现产生负面影响。如果处理请求取决于响应和其他客户的失败检测，那么服务本身的实现将变得更加复杂。因此，我们的系统（Zookeeper）实现了一种API，该API像文件系统中一样，在层次上组织简单的无等待数据对象。实际上，Zookeeper API类似于其他任何文件系统之一，并且仅查看API签名，Zookeeper似乎像Chubby一样没有锁、open和close。但是，实现无需候补数据对象，基于阻止原语锁（例如锁），将ZooKeeper与系统显著区分。虽然无等待属性对性能和容错很重要，但它不足以协调。我们还必须为操作提供顺序保证。特别是，我们发现，保证所有操作的FIFO客户端顺序和线性写入能够有效地实施该服务，并且足以为我们的应用程序的实施关注的协调基础。实际上，我们可以使用我们的API对任何数量的流程实现共识，并且根据Herlihy的层次结构，Zoo-Keeper实现了一个通用对象。Zookeeper服务包括一系列服务器，这些服务器使用复制来实现高可用性和性能。它的高性能使应用程序可以使用大量操作来使用此类协调内核来管理协调的所有方面。我们能够实施一个简单的管道架构，使我们能够有数百或数千个请求，同时仍达到低延迟。这样的管道自然可以以FIFO顺序从单个客户端执行操作。保证FIFO客户顺序使客户能够异步提交操作。通过异步操作，客户可以一次进行多个不错的操作。当新客户成为领导者时，此功能是可取的，因此必须操纵元数据并相应地对其进行更新。如果没有多次出色操作的可能性，初始化的时间可以是秒的顺序，而不是次秒。</p><p>为了确保该更新操作满足线性性能，我们实施了一个基于领导者的原子广播协议，称为ZAB。但是，Zookeeper应用程序的典型工作负载主要由读取操作主导，并且希望扩展读取吞吐量。在Zookeeper中，服务器过程在本地读取操作，我们不会使用ZAB来完全排序它们。</p><p>客户端的缓存数据是提高读取性能的重要技术。例如，对于一个过程来缓存当前领导者的标识符，而不是每次需要了解领导者时探测Zookeeper，这很有用。Zookeeper使用watch机制来使客户能够直接加速客户端缓存数据。有了这种机制，客户端可以关注给定数据对象的更新，并在更新时接收通知。Chubby直接管理客户端缓存。它会阻止更新，以内部估算所有客户端的缓存数据的缓存。在此设计下，如果这些客户端中的任何一个是缓慢或错误的，则更新会延迟。Chubby使用租赁来防止有缺陷的客户无限地阻塞系统。但是，租赁只会限制慢速或错误客户的影响，而ZooKeeper的watch机制完全避免了问题。</p><p>在本文中，我们讨论了我们对ZooKeeper的设计和实施。使用Zookeeper，即使只能写入可以线性化，我们也能够完成我们应用所需的所有协调基础。为了验证我们的方法，我们展示了如何与Zookeeper实施一些协调基础。</p><p>总而言之，在本文中，我们的主要贡献是：</p><p><code>协调内核</code>：我们提出了一项无等待的协调，并具有轻松的一致性保证，可用于分布式系统。我们特别描述了协调内核的设计和实现，我们已在许多关键应用程序中使用该内核来实现各种协调技术。</p><p><code>协调方案</code>：我们展示了如何使用 ZooKeeper 构建更高级别的协调原语，甚至是分布式应用程序中经常使用的阻塞和强一致原语。</p><p><code>协调经验</code>：我们分享一些使用 ZooKeeper 并评估其性能的方法。</p><h2 id="2-ZooKeeper服务"><a href="#2-ZooKeeper服务" class="headerlink" title="2.ZooKeeper服务"></a>2.ZooKeeper服务</h2><p>客户端使用 ZooKeeper 客户端库通过客户端 API 向 ZooKeeper 提交请求。除了通过客户端API公开ZooKeeper服务接口之外，客户端库还管理客户端和ZooKeeper服务器之间的网络连接。在本节中，我们首先提供 ZooKeeper 服务的高级视图。然后我们讨论客户端用来与ZooKeeper交互的API。</p><p><code>术语</code>：本文中，我们用client表示ZooKeeper服务的用户，server表示提供ZooKeeper服务的进程，znode 表示 ZooKeeper 数据中的内存数据节点，它组织在称为数据树的分层命名空间中。</p><h3 id="2-1-服务概览"><a href="#2-1-服务概览" class="headerlink" title="2.1 服务概览"></a>2.1 服务概览</h3><p>ZooKeeper 向其客户端提供一组数据节点（znode）的抽象，这些数据节点根据分层名称空间进行组织。此层次结构中的 znode 是客户端通过 ZooKeeper API 操作的数据对象。层次命名空间通常用在文件系统中。这是组织数据对象的理想方式，因为用户已经习惯了这种抽象，并且它可以更好地组织应用程序元数据。为了指向一个给定的znode，我们对文件系统路径使用标准 UNIX 表示法。例如，我们使用 &#x2F;A&#x2F;B&#x2F;C 来表示 znode C 的路径，其中 C 以 B 作为其父节点，B 以 A 作为其父节点。所有 znode 都存储数据，并且除临时 znode 之外的所有 znode 都可以有子节点。</p><p><img src="/../imgs/ZooKeeper/image-20240502031217505.png" alt="图 1：ZooKeeper 分层名称空间的图示。"></p><p>客户端可以创建两种类型的znode：</p><p><code>常规</code>：客户端通过显式创建和删除常规znode来操作它们；</p><p><code>短期</code>：客户端创建此类znode，并且它们要么显式删除它们，要么让系统在创建它们的会话终止时（故意或由于失败）自动删除它们。</p><p>此外，当创建新的 znode 时，客户端可以设置顺序标志。使用顺序标志集创建的节点具有附加到其名称的单调递增计数器的值。如果 n 是新 znode，p 是父 znode，则 n 的序列值永远不会小于 p 下创建的任何其他顺序 znode 的名称中的值。ZooKeeper 实现了Watch，允许客户端及时接收更改通知，而无需轮询。当客户端发出设置了watch标志的读取操作时，操作会正常完成，只是服务器承诺在返回的信息发生更改时通知客户端。监视是与会话关联的一次性触发器；一旦触发或会话关闭，它们就会被注销。Watch指示已发生更改，但不提供更改。例如，如果客户端在“&#x2F;foo”更改两次之前发出 getData(‘‘&#x2F;foo’’, true)，则客户端将收到一个监视事件，告诉客户端“&#x2F;foo”的数据已更改。会话事件（例如连接丢失事件）也会发送到监视回调，以便客户端知道监视事件可能会延迟。</p><p><strong>数据模型</strong></p><p>ZooKeeper的数据模型本质上是一个具有简化API且仅进行完整数据读写的文件系统，或者是具有分层键的键&#x2F;值表。分层命名空间对于为不同应用程序的命名空间分配子树以及设置对这些子树的访问权限非常有用。我们还利用客户端的目录概念来构建更高级别的原语，正如我们将在 2.4 节中看到的那样。</p><p>与文件系统中的文件不同，znode 并不是为一般数据存储而设计的。相反，znode 映射到客户端应用程序的抽象，通常对应于用于协调目的的元数据。为了说明这一点，在图 1 中，我们有两个子树，一个用于应用程序 1 (&#x2F;app1)，另一个用于应用程序 2 (&#x2F;app2)。应用程序 1 的子树实现了一个简单的组成员身份协议：每个客户端进程 pi 在 &#x2F;app1 下创建一个 znode pi，只要进程正在运行，该节点就会持续存在。</p><p>尽管 znode 不是为一般数据存储而设计的，但 ZooKeeper 确实允许客户端存储一些可用于分布式计算中的元数据或配置的信息。例如，在基于领导者的应用程序中，对于刚刚开始了解哪个其他服务器当前是领导者的应用程序服务器非常有用。为了实现这个目标，我们可以让当前领导者将此信息写入 znode 空间中的已知位置。Znode 还具有与时间戳和版本计数器关联的元数据，这允许客户端跟踪 znode 的更改并根据 znode 的版本执行条件更新。</p><p><strong>会话</strong></p><p>客户端连接到 ZooKeeper 并启动会话。会话有对应的超时。如果客户端在超过该超时时间内没有从会话中收到任何内容，Zoo-Keeper 就会认为客户端有故障。当客户端显式关闭会话句柄或 ZooKeeper 检测到客户端出现故障时，会话结束。在会话中，客户端观察到一系列反映其操作执行情况的状态更改。会话使客户端能够在 ZooKeeper 整体中透明地从一台服务器移动到另一台服务器，从而在 ZooKeeper 服务器之间持续存在。</p><h3 id="2-2-客户端API"><a href="#2-2-客户端API" class="headerlink" title="2.2 客户端API"></a>2.2 客户端API</h3><p>我们在下面介绍了 ZooKeeper API 的相关子集，并讨论了每个请求的语义。</p><p><code>create(path, data, flags)</code>：创建一个路径名为path的znode，在其中存储data[]，并返回新znode的名称。 flags 使客户端能够选择 znode 的类型：常规、临时，并设置顺序标志；</p><p><code>delete(path, version)</code>：如果 znode 处于预期的版本，则删除该 znode 路径；</p><p><code>exists(path, watch)</code>:如果路径名为path的znode存在则返回true，否则返回false。watch标识符使用户在该znode上建立一个watch</p><p><code>getData(path, watch)</code>：返回与 znode 关联的数据和元数据，例如版本信息。 watch 标志的工作方式与 Exists() 相同，只是如果 znode 不存在，Zoo-Keeper 不会设置 watch；</p><p><code>setData(path, data, version)</code>：如果版本号是znode的当前版本，则将data[]写入znode路径；</p><p><code>getChildren(path, watch)</code>：返回 znode 的子节点的名称集合；</p><p><code>sync(path)</code>：等待操作开始时挂起的所有更新传播到客户端连接到的服务器。该路径当前被忽略。</p><p>所有方法都有通过 API 提供的同步和异步版本。当应用程序需要执行单个 ZooKeeper 操作并且没有要执行的并发任务时，应用程序会使用同步 API，因此它会进行必要的 ZooKeeper 调用并阻塞。然而，异步 API 使应用程序能够同时执行多个未完成的 ZooKeeper 操作和其他任务。ZooKeeper 客户端保证每个操作的相应回调按顺序调用。</p><p>请注意，ZooKeeper 不使用句柄来访问 znode。每个请求都包含正在操作的 znode 的完整路径。这种选择不仅简化了 API（没有 open() 或 close() 方法），而且还消除了服务器需要维护的额外状态。</p><p>每个更新方法都采用预期的版本号，这使得可以实现条件更新。如果 znode 的实际版本号与预期版本号不匹配，则更新将失败并出现意外版本错误。如果版本号为-1，则不进行版本检查。</p><h3 id="2-3-ZooKeeper-保证"><a href="#2-3-ZooKeeper-保证" class="headerlink" title="2.3 ZooKeeper 保证"></a>2.3 ZooKeeper 保证</h3><p>ZooKeeper 有两个基本的顺序保证：</p><ol><li>线性化写入：所有更新 ZooKeeper 状态的请求都是可序列化的并尊重优先级；</li><li>FIFO 客户端顺序：来自给定客户端的所有请求都按照客户端发送的顺序执行。</li></ol><p>请注意，我们对线性化的定义与 Herlihy 最初提出的定义不同，我们将其称为 A-线性化（异步线性化）。在 Herlihy 对线性化的最初定义中，客户端一次只能有一个未完成的操作（一个客户端是一个线程）。在我们的系统中，我们允许一个客户端有多个未完成的操作，因此我们可以选择对同一客户端的未完成操作不保证特定的顺序，或者保证先进先出的顺序。我们为我们的属性选择后者。重要的是要观察到，适用于可线性化对象的所有结果也适用于可线性化对象，因为满足A-线性化的系统也满足可线性化的系统。由于只有更新请求是 A 线性化的，ZooKeeper 在每个副本上本地处理读取请求。这使得服务可以随着服务器添加到系统而线性扩展。</p><p>要了解这两个保证如何相互作用，请考虑以下场景。包含多个进程的系统会选举一个领导者来指挥工作进程。当新的领导者接管系统时，它必须更改大量配置参数，并在完成后通知其他进程。那么我们有两个重要的要求：</p><ul><li>当新的领导者开始进行更改时，我们不希望其他进程开始使用正在更改的配置；</li><li>如果新的领导者在配置完全更新之前死亡，我们不希望进程使用这部分配置。</li></ul><p>请注意，分布式锁（例如 Chubby 提供的锁）有助于满足第一个要求，但不足以满足第二个要求。通过ZooKeeper，新领导者可以指定一条路径作为就绪znode；其他进程只会在该 znode 存在时使用该配置。新领导者通过删除ready、更新各种配置znodes以及创建ready来进行配置更改。所有这些更改都可以通过管道传输并异步发出，以快速更新配置状态。尽管变更操作的延迟约为 2 毫秒，但如果请求是另一个接一个地发出的请求，则必须更新5000个不同Znodes的新领导者将需要10秒；通过异步发出请求，请求将不到一秒钟。由于顺序保证，如果一个进程看到就绪的 znode，它还必须看到新领导者所做的所有配置更改。如果新的领导者在创建就绪的 znode 之前死亡，则其他进程知道配置尚未最终确定并且不会使用它。上述方案仍然存在一个问题：如果一个进程在新的领导者开始进行更改之前发现就绪存在，然后在更改正在进行时开始读取配置，会发生什么情况。这个问题可以通过通知的顺序保证来解决：如果客户端正在监视更改，则客户端将在更改发生后看到系统的新状态之前看到通知事件。因此，如果读取就绪 znode 的进程请求获得该 znode 更改的通知，在它可以读取任何新配置之前它会看到通知告诉它客户端的更改。</p><p>当客户端除了 ZooKeeper 之外还有自己的通信通道时，可能会出现另一个问题。例如，考虑两个客户端 A 和 B 在 ZooKeeper 中具有共享配置并通过共享通信通道进行通信。如果 A 更改了 ZooKeeper 中的共享配置并通过共享通信通道告知 B 更改，B 会期望在重新读取配置时看到更改。如果 B 的 ZooKeeper 副本稍微落后于 A，则它可能看不到新配置。使用上述保证 B 可以通过在重新读取配置之前发出写入来确保它看到最新的信息。为了更有效地处理这种情况，Zoo-Keeper 提供了同步请求：当随后进行读取时，构成慢速读取。同步会导致服务器在处理读取之前应用所有挂起的写入请求，而不会产生完整写入的开销。该原语在思想上与ISIS的flush原语类似。</p><p>ZooKeeper还具有以下两个活性和持久性保证：</p><ul><li>如果大多数 ZooKeeper 服务器处于活动状态并且通信服务可用；</li><li>如果 ZooKeeper 服务成功响应更改请求，则只要特度不够数量的服务器最终能够恢复，该更改就会在任意数量的故障中持续存在。</li></ul><h3 id="2-4-原语示例"><a href="#2-4-原语示例" class="headerlink" title="2.4 原语示例"></a>2.4 原语示例</h3><p>在本节中，我们将展示如何使用ZooKeeper API来实现更强大的原语。ZooKeeper服务对这些更强大的原语一无所知，因为它们完全是使用ZooKeeper客户端API在客户端实现的。一些常见的原语（例如组成员身份和配置管理）也是无需等待的。对于其他事件，例如集合点，客户端需要等待事件。即使 ZooKeeper 是无等待的，我们也可以使用 ZooKeeper 实现高效的阻塞原语。ZooKeeper 的排序保证允许对系统状态进行有效的推理，而监视则允许有效的等待。</p><p><code>配置管理</code>：ZooKeeper可用于在分布式应用程序中实现动态配置。配置以最简单的形式存储在 znode z<sub>c</sub> 中。进程以z<sub>c</sub>的完整路径名启动。启动进程通过读取 z<sub>c</sub> 来获取其配置，并将监视标志设置为 true。如果 z<sub>c</sub> 中的配置被更新，进程会收到通知并读取新配置，再次将监视标志设置为 true。请注意，在此方案中，与大多数使用监视的其他方案一样，监视用于确保进程拥有最新信息。例如，如果监视 z<sub>c</sub> 的进程收到 z<sub>c</sub> 更改的通知，并且在它可以发出对 z<sub>c</sub> 的读取之前，z<sub>c</sub> 又发生了三个更改，则该进程不会再收到三个通知事件。这不会影响进程的行为，因为这三个事件只是通知进程它已经知道的事情：它拥有的 z<sub>c</sub> 信息已过时。</p><p><code>汇合</code>：有时，在分布式系统中，并不总是先验地清楚最终的系统配置会是什么样子。例如，客户端可能想要启动一个主进程和几个工作进程，但是启动进程是由调度程序完成的，因此客户端无法提前知道可以为工作进程提供连接到主进程的地址和端口等信息。我们通过 ZooKeeper 使用集合点 znode z<sub>r</sub> 来处理这种情况，z<sub>r</sub> 是客户端创建的节点。客户端将 z<sub>r</sub> 的完整路径名作为主进程和工作进程的启动参数传递。当主机启动时，它会在 z<sub>r</sub> 中填充有关其正在使用的地址和端口的信息。当worker启动时，他们会读取 z<sub>r</sub> 并将 watch 设置为 true。如果 z<sub>r</sub> 尚未填写，worker 等待 z<sub>r</sub> 更新时收到通知。如果 z<sub>r</sub> 是临时节点，则主进程和工作进程可以监视 z<sub>r</sub> 是否被删除，并在客户端结束时自行清理。</p><p><code>组成员</code>：我们利用临时节点来实现组成员资格。具体来说，我们利用临时节点允许我们查看创建节点的会话状态的事实。我们首先指定一个 znode，z<sub>g</sub> 来代表该组。当组中的进程成员启动时，它会在 z<sub>g</sub> 下创建一个临时子 znode。如果每个进程都有唯一的名称或标识符，则该名称用作子 znode 的名称；否则，进程将创建带有 SEQUENTIAL 标志的 znode 以获得唯一的名称分配。例如，进程可以将进程信息放入子znode的数据、进程使用的地址和端口中。</p><p>在 z<sub>g</sub> 下创建子 znode 后，进程正常启动。它不需要做任何其他事情。如果进程失败或者结束，z<sub>g</sub>下代表它的znode会被自动移除。</p><p>进程可以通过简单地列出 z<sub>g</sub> 的子进程来获取组信息。如果进程想要监视组成员身份的更改，则该进程可以将监视标志设置为 true，并在收到更改通知时刷新组信息（始终将监视标志设置为 true）。</p><p><code>简单的锁</code>：虽然ZooKeeper不是一个锁服务，但它可以用来实现锁。使用 ZooKeeper 的应用程序通常使用根据其需求定制的同步原语，例如上面所示的那些。在这里，我们展示了如何使用 ZooKeeper 实现锁，以表明它可以实现各种通用同步原语。</p><p>最简单的锁实现使用“锁文件”。锁由 znode 表示。为了获取锁，客户端尝试使用 EPHEMERAL 标志创建指定的 znode。如果创建成功，则客户端持有锁。否则，客户端可以读取设置了监视标志的 znode，以便在当前领导者死亡时收到通知。客户端在死亡或显式删除 znode 时释放锁。其他正在等待锁的客户端一旦观察到 znode 被删除，就会再次尝试获取锁。</p><p>虽然这个简单的锁定协议有效，但它确实存在一些问题。首先，它受到羊群效应的影响。如果有很多客户端等待获取锁，那么当锁释放时，即使只有一个客户端可以获得锁，它们也会争夺锁。其次，它只实现独占锁定。以下两个原语展示了如何克服这两个问题。</p><p><code>无羊群效应的简单锁</code>：我们定义一个锁znode l来实现这样的锁。直观上，我们将所有请求锁的客户端排列起来，每个客户端按照请求到达的顺序获得锁。因此，希望获得锁的客户端执行以下操作：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs awk">Lock <br><span class="hljs-number">1</span> n = create(l + “/lock-”, EPHEMERAL|SEQUENTIAL) <br><span class="hljs-number">2</span> C = getChildren(l, false) <br><span class="hljs-number">3</span> <span class="hljs-keyword">if</span> n is lowest znode <span class="hljs-keyword">in</span> C, <span class="hljs-keyword">exit</span> <br><span class="hljs-number">4</span> p = znode <span class="hljs-keyword">in</span> C ordered just before n <br><span class="hljs-number">5</span> <span class="hljs-keyword">if</span> exists(p, true) wait <span class="hljs-keyword">for</span> watch event <br><span class="hljs-number">6</span> goto <span class="hljs-number">2</span> <br>Unlock <br><span class="hljs-number">1</span> <span class="hljs-keyword">delete</span>(n) <br></code></pre></td></tr></table></figure><p>Lock 第 1 行中 SEQUENTIAL 标志的使用命令客户端获取锁的尝试相对于所有其他尝试。如果客户端的 znode 在第 3 行具有最低序列号，则客户端持有锁。否则，客户端将等待删除拥有锁或将在该客户端的 znode 之前接收锁的 znode。通过仅观察客户端 znode 之前的 znode，我们可以在释放锁或放弃锁请求时仅唤醒一个进程，从而避免羊群效应。一旦客户端正在监视的 znode 消失，客户端必须检查它现在是否持有锁。（之前的锁请求可能已经被放弃，并且有一个序列号较低的znode仍在等待或持有锁。）</p><p>释放锁就像删除代表锁请求的 znode n 一样简单。通过在创建时使用 EPHEMERAL 标志，崩溃的进程将自动清除任何锁定请求或释放它们可能拥有的任何锁定。综上所述，这种锁定方案有以下优点：</p><ol><li>删除一个 znode 只会导致一个客户端醒来，因为每个 znode 都被另一个客户端监视，所以我们没有羊群效应；</li><li>没有轮询或超时；</li><li>由于我们实现锁定的方式，我们可以通过浏览 ZooKeeper 数据来查看锁争用、中断锁定和调试锁定问题的数量。</li></ol><p><code>读/写锁</code>：为了实现读&#x2F;写锁，我们稍微改变了锁定过程，并具有单独的读锁和写锁过程。解锁过程与全局锁定情况相同。</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">Write</span> <span class="hljs-keyword">Lock</span> <br><span class="hljs-number">1</span> n = <span class="hljs-keyword">create</span>(l + “/<span class="hljs-keyword">write</span>-”, EPHEMERAL|SEQUENTIAL) <br><span class="hljs-number">2</span> C = getChildren(l, <span class="hljs-keyword">false</span>) <br><span class="hljs-number">3</span> <span class="hljs-keyword">if</span> n <span class="hljs-keyword">is</span> lowest znode <span class="hljs-keyword">in</span> C, <span class="hljs-keyword">exit</span> <br><span class="hljs-number">4</span> p = znode <span class="hljs-keyword">in</span> C ordered just <span class="hljs-keyword">before</span> n <br><span class="hljs-number">5</span> <span class="hljs-keyword">if</span> <span class="hljs-keyword">exists</span>(p, <span class="hljs-keyword">true</span>) wait <span class="hljs-keyword">for</span> event <br><span class="hljs-number">6</span> goto <span class="hljs-number">2</span> <br><span class="hljs-keyword">Read</span> <span class="hljs-keyword">Lock</span> <br><span class="hljs-number">1</span> n = <span class="hljs-keyword">create</span>(l + “/<span class="hljs-keyword">read</span>-”, EPHEMERAL|SEQUENTIAL) <br><span class="hljs-number">2</span> C = getChildren(l, <span class="hljs-keyword">false</span>) <br><span class="hljs-number">3</span> <span class="hljs-keyword">if</span> <span class="hljs-keyword">no</span> <span class="hljs-keyword">write</span> znodes lower than n <span class="hljs-keyword">in</span> C, <span class="hljs-keyword">exit</span> <br><span class="hljs-number">4</span> p = <span class="hljs-keyword">write</span> znode <span class="hljs-keyword">in</span> C ordered just <span class="hljs-keyword">before</span> n <br><span class="hljs-number">5</span> <span class="hljs-keyword">if</span> <span class="hljs-keyword">exists</span>(p, <span class="hljs-keyword">true</span>) wait <span class="hljs-keyword">for</span> event <br><span class="hljs-number">6</span> goto <span class="hljs-number">3</span> <br></code></pre></td></tr></table></figure><p>此锁定过程与之前的锁定略有不同。写锁仅在命名上有所不同。由于读锁可能是共享的，因此第 3 行和第 4 行略有不同，因为只有较早的写锁 znode 会阻止客户端获取读锁。当有多个客户端等待读锁并在删除序列号较低的“写”znode 时收到通知时，我们可能会出现“羊群效应”；事实上，这是一种期望的行为，所有这些读取客户端都应该被释放，因为它们现在可能拥有锁。</p><p><code>双重屏障</code>:双屏障使客户端能够同步计算的开始和结束。当由屏障阈值定义的足够多的进程加入屏障时，进程开始计算并在完成后离开屏障。我们用 znode 表示 ZooKeeper 中的屏障，称为 b。每个进程 p 在进入时向 b 注册（通过创建一个 znode 作为 b 的子节点），并在准备离开时取消注册（重新移动子节点）。当 b 的子 znode 数量超过屏障阈值时，进程可以进入屏障。当所有进程都删除了它们的子进程时，进程就可以离开屏障。我们使用watch有效等待满足的进入和退出条件。为了进入，进程会监视 b 是否存在就绪子级，该子级将由导致子级数量超过屏障阈值的进程创建。为了离开，进程会监视特定子节点的消失，并且仅在该 znode 被删除后才检查退出条件。</p><h2 id="3-ZooKeeper应用程序"><a href="#3-ZooKeeper应用程序" class="headerlink" title="3 ZooKeeper应用程序"></a>3 ZooKeeper应用程序</h2><p>现在我们描述一些使用 ZooKeeper 的应用程序，并简要解释它们如何使用它。我们以<strong>粗体</strong>显示每个示例的原语。</p><p><strong>抓取服务</strong> 爬虫是搜索引擎的重要组成部分，而 Yahoo!抓取数十亿的Web文档。获取服务 (FS) 是Yahoo!爬虫的一部分，目前正在生产中。本质上，它具有命令页面获取进程的主进程。主设备为提取器提供配置，并且提取器回写通知其状态和健康状况。使用 ZooKeeper for FS 的主要优点是从主服务器故障中恢复、在发生故障时保证可用性以及将客户端与服务器解耦，允许他们通过从 ZooKeeper 读取状态来将请求定向到健康的服务器。因此，FS主要使用ZooKeeper来管理配置元数据，尽管它也使用ZooKeeper来选举master（领导者选举）。</p><p><img src="/../imgs/ZooKeeper/image-20240502031314762.png"></p><p>图 2 显示了 FS 使用的 ZooKeeper 服务器三天内的读写流量。为了生成这个图表，我们计算了该时间段内每一秒的操作次数，每个点对应于该秒内的操作次数。我们观察到读取流量比写入流量高得多。在速率高于每秒 1,000 次操作期间，读：写比率在 10:1 和 100:1 之间变化。此工作负载中的读取操作为 getData()、getChildren() 和 Exists()，按流行程度递增的顺序排列</p><p><strong><font size=3>Katta</font></strong> Katta是一个分布式索引器，使用 ZooKeeper 进行协调，它是非 Yahoo! 的一个示例应用。Katta 使用分片来划分索引工作。主服务器将分片分配给从服务器并跟踪进度。从站可能会发生故障，因此主节点必须在从节点来来去去时重新分配负载。主服务器也可能发生故障，因此其他服务器必须准备好在发生故障时接管。 Katta 使用 ZooKeeper 跟踪从服务器和主服务器的状态（组成员身份），并处理主服务器故障转移（领导者选举）。Katta 还使用 ZooKeeper 来跟踪分片分配并将其传播到从属设备（配置管理）。</p><p><strong><font size=3>Yahoo!消息代理</font></strong> Yahoo！消息代理（YMB）是一个分布式发布订阅系统。该系统管理着数千个主题，客户端可以向这些主题发布消息并从中接收消息。这些主题分布在一组服务器中以提供可扩展性。每个主题都使用主备方案进行复制，确保消息复制到两台机器，以确保可靠的消息传递。组成 YMB 的服务器使用无共享分布式架构，这使得协调对于正确操作至关重要。组成 YMB 的服务器使用无共享分布式架构，这使得协调对于正确操作至关重要。YMB使用ZooKeeper来管理主题的分布（配置元数据），处理系统中机器的故障（故障检测和组成员身份），并控制系统操作。</p><p><img src="/../imgs/ZooKeeper/image-20240502031330397.png" alt="图 3：YMB在ZooKeeper中的消息代理结构"></p><p>图 3 显示了 YMB 的 znode 数据布局的一部分。每个代理域都有一个称为节点的 znode，它为组成 YMB 服务的每个活动服务器都有一个临时 znode。每个 YMB 服务器在具有负载和状态信息的节点下创建一个临时 znode，通过 ZooKeeper 提供组成员身份和状态信息。禁止关闭和迁移等节点由组成服务的所有服务器进行监控，并允许 YMB 进行集中控制。主题目录对于 YMB 管理的每个主题都有一个子 znode。这些主题 znode 具有子 znode，它们指示每个主题的主服务器和备份服务器以及该主题的订阅者。主服务器和备份服务器 znode 不仅允许服务器发现负责某个主题的服务器，而且还管理领导者选举和服务器崩溃。</p><p><img src="/../imgs/ZooKeeper/image-20240502031349211.png" alt="图4：ZooKeeper服务的组件"></p><h2 id="4-ZooKeeper实现"><a href="#4-ZooKeeper实现" class="headerlink" title="4.ZooKeeper实现"></a>4.ZooKeeper实现</h2><p>ZooKeeper 通过在组成服务的每台服务器上复制 ZooKeeper 数据来提供高可用性。我们假设服务器因崩溃而发生故障，并且此类故障服务器稍后可能会恢复。图 4 显示了 ZooKeeper 服务的高级组件。接收到请求后，服务器准备执行该请求（请求处理器）。如果这样的请求需要服务器之间的协调（写请求），那么它们使用一致协议（原子广播的实现），最后，服务器将更改提交到 ZooKeeper 数据库，并在整体的所有服务器上完全复制。在读取请求的情况下，服务器只需读取本地数据库的状态并生成对请求的响应。</p><p>复制数据库是包含整个数据树的内存数据库。树中的每个 znode 默认情况下最多存储 1MB 的数据，但这个最大值是一个配置参数，可以在特定情况下更改。为了可恢复性，我们将更新有效地记录到磁盘，并强制写入在磁盘介质上，然后再应用于内存数据库。事实上，正如Chubby一样，我们保留已提交操作的重播日志（在我们的例子中是预写日志），并生成内存数据库的定期快照。</p><p>每个 ZooKeeper 服务器都为客户端提供服务。客户端仅连接到一台服务器来提交其请求。正如我们之前提到的，读取请求由每个服务器数据库的本地副本提供服务。更改服务状态的请求（写入请求）由协议协议处理。作为协议的一部分，写请求被转发到称为领导者的单个服务器。剩下的ZooKeeper服务器，叫做跟随者，接收消息提案包括来自领导者的状态更改，并就状态更改达成一致。</p><h3 id="4-1-请求处理器"><a href="#4-1-请求处理器" class="headerlink" title="4.1 请求处理器"></a>4.1 请求处理器</h3><p>由于消息传递层是原子的，因此我们保证本地副本永远不会分歧，尽管在任何时候某些服务器可能比其他服务器应用了更多的事务。与客户端发送的请求不同，事务是幂等的。当领导者收到写入请求时，它会计算应用写入时系统的状态，并将其转换为捕获此新状态的事务。必须计算未来状态，因为可能存在尚未应用到数据库的未完成事务。例如，如果客户端执行了条件 setData 并且请求中的版本号与正在更新的 znode 的未来版本号相匹配，该服务生成一个 setDataTXN，其中包含新数据、新版本号和更新的时间戳。如果发生错误，例如版本号不匹配或要更新的 znode 不存在，则会生成 errorTXN。</p><h3 id="4-2-原子广播"><a href="#4-2-原子广播" class="headerlink" title="4.2 原子广播"></a>4.2 原子广播</h3><p>所有更新 ZooKeeper 状态的请求都会转发给领导者。 Leader 执行请求并通过原子广播协议 Zab 将变化广播到 ZooKeeper 状态。接收到客户端请求的服务器在传递相应的状态变化时响应客户端。Zab 默认使用简单多数仲裁来决定提案，因此只有大多数服务器正确时，Zab 和 ZooKeeper 才能工作（即，使用 2f + 1 个服务器，我们可以容忍 f 个故障）。</p><p>为了实现高吞吐量，ZooKeeper 尝试保持请求处理管道已满。它可能在处理管道的不同部分有数千个请求。由于状态更改取决于先前状态更改的应用，因此 Zab 提供了比常规原子广播更强的顺序保证。更具体地说，Zab 保证领导者广播的更改按照发送的顺序进行传递，并且先前领导者的所有更改都会在已建立的领导者广播自己的更改之前传递给已建立的领导者。</p><p>有一些实现细节可以简化我们的实现并为我们提供出色的性能。我们使用 TCP 进行传输，因此消息顺序由网络维护，这使我们能够简化实现。我们使用 Zab 选择的领导者作为 ZooKeeper 领导者，以便创建事务的同一进程也会提议它们。我们使用日志来跟踪提案,作为内存数据库的预写日志，这样我们就不必将消息写入磁盘两次。</p><p>在正常操作期间，Zab 确实按顺序传递所有消息并且只传递一次，但由于 Zab 不会持久记录传递的每条消息的 id，因此 Zab 可能会在恢复期间重新传递消息。因为我们使用幂等事务，所以只要按顺序交付，多次交付是可以接受的。事实上，ZooKeeper 要求 Zab 至少重新传送上次快照开始后传送的所有消息。</p><h3 id="4-3-复制数据库"><a href="#4-3-复制数据库" class="headerlink" title="4.3 复制数据库"></a>4.3 复制数据库</h3><p>每个副本在内存中都有一个 ZooKeeper 状态的副本。当 ZooKeeper 服务器从崩溃中恢复时，它需要恢复此内部状态。在运行服务器一段时间后，重放所有已传递的消息以恢复状态将花费非常长的时间，因此 ZooKeeper 使用定期快照，并且只需要自快照启动以来重新传递消息。我们将 ZooKeeper 快照称为模糊快照，因为我们不锁定 ZooKeeper 状态来拍摄快照；相反，我们对树进行深度优先扫描，自动读取每个 znode 的数据和元数据并将它们写入磁盘。由于生成的模糊快照可能应用了快照生成期间传递的状态更改的某些子集，因此结果可能与 ZooKeeper 在任何时间点的状态都不对应。但是，由于状态更改是幂等的，因此只要按顺序应用状态更改，我们就可以应用两次。</p><p>例如，假设在 ZooKeeper 数据树中，两个节点 &#x2F;foo 和 &#x2F;goo 的值分别为 f1 和 g1，并且在模糊快照开始时都位于版本 1，并且以下状态更改流的格式为 &lt;transactionType， path， value， new-version&gt;：</p><p>&lt;SetDataTXN, &#x2F;foo, f2, 2&gt;</p><p>&lt;SetDataTXN, &#x2F;goo, g2, 2&gt; </p><p>&lt;SetDataTXN, &#x2F;foo, f3, 3&gt; </p><p>处理这些状态更改后，&#x2F;foo 和 &#x2F;goo 的值 f3 和 g2 分别为版本 3 和 2。然而，模糊快照可能记录了 &#x2F;foo 和 &#x2F;goo 的值 f3 和 g1 分别为版本 3 和 1，这不是 ZooKeeper 数据树的有效状态。如果服务器崩溃并使用此快照恢复，并且 Zab 重新传递状态更改，则结果状态对应于崩溃之前服务的状态。</p><h3 id="4-4-客户端-服务器交互"><a href="#4-4-客户端-服务器交互" class="headerlink" title="4.4 客户端-服务器交互"></a>4.4 客户端-服务器交互</h3><p>当服务器处理写入请求时，它还会发送并清除与与该更新相对应的任何监视相关的通知。服务器按顺序处理写入，不会同时处理其他写入或读取。这确保了通知的严格连续性。请注意，服务器在本地处理通知。只有客户端连接的服务器才会跟踪并触发该客户端的通知。</p><p>读取请求在每台服务器上本地处理。每个读取请求都会被处理并使用 zxid 进行标记，该 zxid 对应于服务器看到的最后一个事务。该 zxid 定义读请求相对于写请求的部分顺序。通过在本地处理读取，我们获得了出色的读取性能，因为它只是本地服务器上的内存中操作，并且没有磁盘活动或协议协议可以运行。这种设计选择对于实现我们以读取为主的工作负载实现卓越性能的目标至关重要。</p><p>使用快速读取的一个缺点是不能保证读取操作的优先顺序。也就是说，即使已提交对同一 znode 的更新更新，读取操作也可能返回过时的值。并非所有应用程序都需要优先顺序，但对于确实需要优先顺序的应用程序，我们已经实现了同步。该原语异步执行，并在所有待处理写入其本地副本后由领导者排序。为了保证给定的读取操作返回最新更新的值，客户端在读取操作后调用同步。客户端操作的 FIFO 顺序保证与同步的全局保证一起使读取操作的结果能够反映发出同步之前发生的任何更改。在我们的实现中，我们不需要原子地广播同步，因为我们使用基于领导者的算法，我们只需将同步操作放在领导者和执行同步调用的服务器之间的请求队列的末尾。为了使其发挥作用，追随者必须确保领导者仍然是领导者。如果有待提交的事务，则服务器不会怀疑领导者。如果挂起队列为空，则领导者需要发出一个空事务来提交，并在该事务之后命令同步。这有一个很好的特性，即当领导者处于负载状态时，不会生成额外的广播流量。在我们的实现中，设置了超时，以便领导者在追随者放弃他们之前意识到自己不是领导者，因此我们不会发出空事务。</p><p>ZooKeeper 服务器按照 FIFO 顺序处理来自客户端的请求。响应包括响应相关的 zxid。即使在无活动间隔期间的心跳消息也包含客户端连接到的服务器看到的最后一个 zxid。如果客户端连接到新服务器，则该新服务器通过对照客户端的最后一个 zxid 来检查客户端的最后一个 zxid，以确保其 ZooKeeper 数据的视图至少与客户端的视图一样新。如果客户端的视图比服务器更新，则在服务器赶上之前，服务器不会重新建立与客户端的会话。保证客户端能够找到具有系统最新视图的另一台服务器，因为客户端只能看到已复制到大多数 ZooKeeper 服务器的更改。此行为对于保证持久性非常重要。</p><p>为了检测客户端会话失败，ZooKeeper 使用超时。如果在会话超时期间没有其他服务器从客户端接收到任何内容，则领导者确定已发生故障。如果客户端发送重新任务的频率足够高，则无需发送任何其他消息。否则，客户端将在低活动期间发送检测信号消息。如果客户端无法与服务器通信以发送请求或检测信号，它将连接到其他 ZooKeeper 服务器以重新建立其会话。为了防止会话计时，ZooKeeper 客户端库在会话空闲 s&#x2F;3 毫秒后发送检测信号，如果会话在 2s&#x2F;3 毫秒内没有收到来自服务器的消息，则切换到新服务器，其中 s 是会话超时（以毫秒为单位）。</p><h2 id="5-相关工作"><a href="#5-相关工作" class="headerlink" title="5 相关工作"></a>5 相关工作</h2><p>ZooKeeper 的目标是提供一种服务来缓解分布式应用程序中协调进程的问题。为了实现这一目标，它的设计借鉴了之前的协调服务、容错系统、分布式算法和文件系统的思想。</p><p>我们并不是第一个提出分布式应用程序协调系统的人。一些早期的系统提出了一种用于事务应用程序的分布式锁服务，以及用于在计算机集群中共享信息。最近，Chubby 提出了一个系统来管理分布式应用程序的咨询锁 。 Chubby 与 ZooKeeper 有着共同的几个目标。它还具有类似文件系统的接口，并使用一致协议来保证副本的一致性。但是，ZooKeeper 不是锁服务。客户端可以使用它来实现锁，但其API中没有锁操作。与 Chubby 不同，ZooKeeper 允许客户端连接到任何 ZooKeeper 服务器，而不仅仅是领导者。ZooKeeper 客户端可以使用其本地副本来提供数据并管理监视，因为它的一致性模型比 Chubby 轻松得多。这使得ZooKeeper能够提供比Chubby更高的性能，从而允许应用程序更广泛地使用ZooKeeper。</p><p>文献中已经提出了容错系统，其目标是缓解构建容错分布式应用程序的问题。ISIS 是一种早期系统。 ISIS系统将抽象类型规范转换为容错的分布式对象，从而使容错机制对用户透明。Horus 和 Ensemble 是从 ISIS 演变而来的系统。 ZooKeeper 采用 ISIS 虚拟同步的概念。最后，Totem 保证了利用局域网硬件广播的架构中消息传递的总顺序。ZooKeeper 适用于各种网络拓扑，这促使我们依赖服务器进程之间的 TCP 连接，而不是假设任何特殊的拓扑或硬件功能。我们也不会公开 ZooKeeper 内部使用的任何集成通信。</p><p>构建容错服务的一项重要技术是状态机复制，而 Paxos 是一种能够高效实现异步系统复制状态机的算法。我们使用的算法具有 Paxos 的一些特性，但它将共识所需的事务日志记录与数据树恢复所需的预写日志记录相结合，以实现高效的实现。已经提出了用于实际实现拜占庭容错复制状态机的协议。ZooKeeper 并不假设服务器可以是拜占庭式的，但我们确实采用校验和和健全性检查等机制来捕获非恶意的拜占庭式错误。克莱门特等人，讨论一种在不修改当前服务器代码库的情况下使 ZooKeeper 完全具有拜占庭容错能力的方法。迄今为止，我们还没有观察到使用完全拜占庭容错协议可以避免的生产错误。</p><p>Boxwood 是一个使用分布式锁服务器的系统。 Boxwood 为应用程序提供了更高级别的抽象，并且它依赖于基于 Paxos 的分布式锁服务。与 Boxwood 一样，ZooKeeper 是用于构建分布式系统的组件。但是，ZooKeeper 具有高性能要求，并且在客户端应用程序中使用得更广泛。ZooKeeper 公开了应用程序用于实现高级基元的较低级别基元。</p><p>ZooKeeper 类似于一个小型文件系统，但它只提供文件系统操作的一小部分，并添加了大多数文件系统中不存在的功能，例如排序保证和条件写入。然而，ZooKeeper watch在思想上与 AFS 的缓存回调相似。</p><p>Sinfonia 引入了迷你事务，这是构建可扩展分布式系统的新范例。 Sinfonia 被设计用来存储应用程序数据，而 ZooKeeper 则存储应用程序元数据。ZooKeeper 将其状态完全复制并保存在内存中，以实现高性能和一致的延迟。我们使用文件系统（如操作和排序）来实现类似于小型事务的功能。znode 是一个方便的抽象，我们在它上面添加了watch，这是 Sinfonia 中缺少的功能。Dynamo 允许客户端获取相对少量（小于 1M）的数据并将其放入分布式键值存储中。与 ZooKeeper 不同，Dynamo 中的密钥空间不是分层的。Dynamo 也不为写入提供强大的持久性和一致性保证，而是解决读取冲突。</p><p>DepSpace 使用元组空间来提供拜占庭容错服务。与 ZooKeeper 一样，DepSpace 使用简单的服务器接口在客户端实现强同步原语。虽然DepSpace的性能远低于ZooKeeper，但它提供了更强的容错性和机密性保证。</p><h2 id="6-总结"><a href="#6-总结" class="headerlink" title="6 总结"></a>6 总结</h2><p>ZooKeeper 通过向客户端公开无等待对象，采用无等待方法来解决分布式系统中的进程协调问题。我们发现 ZooKeeper 对于 Yahoo! 内部和外部的多个应用程序非常有用。ZooKeeper 通过使用watch的快速读取（这两个操作均由本地副本提供服务），为读取为主的工作负载实现了每秒数十万次操作的吞吐量值。尽管我们对读取和监视的一致性保证似乎很弱，但我们已经通过我们的用例表明，这种组合使我们能够在客户端实现高效和复杂的协调协议，即使读取不是优先顺序的，并且数据对象的实现是无等待的。事实证明，无等待属性对于高性能至关重要。</p><p>虽然我们只描述了几个应用程序，但还有许多其他应用程序使用 ZooKeeper。我们相信这样的成功是由于其简单的界面和可以通过这种界面实现的强大抽象。此外，由于 ZooKeeper 的高吞吐量，应用程序可以广泛使用它，而不仅仅是粗粒度锁定。</p>]]></content>
    
    
    <categories>
      
      <category>mit6.824</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式系统</tag>
      
      <tag>mit6.824</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>raft面试</title>
    <link href="/2024/03/24/raft%E9%9D%A2%E8%AF%95/"/>
    <url>/2024/03/24/raft%E9%9D%A2%E8%AF%95/</url>
    
    <content type="html"><![CDATA[<h1 id="口撕Raft"><a href="#口撕Raft" class="headerlink" title="口撕Raft"></a>口撕Raft</h1><h2 id="1-Raft协议什么作用"><a href="#1-Raft协议什么作用" class="headerlink" title="1.Raft协议什么作用"></a>1.Raft协议什么作用</h2><p>Raft是一种分布式一致性算法，主要用于管理分布式系统中的复制日志。其设计的主要目标是易于理解和实现，同时保证系统的一致性和可用性。</p><p>在分布式系统中，由于网络延迟、节点故障等问题，确保所有节点的状态保持一致是一个非常大的挑战。Raft协议就是为了解决这个问题而设计的。</p><ol><li><strong>领导者选举：</strong>在Raft协议中，系统的所有操作都有领导者来进行。当系统启动或者当前的领导者失效时，Raft协议能够通过领导者选举过程来选举出一个新的领导者。</li><li><strong>日志复制：</strong>领导者负责将系统的状态变更（即操作或者事务）以日志条目的形式复制到其它节点。Raft协议保证了所有的日志复制操作都是由领导者来协调的，这大大简化了复制过程。</li><li><strong>保证一致性：</strong>Raft协议通过一系列的机制来保证系统的一致性。无论何时，只要大多数节点都可用，Raft协议都能保证系统的一致性。</li><li><strong>故障恢复：</strong>当一个节点崩溃并重新启动后，Raft协议能够帮助这个节点恢复其状态，重新加入到系统中来。</li></ol><p>总的来说，Raft协议在分布式系统中起到了关键的作用，它使得构建高可用、一致性的分布式系统成为可能。</p><h2 id="2-详细介绍Raft流程"><a href="#2-详细介绍Raft流程" class="headerlink" title="2.详细介绍Raft流程"></a>2.详细介绍Raft流程</h2><ol><li><strong>启动：</strong>当集群启动时，所有的节点都处于跟随者状态。这时，它们等待领导者发送心跳消息</li><li><strong>选举：</strong>如果跟随者在一段时间内（称为选举超时时间）没有收到领导者的心跳消息，它们会认为领导者已经失效，并启动领导者选举。每个跟随者都会自增其任期号，切换到候选人状态，然后向所有其他节点发送请求投票的消息。</li><li><strong>投票：</strong>当一个节点收到请求投票的消息时，如果它没有给别的候选人投过票，并且请求者的任期号不小于自己的任期号，且请求者的日志至少和自己一样新，那么它就会投票给这个请求者。否则，它会拒绝投票。</li><li><strong>当选：</strong>一个候选人如果在一次选举中收到了大多数节点的投票，那么它就成为了新的领导者。然后，它会开始向所有节点发送心跳消息，阻止他们新的选举。</li><li><strong>领导者的工作：</strong>领导者接收到客户端的请求后，将请求作为一个新的日志条目添加到自己的日志中，然后尝试将这个日志条目复制到所有其他节点的日志中。。</li><li><strong>日志复制：</strong>领导者通过心跳消息来复制日志条目。每个心跳消息中都包含了需要复制的日志条目。当一个跟随者收到心跳消息后，它会将其中的日志条目添加到自己的日志中。</li><li><strong>日志提交：</strong>当一个日志条目呗复制到了大多数节点的日志中，领导者就认为这个日志条目已经被提交，然后它会通知所有节点将这个日志条目应用到自己的状态机。</li><li><strong>领导者失效和重新选举：</strong>如果一个领导者失效（崩溃或者网络问题），那么当跟随者超过选举超时时间没有收到领导者的心跳消息时，它们就会开始新的领导者选举。</li><li><strong>安全性：</strong>为了保证系统的一致性，Raft协议在领导者选举和日志复制等过程中加入了一些安全性措施。例如，一个候选人在领导者选举中只有在其日志至少和大多数节点一样新时，才能赢得选举。</li><li><strong>持久化：</strong>节点会定期将自己的信息，比如当前任期号、投票信息、日志条目和快照，持久化到硬盘。这是为了确保即使节点崩溃或者重启，也能从硬盘恢复到最新的状态。</li><li><strong>恢复：</strong>当节点重启时，它首先从硬盘中读取持久化的信息，恢复其任期号、投票信息、日志条目和快照。然后，它会以跟随者的身份开始运行，等待领导者的心跳消息。</li><li><strong>日志压缩：</strong>随着时间的推移，每个节点的日志可能会变得非常大，因此需要进行压缩。这个过程被称为快照，在快照过程中，节点将当前的系统状态（状态机的状态）保存下来，并清除所有已被应用且索引值小于这个状态的日志条目。快照也需要持久化存储，以防节点重启时丢失状态。</li></ol><h3 id="3-follower会响应client的读写操作吗"><a href="#3-follower会响应client的读写操作吗" class="headerlink" title="3.follower会响应client的读写操作吗"></a>3.follower会响应client的读写操作吗</h3><p>在Raft协议中，跟随者节点通常不直接响应客户端的读写请求。所有的读写请求都应该由领导者节点处理。这样设计的主要原因是保持系统的一致性。因为只有领导者节点才能确保它拥有过最新和完整的系统状态。</p><p>对于写请求，客户端的请求首先会被发送到领导者节点，然后领导者把这个更新操作作为一个新的日志条目，然后通过日志复制过程，将这个新的日志条目复制到所有的跟随者节点。只有当大多数节点都写入了这个日志条目，领导者才会认为这个操作已经完成，然后应用这个操作到系统的状态机，并将结果返回给客户端。</p><p>对于读请求，也通常由领导者节点直接处理。因为只有领导者才能确保它的状态是最新的。</p><p>但是也有一些优化的方法可以让跟随者处理读请求，以减轻领导者的负载。一种方法是领导者在响应客户端的读请求之前，首先向所有的跟随者发送一条心跳消息，等所有的跟随者都恢复后，再响应客户端的读请求。这样可以确保跟随者的状态和领导者是一致的。然后跟随者就可以直接响应来自客户端的读请求。</p><h2 id="4-超过半数的决策机制如何保证leader日志的完整性"><a href="#4-超过半数的决策机制如何保证leader日志的完整性" class="headerlink" title="4.超过半数的决策机制如何保证leader日志的完整性"></a>4.超过半数的决策机制如何保证leader日志的完整性</h2><p>在Raft协议中，领导者维护的日志的完整性通过多数投票机制进行保障。这主要体现在两个方面：</p><ol><li>领导者选举：在选举新的领导者时，只有当候选人的日志至少和大部分节点的日志一样新，它才能得到足够多的票数称为领导者。这就确保了新领导者的日志中包含了所有已经提交的日志项。</li><li>日志复制：领导者在接收到客户端的命令后，将命令作为新的日志项添加到其日志中，然后尝试将这个日志项复制到其他的跟随者节点。一旦这个日志项被复制到大多数的服务器上，它就被认为时已经提交的。领导者会将已提交的日志项应用到状态机，然后客户端返回结果。</li></ol><p>通过这样的方式，超过半数的决策机制确保了领导者日志的完整性，确保了在领导者发生更换的时候，新的领导者的日志包含了所有已经提交的日志项，从而避免了数据丢失。同时，只有当一个日志项被大多数的服务器复制，它才被认为时已经提交的，这样就能确保数据的一致性。</p><h2 id="5-为什么使用log，不直接写入状态机"><a href="#5-为什么使用log，不直接写入状态机" class="headerlink" title="5.为什么使用log，不直接写入状态机"></a>5.为什么使用log，不直接写入状态机</h2><ol><li>Raft系统之所以对log关注这么多的一个原因时，log时leader用来对操作排序的一种手段。这对复制状态机而言至关重要，对于这些复制状态机来说，所有副本不仅要执行相同的操作，还需要用相同的顺序执行这些操作。而log与其他很多事物，共同构成了Leader对接收到的客户端操作分配顺序的机制。比如说，我由10个客户端同时向Leader发出请求，Leader必须对这些请求确定一个顺序，并确保所有其他的副本都遵从这个顺序。实际上，log时一些按照数字编号的槽位，槽位的数字表示了leader选择的顺序。</li><li>Log的另一个用途是，在一个副本收到了操作，但是还没有执行操作时。该副本需要将这个操作存放在某处，直到收到了Leader发送的新的commit号才执行。所以，对于Raft的Follower来说，Log时用来存放临时操作的地方。Follower收到了这些临时的操作，但是还不确定这些操作是否被commit了。我们将会看到，这些操作可能会被抛弃。</li><li>Log的另一个用途是用在Leader节点，我（Robert教授）很喜欢这个特性。Leader需要在它的Log中记录操作，因为这些操作可能需要重传给Follower。如果一些Follower由于网络原因或者其他原因短时间离线了或者丢了一些消息，Leader需要能够向Follower重传丢失的Log消息。所以，Leader也需要一个地方来存放客户端请求的拷贝。即使对那些已经commit的请求，为了能够向丢失了相应操作的副本重传，也需要存储在Leader的Log中。</li><li>所有节点都需要保存Log还有一个原因，就是它可以帮助重启的服务器恢复状态。你可能的确需要一个故障了的服务器在修复后，能重新加入到Raft集群，要不然你就永远少了一个服务器。比如对于一个3节点的集群来说，如果一个节点故障重启之后不能自动加入，那么当前系统只剩2个节点，那将不能再承受任何故障，所以我们需要能够重新并入故障重启了的服务器。对于一个重启的服务器来说，会使用存储在磁盘中的Log。每个Raft节点都需要将Log写入到它的磁盘中，这样它故障重启之后，Log还能保留。而这个Log会被Raft节点用来从头执行其中的操作进而重建故障前的状态，并继续以这个状态运行。所以，Log也会被用来持久化存储操作，服务器可以依赖这些操作来恢复状态。</li></ol><h2 id="6-如何解决split-vote的问题"><a href="#6-如何解决split-vote的问题" class="headerlink" title="6.如何解决split vote的问题"></a>6.如何解决split vote的问题</h2><p>分票(split vote): 这是一个选举问题，在Raft等一致性协议中可能会遇到。当一个集群中没有一个节点能够得到大多数节点的选票，从而无法选举出新的领导者时，我们就称之为发生了分票。这通常是由于网络延迟，节点启动时间不一致或者其他原因导致的。</p><ol><li>随机选举超时时间</li><li>选举失败后的重新选举</li><li>票的限制性投票</li></ol><h2 id="7-Paxos"><a href="#7-Paxos" class="headerlink" title="7.Paxos"></a>7.Paxos</h2><p>Paxos协议是基于消息传递的，并且有三种角色：proposers（提议者），acceptors（接受者）和learners（学习者）。一个节点可以扮演这三种角色中的一个或多个。</p><ol><li>Proposers：提议者提出一个提议，这个提议包含了一个提议编号（N）和一个值（V）。提议者首先发送一个请求，请求在一组接受者中获得对提议编号N的承诺。如果提议者从大多数接受者那里受到了承诺，那么它就可以向这些接受者发送一个新请求，要求它们接受提议（N，V）。</li><li>Acceptors：接受者是Paxos协议中的主要角色。一个接受者可以接受多个提议者的建议。但是，一旦它已经对某个提议编号N做出了承诺，就不能再接受任何编号小于N的提议。</li><li>Learners:学习者角色是用来学习呗接受者接受的提议。再大多数的Paxos应用中，每个节点都充当了学习者的角色，这个每个节点都能了解到被接受的提议。</li></ol><p>虽然Paxos协议在理论上是一个很好的解决一致性问题的方法， 但是在实际中并不常用。这是因为它的原始版本相当复杂，难以理解和实现。此外，它不支持更复杂的功能，如集群成员管理和日志复制等。因此，许多系统采用了Paxos的变体或其他替代方案，如Raft协议等</p><p>Paxos算法流程可分为两个阶段，即准备和提议阶段</p><p>1.准备阶段：</p><ul><li>提议者选择一个提议编号N，并将准备请求发送给接受者群体中的大多数或全部节点，该请求包含提议编号N。</li><li>接受者收到准备请求后，如果此请求的提议编号N大于该接受者已经恢复过的所有准备请求的编号，那么该接受者承诺不再接受任何编号小于N的提议，并将自己上一次接受的提议回复给提议者。</li></ul><p>2.提议阶段</p><ul><li>提议者如果收到了大多数接受者的回复，那么就会开始第二阶段，发送接受请求给大多数或全部接受者。该请求包含提议编号N和一个值V，如果提议者收到的回复中有接受者已接受的提议，那么该值V应该是所有回复中编号最大的已接受提议的值，否则V可以是提议者自己决定的值。</li><li>接受者收到接受请求后，如果此请求的提议编号N不小于该接受者已经回复过的所有准备请求的编号，那么接受者就接受这个提议，即该提议称为接受者接受的提议。</li></ul><p>Paxos算法的基本思想是只要有一个提议被大多数接受者接受，那么该提议的值就被决定下来。但在实际过程中可能存在多个提议者同时提交提议的情况，因此可能出现一个值被确定后，仍有提议者不知情而继续提交新的提议，所以这个算法要确保任何新的提议的值必须等于已经被决定的值，这就需要接受者做出承诺，不再接受编号小于N的任何提议，确保已决定的值不会被更改。</p>]]></content>
    
    
    <categories>
      
      <category>mit6.824</category>
      
    </categories>
    
    
    <tags>
      
      <tag>raft</tag>
      
      <tag>分布式算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>GFS</title>
    <link href="/2024/03/23/GFS/"/>
    <url>/2024/03/23/GFS/</url>
    
    <content type="html"><![CDATA[<h1 id="GFS"><a href="#GFS" class="headerlink" title="GFS"></a>GFS</h1><h2 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h2><p>我们设计并实现了google文件系统，这是一个可扩展的分布式文件系统，适用于大型分布式数据密集型应用程序。它在廉价的商用硬件上运行时提供容错性，并为大量客户机提供高聚合性能。</p><p>虽然与以前的分布式文件系统有许多相同的目标，但我们的设计是由对应用程序工作负载和技术环境的观察(包括当前的和预期的)驱动的，这反映了与早期文件系统假设的明显背离。这促使我们重新审视传统的选择，并探索完全不同的设计要点。</p><p>文件系统已成功满足我们的存储需求。它在谷歌内部被广泛部署为存储平台，用于生成和处理我们的服务所使用的数据，以及需要大量数据集的研究和开发工作。迄今为止最大的集群在1000多台机器上的数千个磁盘上提供了数百tb的存储，并且可以由数百个客户机并发访问。</p><p>在本文中，我们介绍了为支持分布式应用程序而设计的文件系统接口扩展，讨论了我们设计的许多方面，并报告了来自微基准测试和实际使用的测量结果。</p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>我们设计并实现了谷歌文件系统(GFS)，以满足谷歌快速增长的数据处理需求。GFS与以前的分布式文件系统有许多相同的目标，比如性能、可伸缩性、可靠性和可用性。然而，它的设计是由我们的应用程序工作负载和技术环境的关键观察驱动的，包括当前的和预期的，这反映了与早期一些文件系统设计假设的明显背离。我们重新审视了传统的选择，并在设计空间中探索了截然不同的观点。</p><p>首先，组件故障是常态，而不是例外。文件系统由数百甚至数千台存储机器组成，这些存储机器由廉价的商品部件组成，并由相当数量的客户机访问。组件的数量和质量实际上保证了一些组件在任何给定的时间都不能正常工作，一些组件将无法从当前的故障中恢复。我们已经看到了由应用程序错误、操作系统错误、人为错误以及磁盘、内存、连接器、网络和电源故障引起的问题。因此，持续监控、错误检测、容错和自动恢复必须是系统的组成部分。</p><p>其次，按照传统标准，文件是巨大的。多gb文件很常见。每个文件通常包含许多应用程序对象，例如web文档。当我们经常处理由数十亿个对象组成的tb级快速增长的数据集时，管理数十亿个接近kb大小的文件是非常笨拙的，即使文件系统可以支持它。因此，必须重新考虑设计假设和参数，例如I&#x2F;O操作和块大小。</p><p>第三，大多数文件都是通过附加新数据而不是覆盖现有数据来改变的。在文件中随机写实际上是不存在的。一旦写入，文件就只能被读取，而且通常只能按顺序读取。各种数据都具有这些特征。有些可能构成数据分析程序扫描的更大的存储库。有些可能是由运行的应用程序不断生成的数据流。有些可能是档案资料。有些可能是在一台机器上产生的中间结果，在另一台机器上处理，无论是同时处理还是稍后处理。考虑到这种对大文件的访问模式，追加成为性能优化和原子性保证的重点。而在客户端缓存数据块就失去了吸引力。</p><p>第四，共同设计应用程序和文件系统API通过增加我们的灵活性使整个系统受益。例如，我们放宽了GFS的一致性模型，以极大地简化文件系统，而不会给应用程序带来繁重的负担。我们还引入了原子追加操作，以便多个客户机可以并发地追加到一个文件，而无需在它们之间进行额外的同步。这些将在本文后面进行更详细的讨论。</p><p>目前部署了多个GFS集群用于不同的目的。最大的数据库有超过1000个存储节点，超过300 TB的磁盘存储，并且在不同的机器上有数百个客户端连续地大量访问。</p><h2 id="设计概况"><a href="#设计概况" class="headerlink" title="设计概况"></a>设计概况</h2><h3 id="假设"><a href="#假设" class="headerlink" title="假设"></a>假设</h3><p>在为我们的需求设计文件系统的过程中，我们一直受到既有挑战又有机会的假设的指导。我们之前提到了一些关键的观察结果，现在更详细地列出我们的假设。</p><ul><li>该系统是由许多经常失效的廉价商品组件构建而成的。它必须不断地监控自身，并在常规基础上检测、容忍组件故障，并迅速从组件故障中恢复。</li><li>系统存储少量的大文件。我们期望有几百万个文件，每个文件的大小通常为100mb或更大。多gb文件是常见的情况，应该有效地管理。必须支持小文件，但我们不需要针对它们进行优化。</li><li>工作负载主要包括两种类型的读:大的流读和小的随机读。在大型流读取中，单个操作通常读取数百kb，更常见的是1mb或更多。来自同一客户机的连续操作通常读取文件的连续区域。一个小的随机读取通常以一些任意偏移量读取几个kb。注重性能的应用程序通常对它们的小读取进行批处理和排序，以便在文件中稳定地前进，而不是来回移动。</li><li>这些工作负载还有许多大的、顺序的写操作，将数据附加到文件中。典型的操作大小与读操作大小相似。一旦写入，文件就很少再被修改。支持在文件中的任意位置进行小的写操作，但不一定要高效。</li><li>系统必须有效地为并发追加到同一文件的多个客户端实现定义良好的语义。我们的文件通常用作生产者-消费者队列或用于多路合并。数百个生产者，每台机器运行一个，将并发地附加到一个文件。具有最小同步开销的原子性是必不可少的。该文件可以稍后读取，或者消费者可以同时读取该文件。</li><li>高持续带宽比低延迟更重要。我们的大多数目标应用程序都非常重视以高速率批量处理数据，而很少有对单个读或写有严格的响应时间要求。</li></ul><h3 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h3><p>GFS提供了一个熟悉的文件系统接口，尽管它没有实现像POSIX这样的标准API。文件在目录中按层次结构组织，并由路径名标识。我们支持创建、删除、打开、关闭、读取、写入文件等常用操作</p><p>此外，GFS还具有快照和记录追加操作。快照以较低的成本创建文件或目录树的副本。记录追加允许多个客户端并发地将数据追加到同一个文件，同时保证每个客户端追加的原子性。这对于实现多路合并结果和生产者-消费者队列非常有用，因为许多客户机可以在不附加锁定的情况下同时挂起它们。我们发现这些类型的文件在构建大型分布式应用程序时是无价的。快照和记录追加将分别在3.4节和3.3节中进一步讨论。</p><h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p>一个GFS文件系统是由多个块服务器和多个主服务器组成，并由多个客户端访问，如图1所示。这些机器通常都是运行用户级服务器进程的普通Linux机器。在同一台机器上同时运行chunkserver和客户机是很容易的，只要机器资源允许，并且运行可能不可靠的应用程序代码所导致的较低的可靠性是可以接受的。</p><p><img src="/../imgs/GFS/image-20240323170452675.png" alt="图1：GFS架构"></p><p>文件被分成固定大小的块。它由一个不可变的、全局唯一的64位块句柄来标识，这个句柄是在创建块时由主机分配的。chunkserver将块以Linux文件的形式存储在本地磁盘上，并通过块句柄和字节范围指定读取或写入块数据。为了提高可靠性，每个块都在多个块服务器上复制。默认情况下，我们存储三个副本，不过用户可以为文件名称空间的不同区域指定不同的复制级别。</p><p>主服务器维护所有文件系统元数据。这包括名称空间、访问控制信息、从文件到块的映射以及块的当前位置。它还控制系统范围的活动，如块租赁管理、孤立块的垃圾收集和块服务器之间的块迁移。主服务器定期与HeartBeat消息中的每个chunkserver通信，向其提供指令并收集其状态。</p><p>链接到每个应用程序中的GFS客户端代码实现文件系统API，并与主服务器和块服务器通信，以代表应用程序读取或写入数据。客户端与主服务器交互进行元数据操作，但所有承载数据的通信都直接到chunkserver。我们不提供POSIX API，因此不需要挂钩到Linux vnode层。</p><p>客户端和chunkserver都不缓存文件数据。客户机缓存提供的好处很少，因为大多数应用程序都要处理巨大的文件，或者工作集太大而无法缓存。没有它们可以通过消除缓存一致性问题来简化客户端和整个系统。(不过，客户端确实会缓存元数据。)chunkserver不需要缓存文件数据，因为块存储为本地文件，因此Linux的缓冲区缓存已经将频繁访问的数据保存在内存中。</p><h3 id="单个master"><a href="#单个master" class="headerlink" title="单个master"></a>单个master</h3><p>拥有单个主节点极大地简化了我们的设计，并使主节点能够使用全局知识做出复杂的块放置和复制决策。然而，我们必须尽量减少它对读写的参与，这样它才不会成为瓶颈。客户端从不通过主服务器读写文件数据。相反，客户端询问主服务器它应该联系哪个块服务器。它将这些信息缓存一段有限的时间，并直接与chunkserver交互以进行许多后续操作。</p><p>让我们参照图1来解释一个简单读取的交互。首先，使用固定的块大小，客户机将应用程序指定的文件名和字节偏移量转换为文件中的块索引。然后，它向主机发送一个包含文件名和块索引的请求。主服务器返回相应的块句柄和副本的位置。客户端使用文件名和块索引作为键来缓存这些信息。</p><p>然后，客户端向其中一个副本(很可能是最近的副本)发送请求。请求指定块句柄和该块中的字节范围。在缓存的信息过期或文件被重新打开之前，对同一块的进一步读取不需要更多的客户机-主交互。实际上，客户端通常在同一个请求中请求多个数据块，而主服务器也可以在被请求的数据块之后立即包含数据块的信息。这些额外的信息避免了未来的几个客户机-主交互，几乎没有额外的成本。</p><h3 id="块大小"><a href="#块大小" class="headerlink" title="块大小"></a>块大小</h3><p>块大小是关键的设计参数之一。我们选择64 MB，这比典型的文件系统块大小大得多。每个块副本以普通Linux文件的形式存储在chunkserver上，仅在需要时进行扩展。惰性空间分配避免了由于内部碎片而造成的空间浪费，这可能是对这种方法最大的反对意见</p><p>大块大小提供了几个重要的优势。首先，它减少了客户端与主服务器交互的需要，因为对同一块进行读写只需要向主服务器发出一次初始请求以获取块位置信息。这种减少对于我们的工作负载来说尤其重要，因为应用程序大多是顺序地读取和写入大量数据。即使是小的随机读取，客户端也可以轻松地缓存所有的块位置信息为多TB的工作集。其次，由于在较大的块上，客户端更有可能在给定的块上执行许多操作，因此可以通过在较长时间内保持与块服务器的持久TCP连接来减少网络开销。第三，它减少了存储在主服务器上的元数据的大小。这允许我们将元数据保存在内存中，这反过来又带来了其他优势，我们将在第2.6.1节中讨论。</p><p>另一方面，大块大小(即使使用惰性空间分配)也有其缺点。小文件由少量块组成，可能只有一个块。如果许多客户端访问同一个文件，存储这些块的块服务器可能会成为热点。在实践中，热点并不是一个主要问题，因为我们的应用程序大多是按顺序读取大的多块文件</p><p>然而，当批处理队列系统首次使用GFS时，热点确实出现了:可执行文件作为单个块文件写入GFS，然后同时在数百台机器上启动。存储此可执行文件的几个块服务器由于数百个同时请求而超载。我们通过使用更高的复制因子来存储这些可执行文件，并通过使批处理队列系统错开应用程序启动时间来解决这个问题。一个潜在的长期解决方案是允许客户机在这种情况下从其他客户机读取数据。</p><h3 id="元数据"><a href="#元数据" class="headerlink" title="元数据"></a>元数据</h3><p>master存储三种主要类型的元数据:文件和块名称空间、从文件到块的映射以及每个块副本的位置。所有元数据都保存在主机内存中。前两种类型(名称空间和文件到块映射)也通过将变化记录到存储在主机本地磁盘上的操作日志并在远程机器上复制来保持持久化。使用日志允许我们简单、可靠地更新主状态，并且在主崩溃时不会冒不一致的风险。主服务器不持久化存储块位置信息。相反，它会在主启动时询问每个chunkserver有关其chunks的信息，以及每当一个chunkserver加入集群时。</p><h4 id="内存数据结构"><a href="#内存数据结构" class="headerlink" title="内存数据结构"></a>内存数据结构</h4><p>由于元数据存储在内存中，所以主操作速度很快。此外，主服务器可以在后台周期性地扫描其整个状态，这既简单又有效。这种周期性扫描用于实现块垃圾收集、出现chunkserver故障时的重新复制以及块迁移，以平衡chunkserver之间的负载和磁盘空间使用。第4.3节和4.4节将进一步讨论这些活动</p><p>这种只使用内存的方法的一个潜在问题是，块的数量以及整个系统的容量受到主服务器拥有多少内存的限制。这在实践中并不是一个严重的限制。master为每个64mb的块维护少于64字节的元数据。大多数块都是满的，因为大多数文件包含许多块，只有最后一个块可能被部分填充。类似地，文件名称空间数据通常需要每个文件少于64字节，因为它使用前缀压缩紧凑地存储文件名。</p><p>如果有必要支持更大的文件系统，向主服务器添加额外内存的成本与将元数据存储在内存中所获得的简单性、可靠性、性能和灵活性相比是微不足道的。</p><h4 id="块位置"><a href="#块位置" class="headerlink" title="块位置"></a>块位置</h4><p>主服务器不会持久记录哪些块服务器拥有给定块的副本。它只是在启动时轮询块服务器以获取该信息。此后，主服务器可以使自己保持最新状态，因为它控制所有块的放置，并使用常规的HeartBeat消息监视块服务器状态</p><p>我们最初试图将块位置信息持久地保存在主服务器上，但我们认为在启动时从chunkserver请求数据要简单得多，之后定期请求数据。这消除了在chunkserver加入和离开集群、更改名称、失败、重新启动等过程中保持主服务器和chunkserver同步的问题。在拥有数百台服务器的集群中，这些事件经常发生。</p><p>理解这种设计决策的另一种方法是认识到，chunkserver对它自己的磁盘上有什么块或没有什么块拥有最终决定权。试图在主服务器上维护这些信息的一致视图是没有意义的，因为chunkserver上的错误可能会导致块自动消失(例如，磁盘可能坏掉并被禁用)，或者操作员可能会重命名chunkserver</p><h4 id="操作日志"><a href="#操作日志" class="headerlink" title="操作日志"></a>操作日志</h4><p>操作日志记录了元数据重大变更的历史记录。这是GFS的核心。它不仅是元数据的唯一持久记录，而且还用作定义并发操作顺序的逻辑时间线。文件和块，以及它们的版本(参见第4.5节)，都是由它们被创建时的逻辑时间唯一且永久地标识的。</p><p>由于操作日志是至关重要的，我们必须可靠地存储它，并且在元数据更改持久化之前，不让更改对客户机可见。否则，即使块本身幸存下来，我们也会有效地丢失整个文件系统或最近的客户端操作。因此，我们在多台远程机器上复制它，并且只有在本地和远程将相应的日志记录刷新到磁盘之后才响应客户机操作。主服务器在刷新之前将多个日志记录批处理在一起，从而减少刷新和复制对整个系统吞吐量的影响</p><p>主服务器通过回放操作日志恢复文件系统状态。为了最小化启动时间，我们必须保持日志较小。每当日志增长超过一定大小时，主服务器就会检查其状态，以便通过从本地磁盘加载最新的检查点并在此之后仅重播有限数量的日志记录来进行恢复。检查点采用类似b树的紧凑形式，可以直接映射到内存中，并用于名称空间查找，而无需进行额外的解析。这进一步加快了恢复速度并提高了可用性。</p><p>因为构建检查点可能需要一段时间，所以master的内部状态是这样构建的，即可以创建新的检查点，而不会延迟传入的突变。主服务器切换到新的日志文件，并在一个单独的线程中创建新的检查点。新的检查点包括转换前的所有突变。对于拥有几百万个文件的集群，可以在一分钟左右的时间内创建它。完成后，将其写入本地和远程磁盘。</p><p>恢复只需要最新的完整检查点和后续的日志文件。旧的检查点和日志文件可以自由删除，但我们保留了一些以防止灾难。检查点期间的失败不会影响正确性，因为恢复代码会检测并跳过不完整的检查点。</p><h3 id="一致性模型"><a href="#一致性模型" class="headerlink" title="一致性模型"></a>一致性模型</h3><p>GFS有一个宽松的一致性模型，可以很好地支持我们的高度分布式应用程序，但实现起来仍然相对简单和高效。现在我们讨论GFS的保证以及它们对应用程序的意义。我们还强调了GFS如何维持这些保证，但将细节留给本文的其他部分。</p><h4 id="GFS担保"><a href="#GFS担保" class="headerlink" title="GFS担保"></a>GFS担保</h4><p>文件名称空间的变化(例如，文件创建)是原子性的。命名空间锁定保证原子性和正确性(章节4.1);主操作日志定义了这些操作的全局总顺序(章节2.6.3)。</p><p>数据突变后文件区域的状态取决于突变的类型、成功还是失败以及是否存在并发突变。表1总结了结果。如果所有客户端总是看到相同的数据，无论他们从哪个副本读取，那么文件区域就是一致的。如果一个文件数据突变是一致的，那么在它之后定义一个区域，并且客户端将看到整个突变所写的内容。当一个突变成功而不受并发写入器的干扰时，受影响的区域就被定义了(并且暗示是一致的):所有客户端都将始终看到突变所写的内容。并发成功的突变使区域未定义，但保持一致:所有客户端都看到相同的数据，但它可能不反映任何一个突变所写的内容。通常，它由来自多个突变的混合片段组成。失败的突变使区域不一致(因此也是未定义的):不同的客户端可能在不同的时间看到不同的数据。我们将在下面描述应用程序如何区分已定义的区域和未定义的区域。应用程序不需要进一步区分不同类型的未定义区域。</p><p><img src="/../imgs/GFS/image-20240323172113185.png" alt="表1"></p><p>数据变化可能是写入或追加记录。写操作导致在应用程序指定的文件偏移量处写入数据。记录追加导致数据(“记录”)至少自动追加一次，即使在并发突变存在的情况下，但在GFS选择的偏移量(3.3节)。(相反，“常规”追加只是在客户端认为是文件当前结束的偏移量处进行写操作。)偏移量返回给客户端，并标记包含该记录的已定义区域的开始。此外，GFS可以在两者之间插入填充或记录重复。它们占用的区域被认为是不一致的，并且通常与用户数据量相比显得微不足道。</p><p>在一系列成功的突变之后，保证被突变的文件区域被定义，并包含由最后一次突变写入的数据。GFS通过(a)在其所有副本上以相同的顺序对块应用突变(章节3.1)，以及(b)使用块版本号来检测任何由于在其chunkserver关闭时错过突变而变得过时的副本(章节4.5)来实现这一点。失效副本将永远不会涉及到突变，也不会给客户端请求主服务器的块位置。他们是垃圾收集在最早的机会。</p><p>由于客户端缓存块位置，因此它们可能会在更新该信息之前从过时的副本中读取数据。该窗口受缓存项超时和下次打开文件的限制，该文件将从缓存中清除该文件的所有块信息。此外，由于我们的大多数文件都是仅追加的，过期的副本通常返回块的过早结束，而不是过时的数据。当读取器重新尝试并联系主服务器时，它将立即获得当前块的位置。</p><p>在成功的突变之后很长一段时间，组件故障当然仍然会损坏或破坏数据。GFS通过主服务器和所有chunkserver之间的定期握手来识别故障的chunkserver，并通过校验和来检测数据损坏(章节5.2)。一旦问题出现，数据会尽快从有效的副本中恢复(章节4.3)。只有在GFS做出反应之前(通常在几分钟内)所有副本都丢失时，块才会不可逆转地丢失。即使在这种情况下，它也变得不可用，而不是损坏:应用程序接收到明显的错误，而不是损坏的数据。</p><h4 id="对应用的影响"><a href="#对应用的影响" class="headerlink" title="对应用的影响"></a>对应用的影响</h4><p>GFS应用程序可以使用一些其他用途已经需要的简单技术来适应宽松的一致性模型:依赖追加而不是覆盖、检查点和编写自我验证、自我识别的记录。</p><p>实际上，我们所有的应用程序都是通过追加而不是覆盖来改变文件的。在一种典型的用法中，编写器从头到尾生成一个文件。它在写入所有数据后自动将文件重命名为永久名称，或者定期检查成功写入了多少数据。检查点还可能包括应用程序级别的校验和。读取器只验证和处理文件区域，直到最后一个检查点，该检查点已知处于定义状态。不考虑一致性和并发性问题，这种方法对我们很有帮助。对于应用程序故障，追加操作比随机写操作更有效，更有弹性。检查点允许写入器以增量方式重新启动，并防止读取器处理从应用程序的角度来看仍然不完整的已成功写入的文件数据。</p><p>在另一种典型使用中，许多写入器并发地挂起到一个文件，用于合并结果或作为生产者-消费者队列。Record append的“至少追加一次”语义保留了每个写入器的输出。读者按如下方式处理偶尔出现的填充和重复。编写者准备的每条记录都包含额外的信息，如校验和，以便验证其有效性。阅读器可以使用校验和识别并丢弃多余的填充和记录片段。如果它不能容忍偶尔的重复(例如，如果它们会触发非幂等操作)，它可以使用记录中的唯一标识符将它们过滤掉，这通常需要为相应的应用程序实体(如web文档)命名。这些记录I&#x2F;O的功能(除去重复)是在我们的应用程序共享的库代码中，并适用于Google的其他文件接口实现。这样，相同的记录序列，加上很少的重复，总是传递给记录读取器。</p><h2 id="系统交互"><a href="#系统交互" class="headerlink" title="系统交互"></a>系统交互</h2><p>我们设计这个系统是为了尽量减少master对所有操作的参与。在此背景下，我们现在描述客户端、主服务器和块服务器如何交互以实现数据突变、原子记录追加和快照。</p><h3 id="租约和突变顺序"><a href="#租约和突变顺序" class="headerlink" title="租约和突变顺序"></a>租约和突变顺序</h3><p>突变是一种改变数据块内容或元数据的操作，例如写操作或追加操作。每个突变都在所有块的副本上执行。我们使用租约来维护跨副本的一致的突变顺序。主服务器将块租期授予其中一个副本，我们称之为主服务器。主节点为数据块的所有突变选择一个serialorder。当应用突变时，所有副本都遵循这个顺序。因此，全局mutationorder首先由master选择的租期授予顺序定义，在租期内由primary分配的序列号定义。</p><p>租期机制的设计目的是最小化主服务器上的管理开销。租约的初始超时为60秒。但是，只要数据块被修改，主服务器就可以无限期地请求和接收主服务器的扩展。这些扩展请求和授予承载在主服务器和所有块服务器之间定期交换的HeartBeat消息上。有时，主服务器可能会尝试在租约到期之前撤销租约(例如，当主服务器想要禁用正在重命名的文件的突变时)。即使主服务器失去了与主服务器的通信，它也可以在旧租约到期后安全地将新租约授予另一个副本。</p><p>在图2中，我们通过这些编号的步骤，遵循写操作的控制流来说明这个过程。</p><p><img src="/../imgs/GFS/image-20240323174142569.png" alt="图2"></p><ol><li>客户端询问主服务器哪个chunkserver持有该块的当前租约以及其他副本的位置。如果没有人拥有租约，主服务器就会将租约授予它选择的副本(未显示)。</li><li>主服务器返回主服务器的身份和其他(辅助)副本的位置。客户端缓存这些数据以备将来发生变化。只有当主服务器无法访问或回复它不再持有租约时，它才需要再次与主服务器联系</li><li>客户端将数据推送到所有副本。客户端可以以任何顺序执行此操作。每个chunkserver将数据存储在内部LRU缓冲区缓存中，直到数据被使用或老化。通过将数据流与控制流解耦，我们可以根据网络拓扑来调度昂贵的数据流，而不管哪个chunkserver是主服务器，从而提高性能。第3.2节进一步讨论了这一点。</li><li>一旦所有副本都确认接收到数据，客户机就向主服务器发送写请求。请求标识早先推送到所有副本的数据。主服务器为它接收到的所有突变(可能来自多个客户机)分配连续的序列号，这提供了必要的序列化。它按序列号顺序将突变应用到自己的局部状态。</li><li>主服务器将写请求转发给所有从服务器副本。每个次要副本按照主副本分配的相同序列号顺序应用突变。</li><li>次要服务器都回复主服务器，表明它们已完成操作。</li><li>主服务器响应客户端。在任何副本上遇到的任何错误都会报告给客户端。如果出现错误，则可能在主副本和辅助副本的任意子集上写操作成功。(如果它在主服务器上失败了，它就不会被分配序列号并转发。)客户端请求被认为失败，修改后的区域处于不一致状态。我们的客户端代码通过重新尝试失败的突变来处理此类错误。它将在步骤(3)到步骤(7)上进行一些尝试，然后从写入的开始重新尝试。</li></ol><p>如果应用程序的写操作很大或跨越块边界，GFS客户机代码将其分解为多个写操作。它们都遵循上面描述的控制流，但可能与来自其他客户机的并发操作交叉或覆盖。因此，共享文件区域最终可能包含来自不同客户端的片段，尽管副本将是相同的，因为在所有副本上以相同的顺序成功完成了单个操作。这使得文件区域处于一致但未定义的状态，如2.7节所述。</p><h3 id="数据流"><a href="#数据流" class="headerlink" title="数据流"></a>数据流</h3><p>我们将数据流与控制流解耦，以有效地利用网络。当控制从客户机流向主服务器，然后流向所有辅助服务器时，数据以流水线方式沿着精心挑选的块服务器链线性推送。我们的目标是充分利用每台机器的网络带宽，避免网络瓶颈和高延迟链接，并最大限度地减少延迟来推送所有数据。</p><p>为了充分利用每台机器的网络带宽，数据沿着块服务器链线性推送，而不是分布在一些其他拓扑结构中(例如，树)。因此，每台机器的全部出站带宽用于尽可能快地传输数据，而不是在多个接收方之间分配。</p><p>为了尽可能避免网络瓶颈和高延迟链路(例如，交换机间链路通常两者都有)，每台机器将数据转发到网络拓扑中“最近的”尚未接收到数据的机器。假设客户端将数据推送到块服务器S1到S4。它将数据发送到最近的块服务器，比如S1。S1转发到最近的块服务器S2，通过最接近S1的S4，比如S2。同样，S2将其转发给S3或S4，哪个更接近S2，依此类推。我们的网络拓扑结构非常简单，可以从IP地址准确地估计“距离”。</p><p>最后，我们通过在TCP连接上进行数据传输来最小化延迟。一旦chunkserver接收到一些数据，它就立即开始转发。流水线对我们特别有帮助，因为我们使用全双工链路的交换网络。立即发送数据不会降低接收速率。在没有网络拥塞的情况下，将B个字节传输到R个副本的理想耗时是B&#x2F;T + RL，其中T是网络吞吐量，L是两台机器之间传输字节的延迟时间。我们的网络链路通常是100mbps (T)，而L远低于1ms。因此，理想情况下，1mb可以在大约80ms内分配。</p><h3 id="原子记录追加"><a href="#原子记录追加" class="headerlink" title="原子记录追加"></a>原子记录追加</h3><p>GFS提供了一个称为recordappend的原子追加操作。在传统的写操作中，客户端指定要写入数据的偏移量。并发写到同一区域是不可序列化的:该区域可能最终包含来自多个客户端的数据片段。然而，在recordappend中，客户端只指定数据。在GFS选择的偏移量处，它至少自动地将它发送到文件一次(即，作为一个连续的字节序列)，并将该偏移量返回给客户端。这类似于书面。在Unix中，当多个写入器并发地以0_APPEND模式打开文件时，不存在任何条件。</p><p>记录追加被我们的分布式应用程序大量使用，在这些应用程序中，不同机器上的许多客户端并发地追加同一个文件。如果客户端使用传统的写操作，则需要额外的复杂和昂贵的同步，例如通过分布式锁管理器。在我们的工作负载中，此类文件通常用作多生产者&#x2F;单消费者队列，或者包含来自许多不同客户机的合并结果。</p><p>记录追加是一种变异，它遵循第3.1节中的控制流，只是在主端增加了一点额外的逻辑。客户端将数据推送到文件最后一个块的所有副本，然后将其请求发送到主服务器。主要检查将记录追加到当前块是否会导致块超过最大大小(64 MB)。如果是，它将块填充到最大大小，告诉辅助服务器也这样做，并回复客户端，指示应该在下一个块上重试该操作。(Record append被限制最多为最大块大小的四分之一，以使最坏情况下的碎片保持在可接受的水平。)如果记录符合最大大小(这是常见的情况)，则主服务器将数据附加到其副本，告诉辅助服务器将数据写入它所处的精确偏移位置，并最终向客户端返回成功。</p><p>如果在任何副本上添加记录失败，则客户端会重试该操作。因此，同一块的副本可能包含不同的数据，可能包括相同记录的全部或部分副本。GFS不保证所有副本在字节方面都是相同的。它只保证数据作为一个原子单元至少写入一次。这个属性很容易从一个简单的观察中得出，即为了使操作报告成功，数据必须在某个块的所有副本上以相同的偏移量写入。此外，在此之后，所有副本至少与记录结束一样长，因此任何未来的记录将被分配更高的偏移量或不同的块，即使不同的副本后来成为主副本。就我们的一致性保证而言，成功的记录追加操作写入数据的区域是定义的(因此是一致的)，而中间区域是不一致的(因此是未定义的)。我们的应用程序可以处理不一致的区域，正如我们在2.7.2节中讨论的那样。</p><h3 id="快照"><a href="#快照" class="headerlink" title="快照"></a>快照</h3><p>快照操作几乎是立即生成文件或目录树(“源”)的副本，同时最小化正在进行的更改的任何中断。我们的用户使用它来快速创建庞大数据集的分支副本(通常是这些副本的副本，递归地)，或者在实验可以稍后提交或回滚的更改之前检查当前状态。</p><p>像AFS一样，我们使用标准的写时复制技术来实现快照。当主服务器接收到快照请求时，它首先撤销即将快照的文件中所有未到期的租约。这确保了对这些块的任何后续写操作都需要与主服务器进行交互才能找到租约持有者。这将使主服务器有机会首先创建块的新副本。</p><p>在租约被撤销或过期后，主服务器将操作记录到磁盘。然后，它通过复制源文件或目录树的元数据，将此日志记录应用于其内存状态。新创建的快照文件指向与源文件相同的块。</p><p>在快照操作之后，客户端第一次想要写入块C时，它向主服务器发送一个请求以查找当前的租约持有者。主服务器注意到块C的引用计数大于1。它延迟响应客户端请求，而是选择一个新的块句柄C’。然后，它要求每个拥有当前C副本的chunkserver创建一个名为C ‘的新块。通过在与原始块服务器相同的chunkserver上创建新块，我们可以确保数据可以在本地复制，而不是通过网络复制(我们的磁盘的速度大约是100 Mb以太网链路的三倍)。从这一点来看，请求处理与任何块的处理没有什么不同:主服务器授予其中一个副本对新块C ‘的租约，并回复客户端，客户端可以正常写块，而不知道它刚刚从现有块中创建。</p><h2 id="master操作"><a href="#master操作" class="headerlink" title="master操作"></a>master操作</h2><p>主节点执行所有命名空间操作。此外，它管理整个系统的块副本:它做出放置决策，创建新的块和副本，并协调各种系统范围的活动以保持块完全复制，平衡所有块服务器之间的负载，并回收未使用的存储。我们现在讨论每一个主题。</p><h3 id="命名空间管理和锁"><a href="#命名空间管理和锁" class="headerlink" title="命名空间管理和锁"></a>命名空间管理和锁</h3><p>许多主操作可能需要很长时间:例如，快照操作必须撤销快照覆盖的所有块的chunkserver租约。我们不希望在其他主操作运行时延迟它们。因此，我们允许多个操作处于活动状态，并在名称空间的区域上使用锁来确保正确的序列化。</p><p>与许多传统文件系统不同，GES没有列出该目录中所有文件的每个目录数据结构。它也不支持同一文件或目录的别名(即Unix术语中的硬链接或符号链接)。GFS逻辑上将其命名空间表示为将完整路径名映射到元数据的查找表。通过前缀压缩，这个表可以有效地在内存中表示。命名空间树中的每个节点(绝对文件名或绝对目录名)都有一个关联的读写锁。</p><p>每个主操作在运行前都会获取一组锁。通常，如果它涉及&#x2F;d1&#x2F;d2&#x2F;…&#x2F;dn&#x2F;leaf，它将获取目录名&#x2F;d1， &#x2F;d1&#x2F;d2，…，&#x2F;d1&#x2F;d2&#x2F;…的读锁。&#x2F;dn，并在完整的路径名&#x2F;d1&#x2F;d2&#x2F;…&#x2F;dn&#x2F;leaf上设置读锁或写锁。注意，根据操作的不同，叶子可以是文件或目录。</p><p>现在我们将演示这种锁定机制如何防止在将&#x2F;home&#x2F;user快照到&#x2F;save&#x2F;user时创建&#x2F;home&#x2F;user&#x2F;foo文件。快照操作获取&#x2F;home和&#x2F;save上的读锁，&#x2F;home&#x2F;user和&#x2F;save&#x2F;user上的写锁。文件创建需要在&#x2F;home和&#x2F;home&#x2F;user上获得读锁，在&#x2F;home&#x2F;user&#x2F;foo上获得写锁。这两个操作将被正确序列化，因为它们试图在&#x2F;home&#x2F;user上获得冲突的锁。文件创建不需要在父目录上加写锁，因为没有类似于orinode的“目录”数据结构需要保护以免被修改。名称上的读锁足以保护父目录不被删除。</p><p>这种锁定方案的一个很好的特性是，它允许在同一目录中并发地进行修改。例如，可以在同一目录中并发地执行多个文件创建:每个文件都获得目录名上的读锁和文件名上的写锁。目录名上的读锁足以防止目录被删除、重命名或快照。文件名上的写锁序列化两次创建同名文件的尝试。</p><p>由于名称空间可以有许多节点，因此会惰性地分配读写锁对象，并在不使用时删除它们。此外，锁是按照一致的总顺序获取的，以防止死锁:它们首先在名称空间树中按级别排序，然后在同一级别内按字典顺序排序</p><h3 id="副本放置"><a href="#副本放置" class="headerlink" title="副本放置"></a>副本放置</h3><p>GFS集群在多个级别上高度分布。它通常有数百个块服务器分布在许多机器机架上。这些块服务器反过来可能被来自相同或不同轨道的数百个客户端访问。不同轨道上的两台机器之间的通信可以通过一个或多个网络交换机。此外，进出机架的带宽可能小于机架内所有机器的总带宽。多级分布对数据的可伸缩性、可靠性和可用性提出了独特的挑战。</p><p>块副本放置策略有两个目的:最大限度地提高数据的可靠性和可用性，最大限度地提高网络带宽利用率。对于这两种情况，将副本分散到机器上是不够的，这只能防止磁盘或机器故障，并充分利用每台机器的网络带宽。我们还必须跨机架散布块副本。这确保了即使整个机架损坏或故障(例如，由于网络交换机或电源电路等共享资源的故障)，块的一些副本仍然存在并保持可用。这也意味着数据块的流量，尤其是读取，可以利用多个机架的聚合带宽。另一方面，写流量必须流经多个机架，这是我们愿意做出的权衡。</p><h3 id="创建、重新复制、再平衡"><a href="#创建、重新复制、再平衡" class="headerlink" title="创建、重新复制、再平衡"></a>创建、重新复制、再平衡</h3><p>创建块副本有三个原因:块创建、重新复制和再平衡。</p><p>当主服务器创建一个块时，它选择在哪里放置最初的空副本。它考虑了几个因素:(1)我们希望将新的副本放置在磁盘空间利用率低于平均水平的块服务器上。(2)我们希望限制每个chunkserver上“最近”创建的数量，尽管创建本身很便宜，但它可靠地预测了即将到来的繁重写流量，因为块是在写请求时创建的，而在我们的“附加一次读多次”工作负载中，一旦它们被完全写入，它们通常实际上是只读的。(3)如上所述，我们希望在机架上分散块的副本。</p><p>只要可用副本的数量低于用户指定的目标，主服务器就会重新复制一个块。发生这种情况的原因有很多:块服务器不可用，报告其副本可能损坏，其中一个磁盘因错误而禁用，或者复制目标增加。需要重新复制的每个块都基于几个因素进行优先级排序。一个是它离复制目标有多远。例如，我们给予丢失两个副本的块比只丢失一个副本的块更高的优先级。此外，我们更倾向于首先为活文件重新复制块，而不是属于最近删除的文件的块(参见第4.4节)。最后，为了最小化故障对运行应用程序的影响，我们提高了阻塞客户端进程的任何块的优先级。</p><p>master选择优先级最高的块，并通过指示一些chunkserver直接从现有的有效副本复制块数据来“克隆”它。放置新副本的目标与创建副本的目标类似:均衡磁盘空间利用率，限制任何单个chunkserver上的活动克隆操作，以及跨机架分布副本。为了防止克隆流量压倒客户端流量，主服务器限制了集群和每个块服务器的活动克隆操作的数量。此外，每个chunkserver通过限制对源chunkserver的读请求来限制它在每个克隆操作上花费的带宽量</p><p>最后，主服务器定期重新平衡副本:它检查当前副本分布并移动副本以获得更好的磁盘空间和负载平衡。此外，通过这个过程，主服务器逐渐填满一个新的chunkserver，而不是立即用新的块和随之而来的沉重的写流量淹没它。新副本的放置标准与上面讨论的相似。此外，主服务器还必须选择要删除的现有副本。通常，它倾向于删除空闲空间低于平均水平的块服务器上的那些块服务器，以便均衡磁盘空间使用。</p><h3 id="垃圾回收"><a href="#垃圾回收" class="headerlink" title="垃圾回收"></a>垃圾回收</h3><p>文件删除后，GFS不会立即回收可用的物理存储。它仅在文件和块级别的常规垃圾收集期间惰性地执行此操作。我们发现这种方法使系统更简单，更可靠。</p><h4 id="机制"><a href="#机制" class="headerlink" title="机制"></a>机制</h4><p>当应用程序删除一个文件时，主机会立即记录删除操作，就像其他更改一样。但是，不是立即回收资源，而是将文件重命名为包含删除时间戳的隐藏名称。在主服务器对文件系统名称空间进行常规扫描期间，如果这些隐藏文件存在超过三天(时间间隔是可配置的)，它将删除它们。在此之前，文件仍然可以在新的特殊名称下读取，并且可以通过将其重命名为正常名称来恢复删除。当从名称空间中删除隐藏文件时，将擦除其内存中的元数据。这有效地切断了它与所有块的链接。</p><p>在对块命名空间进行类似的常规扫描时，主服务器会识别孤立的块(即无法从任何文件访问的块)，并擦除这些块的元数据。在与主服务器定期交换的HeartBeat消息中，每个chunkserver报告它拥有的块的一个子集，主服务器用不再出现在主元数据中的所有块的标识进行回复。chunkserver可以自由地删除这些块的副本。</p><h4 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h4><p>尽管分布式垃圾收集是一个难题，在编程语言的上下文中需要复杂的解决方案，但在我们的示例中它非常简单。我们可以很容易地识别所有对块的引用:它们位于由主服务器专门维护的文件到块的映射中。我们也可以很容易地识别所有的块副本:它们是每个块服务器上指定目录下的Linux文件。任何不为主机所知的副本都是“垃圾”。</p><p>与急于删除相比，垃圾收集存储回收方法有几个优点。首先，它在组件故障常见的大规模分布式系统中简单可靠。在一些块服务器上创建块可能会成功，而在其他块服务器上则不能，从而留下主服务器不知道存在的副本。副本删除消息可能会丢失，并且主服务器必须记住在失败时重新发送它们，无论是它自己的还是块服务器的。垃圾收集提供了一种统一且可靠的方式来清理任何已知无用的副本。其次，它将存储回收合并到主服务器的常规后台活动中，例如定期扫描名称-空间和与块服务器的握手。因此，它是分批完成的，成本是平摊的。此外，只有在主人相对自由的情况下才会这样做。对于需要及时关注的客户端请求，主服务器可以更迅速地作出响应。第三，回收存储的延迟提供了一个安全网，防止意外的、不可逆转的删除。</p><p>在我们的经验中，主要的缺点是，当存储空间很紧时，延迟有时会妨碍用户优化使用。重复创建和删除临时文件的应用程序可能无法立即重用存储。如果已删除的文件再次显式删除，我们通过加速存储回收来解决这些问题。我们还允许用户对名称空间的不同部分应用不同的复制和回收策略。例如，用户可以指定在某个目录树中存储文件中的所有块而不进行复制，并且任何被删除的文件将立即且不可撤销地从文件系统状态中删除。</p><h3 id="失效副本检测"><a href="#失效副本检测" class="headerlink" title="失效副本检测"></a>失效副本检测</h3><p>如果块服务器发生故障，并且在它关闭时错过了对块的更改，则块副本可能会过时。对于每个块，主服务器维护一个块版本号，以区分最新副本和过期副本。</p><p>每当主服务器授予一个块的新租约时，它都会增加块的版本号，并通知最新的副本。主服务器和这些副本都在它们的持久状态中记录新的版本号。这发生在任何客户机收到通知之前，因此在它可以开始向块写入之前。如果另一个副本当前不可用，则不会提高其块版本号。当chunkserver重新启动时，主服务器将检测到这个chunkserver有一个过时的副本，并报告它的块集及其相关的版本号。如果主服务器看到的版本号大于其记录中的版本号，则主服务器认为它在授予租约时失败，因此采用较高的版本作为最新版本。</p><p>主服务器在其常规垃圾收集中删除过时的副本。在此之前，当它应答客户端请求块信息时，它有效地认为陈旧的副本根本不存在。作为另一种保护措施，当主服务器通知客户端哪个chunkserver持有某个块的租约，或者在克隆操作中指示一个chunkserver从另一个chunkserver读取该块时，主服务器包含了块的版本号。客户端或块服务器在执行操作时验证版本号，以便始终访问最新的数据。</p><h2 id="容错与诊断"><a href="#容错与诊断" class="headerlink" title="容错与诊断"></a>容错与诊断</h2><p>我们在设计系统时面临的最大挑战之一是处理频繁的组件故障。部件的质量和数量加在一起，使这些问题成为常态，而不是例外:我们不能完全相信机器，也不能完全相信磁盘。组件故障可能导致系统不可用，或者更糟的是数据损坏。我们将讨论如何应对这些挑战，以及我们在系统中内置的工具，以便在不可避免地出现问题时进行诊断。</p><h3 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h3><p>在GFS集群中的数百台服务器中，某些服务器在任何给定时间都不可用。我们通过两种简单而有效的策略来保持整个系统的高可用性:快速恢复和复制</p><h4 id="快速恢复"><a href="#快速恢复" class="headerlink" title="快速恢复"></a>快速恢复</h4><p>主服务器和chunkserver都被设计为重新存储它们的状态并在几秒钟内启动，无论它们如何终止。实际上，我们不区分正常终止和异常终止;服务器通常通过终止进程来关闭。客户机和其他服务器会遇到一个小问题，因为它们会超时处理未完成的请求，重新连接到重新启动的服务器，然后重试。第6.2.2节报告观察到的启动时间。</p><h4 id="块复制"><a href="#块复制" class="headerlink" title="块复制"></a>块复制</h4><p>如前所述，每个块被复制到不同机架上的多个块服务器上。用户可以为文件命名空间的不同部分指定不同的复制级别。默认值是3。当chunkserver脱机或通过校验和验证检测损坏的副本时，主服务器根据需要克隆现有副本以保持每个块的完全复制(参见5.2节)。尽管复制已经为我们提供了很好的服务，但我们正在探索其他形式的跨服务器冗余，例如奇偶校验或擦除码，以满足我们不断增长的只读存储需求。我们预计，在我们非常松散耦合的系统中实现这些更复杂的冗余方案是具有挑战性的，但也是可以管理的，因为我们的流量主要是追加和读取，而不是小的随机写入。</p><h4 id="主节点复制"><a href="#主节点复制" class="headerlink" title="主节点复制"></a>主节点复制</h4><p>复制主状态是为了提高可靠性。它的操作日志和检查点被复制到多台机器上。只有在其日志记录被刷新到本地磁盘和所有主副本上后，才认为状态的突变已提交。为简单起见，一个主进程仍然负责所有的突变以及在内部改变系统的后台活动，如垃圾收集。当它失败时，它几乎可以立即重新启动。如果它的机器或磁盘发生故障，监视GFS外部的基础设施就会在其他地方启动一个新的主进程，并使用复制的操作日志。客户端只使用主服务器的规范名称(例如gfs-test)，这是一个DNS别名，如果主服务器被重新定位到另一台机器上，则可以更改该别名。</p><p>此外，“影子”主服务器提供对文件系统的只读访问，即使主服务器关闭时也是如此。它们是影子，而不是镜子，因为它们可能会稍微落后于主光源，通常是几分之一秒。它们增强了没有主动变化的文件或不介意得到稍微陈旧的结果的应用程序的读可用性。实际上，由于文件内容是从chunkserver读取的，所以应用程序不会观察到过时的文件内容。在短窗口内可能过时的是文件元数据，如目录内容或访问控制信息。</p><p>为了保持自己的信息，一个shadowmaster读取一个不断增长的操作日志的副本，并将相同的更改顺序应用到它的数据结构中，就像primary所做的那样。与主服务器一样，它在启动时轮询块服务器(之后很少轮询)以定位块副本，并与它们频繁交换握手消息以监视它们的状态。它仅在由主服务器决定创建和删除副本而产生的副本位置更新时依赖于主服务器。</p><h3 id="数据完整性"><a href="#数据完整性" class="headerlink" title="数据完整性"></a>数据完整性</h3><p>每个chunkserver使用校验和来检测存储数据的损坏。考虑到GFS集群通常在数百台机器上有数千个磁盘，它经常会遇到磁盘故障，导致读取和写入路径上的数据损坏或丢失。(原因之一见第7节。)我们可以使用其他块副本从损坏中恢复，但是通过比较跨块服务器的副本来检测损坏是不切实际的。此外，不同的副本可能是合法的:GFS突变的语义，特别是前面讨论的原子记录追加，不能保证相同的副本。因此，每个chunkserver必须通过维护校验和来独立地验证其副本的完整性。</p><p>一个块被分成64 KB的块。每个都有一个相应的32位校验和。与其他元数据一样，校验和保存在内存中，并使用日志进行持久存储。与用户数据分离。</p><p>对于读取，chunkserver在返回任何数据给请求者(无论是客户端还是另一个chunkserver)之前，验证与读取范围重叠的数据锁的校验和。因此，块服务器不会将损坏传播到其他机器。如果一个块与recordedchecksum不匹配，chunkserver返回一个错误给requestoland，并将不匹配报告给master。作为响应，请求者将从其他副本读取数据，而主服务器将从另一个副本克隆数据块。在一个有效的newreplica到位之后，master指示报告不匹配的chunkserver删除它的副本。</p><p>校验和对读性能的影响很小，原因如下。由于我们的大多数读取至少跨越几个块，因此我们只需要读取和校验相对少量的额外数据以进行验证。GES客户端代码通过尝试在校验和块边界上对齐读取来进一步减少这种开销。此外，chunkserver上的校验和查找和比较不需要任何io，校验和计算通常可以与io重叠。</p><p>校验和计算在很大程度上优化了附加到块末尾的写操作(而不是覆盖现有数据的写操作)，因为它们在我们的工作负载中占主导地位。我们只是增量地更新最后一个部分校验和块的校验和，并为任何由追加部分填充的全新校验和块计算新的校验和。即使最后的部分校验和块已经损坏，我们现在也无法检测到它，新的校验和值将与存储的数据不匹配，并且在下次读取块时将像往常一样检测到损坏。</p><p>相反，如果写操作覆盖了块的现有范围，我们必须读取并验证被覆盖范围的第一个和最后一个块，然后执行写操作，最后计算并记录新的校验和。如果我们在部分覆盖第一个和最后一个块之前不验证它们，那么新的校验和可能会隐藏存在于未被覆盖的区域中的损坏。</p><p>在空闲期间，chunkserver可以扫描和验证非活动块的内容。这允许我们检测很少被读取的块中的损坏。一旦检测到损坏，主服务器就可以创建一个新的未损坏的副本，并删除损坏的副本。这可以防止不活动但损坏的块副本欺骗主服务器，使其认为它有足够的有效块副本。</p><h3 id="诊断工具"><a href="#诊断工具" class="headerlink" title="诊断工具"></a>诊断工具</h3><p>广泛而详细的诊断日志记录在问题隔离、调试和性能分析方面提供了显著的帮助，同时只产生最小的成本。如果没有日志，就很难理解机器之间短暂的、不可重复的交互。GFS服务器生成诊断日志，这些日志记录了许多重要事件(例如chunkserver上升和下降)以及所有RPC请求和应答。这些诊断日志可以随意删除，不会影响系统的正确性。然而，我们尽量在空间允许的范围内保留这些日志。</p><p>RPC日志包括在网络上发送的准确的请求和响应，但正在读取或写入的文件数据除外。通过将请求与应答进行匹配并整理不同机器上的RPC记录，我们可以重建整个交互历史以诊断问题。日志还可以作为负载测试和性能分析的跟踪。</p><p>日志记录对性能的影响很小(而且远远超过了它的好处)，因为这些日志是按顺序异步写入的。最近的事件也保存在内存中，可用于连续在线监视。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Google文件系统展示了在商品硬件上支持大规模数据处理工作负载所必需的质量。虽然有些设计决策是特定于我们独特的环境，但许多设计决策可能适用于类似规模和成本意识的数据处理任务。</p><p>我们首先根据当前和预期的应用程序工作负载和技术环境重新检查传统的文件系统假设。我们的观察导致了设计空间中完全不同的观点。我们将组件故障视为常态，而不是异常，优化主要追加(可能并发)然后读取(通常顺序)的大文件，扩展和放松标准文件系统接口，以改进整个系统。</p><p>我们的系统通过持续监控、复制关键数据和快速自动恢复提供容错功能。块复制允许我们容忍块服务器故障。这些故障的频率激发了一种新的在线修复机制，该机制定期和透明地修复损坏并尽快补偿丢失的副本。此外，我们使用校验和来检测磁盘或IDE子系统级别的数据损坏，鉴于系统中的磁盘数量，这种情况变得非常常见。</p><p>我们的设计为执行各种任务的许多并发读取器和写入器提供了高聚合吞吐量。我们通过分离文件系统控制(通过主服务器)和数据传输(直接在块服务器和客户端之间传递)来实现这一点。通过较大的块大小和块租约(将权限委托给数据突变中的主副本)，可以最大限度地减少主操作的参与。这使得一个简单的、集中式的主机不会成为瓶颈成为可能。我们相信，网络堆栈的改进将解除当前对单个客户端看到的写吞吐量的限制。</p><p>GFS已经成功地满足了我们的存储需求，并在Google内部广泛用作研发和生产数据处理的存储平台。它是一个重要的工具，使我们能够继续创新，并在整个网络的规模上解决问题。</p>]]></content>
    
    
    <categories>
      
      <category>mit6.824</category>
      
    </categories>
    
    
    <tags>
      
      <tag>6.824</tag>
      
      <tag>分布式系统</tag>
      
      <tag>data storage</tag>
      
      <tag>容错</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>21st-March</title>
    <link href="/2024/03/21/21st-March/"/>
    <url>/2024/03/21/21st-March/</url>
    
    <content type="html"><![CDATA[<h1 id="滴滴面经"><a href="#滴滴面经" class="headerlink" title="滴滴面经"></a>滴滴面经</h1><h2 id="计网"><a href="#计网" class="headerlink" title="计网"></a>计网</h2><h3 id="键入网址到网页显示，期间发生了什么？"><a href="#键入网址到网页显示，期间发生了什么？" class="headerlink" title="键入网址到网页显示，期间发生了什么？"></a>键入网址到网页显示，期间发生了什么？</h3><h4 id="1-HTTP"><a href="#1-HTTP" class="headerlink" title="1.HTTP"></a>1.HTTP</h4><p>浏览器做的第一步工作就是解析URL</p><p><img src="/../imgs/21st-March/3.jpg" alt="URL 解析"></p><p>所以图中的长长的 URL 实际上是请求服务器里的文件资源。</p><p>对 <code>URL</code> 进行解析之后，浏览器确定了 Web 服务器和文件名，接下来就是根据这些信息来生成 HTTP 请求消息了。</p><p><img src="/../imgs/21st-March/4.jpg" alt="HTTP 的消息格式"></p><h4 id="2-DNS"><a href="#2-DNS" class="headerlink" title="2.DNS"></a>2.DNS</h4><p>通过浏览器解析 URL 并生成 HTTP 消息后，需要委托操作系统将消息发送给 <code>Web</code> 服务器。</p><p>但在发送之前，还有一项工作需要完成，那就是<strong>查询服务器域名对应的 IP 地址</strong>，因为委托操作系统发送消息时，必须提供通信对象的 IP 地址。</p><p>比如我们打电话的时候，必须要知道对方的电话号码，但由于电话号码难以记忆，所以通常我们会将对方电话号 + 姓名保存在通讯录里。</p><p>所以，有一种服务器就专门保存了 <code>Web</code> 服务器域名与 <code>IP</code> 的对应关系，它就是 <code>DNS</code> 服务器。</p><p>DNS 中的域名都是用<strong>句点</strong>来分隔的，比如 <code>www.server.com</code>，这里的句点代表了不同层次之间的<strong>界限</strong>。</p><p>在域名中，<strong>越靠右</strong>的位置表示其层级<strong>越高</strong>。</p><p>毕竟域名是外国人发明，所以思维和中国人相反，比如说一个城市地点的时候，外国喜欢从小到大的方式顺序说起（如 XX 街道 XX 区 XX 市 XX 省），而中国则喜欢从大到小的顺序（如 XX 省 XX 市 XX 区 XX 街道）。</p><p>实际上域名最后还有一个点，比如 <code>www.server.com.</code>，这个最后的一个点代表根域名。</p><p>也就是，<code>.</code> 根域是在最顶层，它的下一层就是 <code>.com</code> 顶级域，再下面是 <code>server.com</code>。</p><p>所以域名的层级关系类似一个树状结构：</p><ul><li>根 DNS 服务器（.）</li><li>顶级域 DNS 服务器（.com）</li><li>权威 DNS 服务器（server.com）</li></ul><ol><li>客户端首先会发出一个 DNS 请求，问 <a href="http://www.server.com/">www.server.com</a> 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端的 TCP&#x2F;IP 设置中填写的 DNS 服务器地址）。</li><li>本地域名服务器收到客户端的请求后，如果缓存里的表格能找到 <a href="http://www.server.com,则它直接返回/">www.server.com，则它直接返回</a> IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大， 能告诉我 <a href="http://www.server.com/">www.server.com</a> 的 IP 地址吗？” 根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。</li><li>根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，说：“<a href="http://www.server.com/">www.server.com</a> 这个域名归 .com 区域管理”，我给你 .com 顶级域名服务器地址给你，你去问问它吧。”</li><li>本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我 <a href="http://www.server.com/">www.server.com</a> 的 IP 地址吗？”</li><li>顶级域名服务器说：“我给你负责 <a href="http://www.server.com/">www.server.com</a> 区域的权威 DNS 服务器的地址，你去问它应该能问到”。</li><li>本地 DNS 于是转向问权威 DNS 服务器：“老三，<a href="http://www.server.com对应的IP是啥呀？”">www.server.com对应的IP是啥呀？”</a> server.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。</li><li>权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。</li><li>本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。</li></ol><h4 id="3-协议栈"><a href="#3-协议栈" class="headerlink" title="3.协议栈"></a>3.协议栈</h4><p>从DNS中获取到IP之后，就可以把HTTP的传输工作交给操作系统中的协议栈</p><p>协议栈的内部分为几个部分，分别承担不同的工作。上下关系是有一定的规则的，上面的部分会向下面的部分委托工作，下面的部分收到委托的工作并执行。</p><p><img src="/../imgs/21st-March/7.jpg" alt="协议栈"></p><p>应用程序（浏览器）通过调用 Socket 库，来委托协议栈工作。协议栈的上半部分有两块，分别是负责收发数据的 TCP 和 UDP 协议，这两个传输协议会接受应用层的委托执行收发数据的操作。</p><p>协议栈的下面一半是用 IP 协议控制网络包收发操作，在互联网上传数据时，数据会被切分成一块块的网络包，而将网络包发送给对方的操作就是由 IP 负责的。</p><p>此外 IP 中还包括 <code>ICMP</code> 协议和 <code>ARP</code> 协议。</p><ul><li><code>ICMP</code> 用于告知网络包传送过程中产生的错误以及各种控制信息。</li><li><code>ARP</code> 用于根据 IP 地址查询相应的以太网 MAC 地址。</li></ul><p>IP 下面的网卡驱动程序负责控制网卡硬件，而最下面的网卡则负责完成实际的收发操作，也就是对网线中的信号执行发送和接收操作。</p><h4 id="4-TCP"><a href="#4-TCP" class="headerlink" title="4.TCP"></a>4.TCP</h4><p>HTTP 是基于 TCP 协议传输的，所以在这我们先了解下 TCP 协议。</p><blockquote><p>TCP 包头格式</p></blockquote><p>我们先看看 TCP 报文头部的格式：</p><p><img src="/../imgs/21st-March/8.jpg" alt="TCP 包头格式"></p><p>首先，<strong>源端口号</strong>和<strong>目标端口</strong>号是不可少的，如果没有这两个端口号，数据就不知道应该发给哪个应用。</p><p>接下来有包的<strong>序</strong>号，这个是为了解决包乱序的问题。</p><p>还有应该有的是<strong>确认号</strong>，目的是确认发出去对方是否有收到。如果没有收到就应该重新发送，直到送达，这个是为了解决丢包的问题。</p><p>接下来还有一些<strong>状态位</strong>。例如 <code>SYN</code> 是发起一个连接，<code>ACK</code> 是回复，<code>RST</code> 是重新连接，<code>FIN</code> 是结束连接等。TCP 是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。</p><p>还有一个重要的就是<strong>窗口大小</strong>。TCP 要做<strong>流量控制</strong>，通信双方各声明一个窗口（缓存大小），标识自己当前能够的处理能力，别发送的太快，撑死我，也别发的太慢，饿死我。</p><blockquote><p>TCP 传输数据之前，要先三次握手建立连接</p></blockquote><p>在 HTTP 传输数据之前，首先需要 TCP 建立连接，TCP 连接的建立，通常称为<strong>三次握手</strong>。</p><p>这个所谓的「连接」，只是双方计算机里维护一个状态机，在连接建立的过程中，双方的状态变化时序图就像这样。</p><p><img src="/../imgs/21st-March/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.drawio.png" alt="TCP 三次握手"></p><ul><li>一开始，客户端和服务端都处于 <code>CLOSED</code> 状态。先是服务端主动监听某个端口，处于 <code>LISTEN</code> 状态。</li><li>然后客户端主动发起连接 <code>SYN</code>，之后处于 <code>SYN-SENT</code> 状态。</li><li>服务端收到发起的连接，返回 <code>SYN</code>，并且 <code>ACK</code> 客户端的 <code>SYN</code>，之后处于 <code>SYN-RCVD</code> 状态。</li><li>客户端收到服务端发送的 <code>SYN</code> 和 <code>ACK</code> 之后，发送对 <code>SYN</code> 确认的 <code>ACK</code>，之后处于 <code>ESTABLISHED</code> 状态，因为它一发一收成功了。</li><li>服务端收到 <code>ACK</code> 的 <code>ACK</code> 之后，处于 <code>ESTABLISHED</code> 状态，因为它也一发一收了。</li></ul><p>所以三次握手目的是<strong>保证双方都有发送和接收的能力</strong>。</p><blockquote><p>TCP 报文生成</p></blockquote><p>TCP 协议里面会有两个端口，一个是浏览器监听的端口（通常是随机生成的），一个是 Web 服务器监听的端口（HTTP 默认端口号是 <code>80</code>， HTTPS 默认端口号是 <code>443</code>）。</p><p>在双方建立了连接后，TCP 报文中的数据部分就是存放 HTTP 头部 + 数据，组装好 TCP 报文之后，就需交给下面的网络层处理。</p><p>至此，网络包的报文如下图。</p><p><img src="/../imgs/21st-March/13.jpg" alt="TCP 层报文"></p><h4 id="5-IP"><a href="#5-IP" class="headerlink" title="5.IP"></a>5.IP</h4><p>TCP 模块在执行连接、收发、断开等各阶段操作时，都需要委托 IP 模块将数据封装成<strong>网络包</strong>发送给通信对象。</p><blockquote><p>IP 包头格式</p></blockquote><p>我们先看看 IP 报文头部的格式：</p><p><img src="/../imgs/21st-March/14.jpg" alt="IP 包头格式"></p><p>在 IP 协议里面需要有<strong>源地址 IP</strong> 和 <strong>目标地址 IP</strong>：</p><ul><li>源地址IP，即是客户端输出的 IP 地址；</li><li>目标地址，即通过 DNS 域名解析得到的 Web 服务器 IP。</li></ul><p>因为 HTTP 是经过 TCP 传输的，所以在 IP 包头的<strong>协议号</strong>，要填写为 <code>06</code>（十六进制），表示协议为 TCP。</p><blockquote><p>假设客户端有多个网卡，就会有多个 IP 地址，那 IP 头部的源地址应该选择哪个 IP 呢？</p></blockquote><p>当存在多个网卡时，在填写源地址 IP 时，就需要判断到底应该填写哪个地址。这个判断相当于在多块网卡中判断应该使用哪个一块网卡来发送包。</p><p>这个时候就需要根据<strong>路由表</strong>规则，来判断哪一个网卡作为源地址 IP。</p><blockquote><p>IP 报文生成</p></blockquote><p>至此，网络包的报文如下图。</p><p><img src="/../imgs/21st-March/17.jpg" alt="IP 层报文"></p><h4 id="6-两点传输-——-MAC"><a href="#6-两点传输-——-MAC" class="headerlink" title="6.两点传输 —— MAC"></a>6.两点传输 —— MAC</h4><p>生成了 IP 头部之后，接下来网络包还需要在 IP 头部的前面加上 <strong>MAC 头部</strong>。</p><blockquote><p>MAC 包头格式</p></blockquote><p>MAC 头部是以太网使用的头部，它包含了接收方和发送方的 MAC 地址等信息。</p><p><img src="/../imgs/21st-March/18.jpg" alt="MAC 包头格式"></p><p>在 MAC 包头里需要<strong>发送方 MAC 地址</strong>和<strong>接收方目标 MAC 地址</strong>，用于<strong>两点之间的传输</strong>。</p><p>一般在 TCP&#x2F;IP 通信里，MAC 包头的<strong>协议类型</strong>只使用：</p><ul><li><code>0800</code> ： IP 协议</li><li><code>0806</code> ： ARP 协议</li></ul><blockquote><p>MAC 发送方和接收方如何确认?</p></blockquote><p><strong>发送方</strong>的 MAC 地址获取就比较简单了，MAC 地址是在网卡生产时写入到 ROM 里的，只要将这个值读取出来写入到 MAC 头部就可以了。</p><p><strong>接收方</strong>的 MAC 地址就有点复杂了，只要告诉以太网对方的 MAC 的地址，以太网就会帮我们把包发送过去，那么很显然这里应该填写对方的 MAC 地址。</p><p>所以先得搞清楚应该把包发给谁，这个只要查一下<strong>路由表</strong>就知道了。在路由表中找到相匹配的条目，然后把包发给 <code>Gateway</code> 列中的 IP 地址就可以了。</p><blockquote><p>既然知道要发给谁，按如何获取对方的 MAC 地址呢？</p></blockquote><p>不知道对方 MAC 地址？不知道就喊呗。</p><p>此时就需要 <code>ARP</code> 协议帮我们找到路由器的 MAC 地址。</p><p><img src="/../imgs/21st-March/19.jpg" alt="ARP 广播"></p><p>ARP 协议会在以太网中以<strong>广播</strong>的形式，对以太网所有的设备喊出：“这个 IP 地址是谁的？请把你的 MAC 地址告诉我”。</p><p>然后就会有人回答：“这个 IP 地址是我的，我的 MAC 地址是 XXXX”。</p><p>如果对方和自己处于同一个子网中，那么通过上面的操作就可以得到对方的 MAC 地址。然后，我们将这个 MAC 地址写入 MAC 头部，MAC 头部就完成了。</p><blockquote><p>好像每次都要广播获取，这不是很麻烦吗？</p></blockquote><p>放心，在后续操作系统会把本次查询结果放到一块叫做 <strong>ARP 缓存</strong>的内存空间留着以后用，不过缓存的时间就几分钟。</p><p>也就是说，在发包时：</p><ul><li>先查询 ARP 缓存，如果其中已经保存了对方的 MAC 地址，就不需要发送 ARP 查询，直接使用 ARP 缓存中的地址。</li><li>而当 ARP 缓存中不存在对方 MAC 地址时，则发送 ARP 广播查询。</li></ul><blockquote><p>MAC 报文生成</p></blockquote><p>至此，网络包的报文如下图。</p><p><img src="/../imgs/21st-March/21.jpg" alt="MAC 层报文"></p><h4 id="7-出口-——-网卡"><a href="#7-出口-——-网卡" class="headerlink" title="7.出口 —— 网卡"></a>7.出口 —— 网卡</h4><p>网络包只是存放在内存中的一串二进制数字信息，没有办法直接发送给对方。因此，我们需要将<strong>数字信息转换为电信号</strong>，才能在网线上传输，也就是说，这才是真正的数据发送过程。</p><p>负责执行这一操作的是<strong>网卡</strong>，要控制网卡还需要靠<strong>网卡驱动程序</strong>。</p><p>网卡驱动获取网络包之后，会将其<strong>复制</strong>到网卡内的缓存区中，接着会在其<strong>开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列</strong>。</p><p><img src="/../imgs/21st-March/%E6%95%B0%E6%8D%AE%E5%8C%85.drawio.png" alt="数据包"></p><h4 id="8-送别者-——-交换机"><a href="#8-送别者-——-交换机" class="headerlink" title="8.送别者 —— 交换机"></a>8.送别者 —— 交换机</h4><p>下面来看一下包是如何通过交换机的。交换机的设计是将网络包<strong>原样</strong>转发到目的地。交换机工作在 MAC 层，也称为<strong>二层网络设备</strong>。</p><blockquote><p>交换机的包接收操作</p></blockquote><p>首先，电信号到达网线接口，交换机里的模块进行接收，接下来交换机里的模块将电信号转换为数字信号。</p><p>然后通过包末尾的 <code>FCS</code> 校验错误，如果没问题则放到缓冲区。这部分操作基本和计算机的网卡相同，但交换机的工作方式和网卡不同。</p><p>计算机的网卡本身具有 MAC 地址，并通过核对收到的包的接收方 MAC 地址判断是不是发给自己的，如果不是发给自己的则丢弃；相对地，交换机的端口不核对接收方 MAC 地址，而是直接接收所有的包并存放到缓冲区中。因此，和网卡不同，<strong>交换机的端口不具有 MAC 地址</strong>。</p><p>将包存入缓冲区后，接下来需要查询一下这个包的接收方 MAC 地址是否已经在 MAC 地址表中有记录了。</p><p>交换机的 MAC 地址表主要包含两个信息：</p><ul><li>一个是设备的 MAC 地址，</li><li>另一个是该设备连接在交换机的哪个端口上。</li></ul><p><img src="/../imgs/21st-March/23.jpg" alt="交换机的 MAC 地址表"></p><p>举个例子，如果收到的包的接收方 MAC 地址为 <code>00-02-B3-1C-9C-F9</code>，则与图中表中的第 3 行匹配，根据端口列的信息，可知这个地址位于 <code>3</code> 号端口上，然后就可以通过交换电路将包发送到相应的端口了。</p><p>所以，<strong>交换机根据 MAC 地址表查找 MAC 地址，然后将信号发送到相应的端口</strong>。</p><blockquote><p>当 MAC 地址表找不到指定的 MAC 地址会怎么样？</p></blockquote><p>地址表中找不到指定的 MAC 地址。这可能是因为具有该地址的设备还没有向交换机发送过包，或者这个设备一段时间没有工作导致地址被从地址表中删除了。</p><p>这种情况下，交换机无法判断应该把包转发到哪个端口，只能将包转发到除了源端口之外的所有端口上，无论该设备连接在哪个端口上都能收到这个包。</p><p>这样做不会产生什么问题，因为以太网的设计本来就是将包发送到整个网络的，然后<strong>只有相应的接收者才接收包，而其他设备则会忽略这个包</strong>。</p><p>有人会说：“这样做会发送多余的包，会不会造成网络拥塞呢？”</p><p>其实完全不用过于担心，因为发送了包之后目标设备会作出响应，只要返回了响应包，交换机就可以将它的地址写入 MAC 地址表，下次也就不需要把包发到所有端口了。</p><p>局域网中每秒可以传输上千个包，多出一两个包并无大碍。</p><p>此外，如果接收方 MAC 地址是一个<strong>广播地址</strong>，那么交换机会将包发送到除源端口之外的所有端口。</p><p>以下两个属于广播地址：</p><ul><li>MAC 地址中的 <code>FF:FF:FF:FF:FF:FF</code></li><li>IP 地址中的 <code>255.255.255.255</code></li></ul><h2 id="出境大门-——-路由器"><a href="#出境大门-——-路由器" class="headerlink" title="出境大门 —— 路由器"></a>出境大门 —— 路由器</h2><blockquote><p>路由器与交换机的区别</p></blockquote><p>网络包经过交换机之后，现在到达了<strong>路由器</strong>，并在此被转发到下一个路由器或目标设备。</p><p>这一步转发的工作原理和交换机类似，也是通过查表判断包转发的目标。</p><p>不过在具体的操作过程上，路由器和交换机是有区别的。</p><ul><li>因为<strong>路由器</strong>是基于 IP 设计的，俗称<strong>三层</strong>网络设备，路由器的各个端口都具有 MAC 地址和 IP 地址；</li><li>而<strong>交换机</strong>是基于以太网设计的，俗称<strong>二层</strong>网络设备，交换机的端口不具有 MAC 地址。</li></ul><blockquote><p>路由器基本原理</p></blockquote><p>路由器的端口具有 MAC 地址，因此它就能够成为以太网的发送方和接收方；同时还具有 IP 地址，从这个意义上来说，它和计算机的网卡是一样的。</p><p>当转发包时，首先路由器端口会接收发给自己的以太网包，然后<strong>路由表</strong>查询转发目标，再由相应的端口作为发送方将以太网包发送出去。</p><blockquote><p>路由器的包接收操作</p></blockquote><p>首先，电信号到达网线接口部分，路由器中的模块会将电信号转成数字信号，然后通过包末尾的 <code>FCS</code> 进行错误校验。</p><p>如果没问题则检查 MAC 头部中的<strong>接收方 MAC 地址</strong>，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包。</p><p>总的来说，路由器的端口都具有 MAC 地址，只接收与自身地址匹配的包，遇到不匹配的包则直接丢弃。</p><blockquote><p>查询路由表确定输出端口</p></blockquote><p>完成包接收操作之后，路由器就会<strong>去掉</strong>包开头的 MAC 头部。</p><p><strong>MAC 头部的作用就是将包送达路由器</strong>，其中的接收方 MAC 地址就是路由器端口的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC 头部就会<strong>被丢弃</strong>。</p><p>接下来，路由器会根据 MAC 头部后方的 <code>IP</code> 头部中的内容进行包的转发操作。</p><p>转发操作分为几个阶段，首先是查询<strong>路由表</strong>判断转发目标。</p><p><img src="/../imgs/21st-March/24.jpg" alt="路由器转发"></p><p>具体的工作流程根据上图，举个例子。</p><p>假设地址为 <code>10.10.1.101</code> 的计算机要向地址为 <code>192.168.1.100</code> 的服务器发送一个包，这个包先到达图中的路由器。</p><p>判断转发目标的第一步，就是根据包的接收方 IP 地址查询路由表中的目标地址栏，以找到相匹配的记录。</p><p>路由匹配和前面讲的一样，每个条目的子网掩码和 <code>192.168.1.100</code> IP 做 <strong>&amp; 与运算</strong>后，得到的结果与对应条目的目标地址进行匹配，如果匹配就会作为候选转发目标，如果不匹配就继续与下个条目进行路由匹配。</p><p>如第二条目的子网掩码 <code>255.255.255.0</code> 与 <code>192.168.1.100</code> IP 做 <strong>&amp; 与运算</strong>后，得到结果是 <code>192.168.1.0</code> ，这与第二条目的目标地址 <code>192.168.1.0</code> 匹配，该第二条目记录就会被作为转发目标。</p><p>实在找不到匹配路由时，就会选择<strong>默认路由</strong>，路由表中子网掩码为 <code>0.0.0.0</code> 的记录表示「默认路由」。</p><blockquote><p>路由器的发送操作</p></blockquote><p>接下来就会进入包的<strong>发送操作</strong>。</p><p>首先，我们需要根据<strong>路由表的网关列</strong>判断对方的地址。</p><ul><li>如果网关是一个 IP 地址，则这个IP 地址就是我们要转发到的目标地址，<strong>还未抵达终点</strong>，还需继续需要路由器转发。</li><li>如果网关为空，则 IP 头部中的接收方 IP 地址就是要转发到的目标地址，也是就终于找到 IP 包头里的目标地址了，说明<strong>已抵达终点</strong>。</li></ul><p>知道对方的 IP 地址之后，接下来需要通过 <code>ARP</code> 协议根据 IP 地址查询 MAC 地址，并将查询的结果作为接收方 MAC 地址。</p><p>路由器也有 ARP 缓存，因此首先会在 ARP 缓存中查询，如果找不到则发送 ARP 查询请求。</p><p>接下来是发送方 MAC 地址字段，这里填写输出端口的 MAC 地址。还有一个以太类型字段，填写 <code>0800</code> （十六进制）表示 IP 协议。</p><p>网络包完成后，接下来会将其转换成电信号并通过端口发送出去。这一步的工作过程和计算机也是相同的。</p><p>发送出去的网络包会通过<strong>交换机</strong>到达下一个路由器。由于接收方 MAC 地址就是下一个路由器的地址，所以交换机会根据这一地址将包传输到下一个路由器。</p><p>接下来，下一个路由器会将包转发给再下一个路由器，经过层层转发之后，网络包就到达了最终的目的地。</p><h4 id="9-服务器-与-客户端"><a href="#9-服务器-与-客户端" class="headerlink" title="9.服务器 与 客户端"></a>9.服务器 与 客户端</h4><p>数据包抵达服务器后，服务器会先扒开数据包的 MAC 头部，查看是否和服务器自己的 MAC 地址符合，符合就将包收起来。</p><p>接着继续扒开数据包的 IP 头，发现 IP 地址符合，根据 IP 头中协议项，知道自己上层是 TCP 协议。</p><p>于是，扒开 TCP 的头，里面有序列号，需要看一看这个序列包是不是我想要的，如果是就放入缓存中然后返回一个 ACK，如果不是就丢弃。TCP头部里面还有端口号， HTTP 的服务器正在监听这个端口号。</p><p>于是，服务器自然就知道是 HTTP 进程想要这个包，于是就将包发给 HTTP 进程。</p><p>服务器的 HTTP 进程看到，原来这个请求是要访问一个页面，于是就把这个网页封装在 HTTP 响应报文里。</p><p>HTTP 响应报文也需要穿上 TCP、IP、MAC 头部，不过这次是源地址是服务器 IP 地址，目的地址是客户端 IP 地址。</p><p>穿好头部衣服后，从网卡出去，交由交换机转发到出城的路由器，路由器就把响应数据包发到了下一个路由器，就这样跳啊跳。</p><p>最后跳到了客户端的城门把守的路由器，路由器扒开 IP 头部发现是要找城内的人，于是又把包发给了城内的交换机，再由交换机转发到客户端。</p><p>客户端收到了服务器的响应数据包后，同样也非常的高兴，客户能拆快递了！</p><p>于是，客户端开始扒皮，把收到的数据包的皮扒剩 HTTP 响应报文后，交给浏览器去渲染页面，一份特别的数据包快递，就这样显示出来了！</p><p>最后，客户端要离开了，向服务器发起了 TCP 四次挥手，至此双方的连接就断开了。</p><h3 id="Https如何防止中间人篡改报文的"><a href="#Https如何防止中间人篡改报文的" class="headerlink" title="Https如何防止中间人篡改报文的"></a>Https如何防止中间人篡改报文的</h3><p>HTTPS 从协议上解决了 HTTP 时代的中间人攻击问题，但是 HTTPS 在用户主动信任了伪造证书的时候也会发生中间人攻击（比如早期的 12306 需要手动信任证书），HTTPS 中间人攻击流程如下：</p><ol><li>客户端用HTTPS连接服务器的443端口</li><li>服务器下发自己的数字证书给客户端</li><li>黑客劫持了服务器的真实证书，并伪造了一个假的证书给浏览器</li><li>浏览器可以发现得到的网站证书是假的，但是浏览器选择信任</li><li>浏览器生成随机对称密钥A，用伪造的证书中的公钥加密发往服务器</li><li>黑客同样可以劫持这个请求，得到浏览器的对称密钥A，从而能够监听或者篡改通信数据</li><li>黑客利用服务器的真实公钥讲客户端的对称密钥A加密发往服务器</li><li>服务器利用私钥解密这个对称密钥A之后与黑客通信</li><li>黑客利用对称密钥A解密服务器的数据，篡改之后利用对称密钥A加密发给客户端</li><li>客户端收到的数据已经是不安全的了</li></ol><h2 id="OS"><a href="#OS" class="headerlink" title="OS"></a>OS</h2><h3 id="进程和线程区别–引入Go的GMP调度"><a href="#进程和线程区别–引入Go的GMP调度" class="headerlink" title="进程和线程区别–引入Go的GMP调度"></a>进程和线程区别–引入Go的GMP调度</h3><p>进程、线程和协程是计算机程序执行的三个不同层次。</p><p><strong>进程（Process）</strong>： 进程是操作系统进行资源分配和调度的基本单位，是一个独立运行的程序实体。每个进程拥有独立的内存空间、文件描述符、寄存器状态等资源。进程之间的资源是相互隔离的，因此进程间通信需要通过操作系统提供的特定机制（如管道、消息队列、共享内存等）进行。由于进程拥有独立的资源，所以进程间的切换和调度开销较大。</p><p><strong>线程（Thread）</strong>： 线程是操作系统调度执行的最小单位，是进程内的一个执行流。一个进程可以拥有多个线程，这些线程共享进程的资源（如内存空间、文件描述符等）。由于线程共享相同的资源，线程间通信相对简单，可以直接通过共享变量、锁等方式进行。线程相较于进程，上下文切换和调度开销较小。但多个线程并发执行时，需要处理好同步和互斥问题，以避免数据不一致或竞争条件。</p><p><strong>协程（Coroutine</strong>）： 协程是一种用户态的轻量级线程，它的调度和切换完全由程序控制，不依赖于操作系统的调度。协程之间共享线程的资源，因此协程间通信也可以通过共享变量、锁等方式进行。协程的优势在于能够轻松地实现高并发，因为协程切换和调度的开销非常小。协程适用于I&#x2F;O密集型任务，通过异步I&#x2F;O可以有效地提高程序的性能。</p><p><strong>联系</strong></p><ul><li>线程属于进程，多个线程共享进程的资源。一个进程可以包含多个线程，这些线程共同完成任务，提高程序的并发性。</li><li>协程属于线程，多个协程共享线程的资源。一个线程可以包含多个协程，这些协程协同完成任务，提高程序的性能。</li><li>进程、线程和协程在执行程序时，都需要面对同步、互斥和通信等问题。在实际应用中，可以根据需求和场景选择合适的执行实体来实现最优的性能和资源利用。</li></ul><h3 id="GMP模型？"><a href="#GMP模型？" class="headerlink" title="GMP模型？"></a>GMP模型？</h3><h4 id="G（goroutine）"><a href="#G（goroutine）" class="headerlink" title="G（goroutine）"></a>G（goroutine）</h4><p>go语言中的协程goroutine的缩写，相当于操作系统中的进程控制块。其中存折goroutine的运行时栈信息，CPU的一些寄存器的值以及执行的函数指令等。sched字段保存了goroutine的上下文。goroutine切换的时候不同于线程有OS来负责这部分数据，而是由一个gobuf结构体来保存。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> g <span class="hljs-keyword">struct</span> &#123;<br>  stack       stack   <span class="hljs-comment">// 描述真实的栈内存，包括上下界</span><br><br>  m              *m     <span class="hljs-comment">// 当前的 m</span><br>  sched          gobuf   <span class="hljs-comment">// goroutine 切换时，用于保存 g 的上下文      </span><br>  param          unsafe.Pointer <span class="hljs-comment">// 用于传递参数，睡眠时其他 goroutine 可以设置 param，唤醒时该goroutine可以获取</span><br>  atomicstatus   <span class="hljs-type">uint32</span><br>  stackLock      <span class="hljs-type">uint32</span> <br>  goid           <span class="hljs-type">int64</span>  <span class="hljs-comment">// goroutine 的 ID</span><br>  waitsince      <span class="hljs-type">int64</span> <span class="hljs-comment">// g 被阻塞的大体时间</span><br>  lockedm        *m     <span class="hljs-comment">// G 被锁定只在这个 m 上运行</span><br>&#125;<br></code></pre></td></tr></table></figure><p>gobuf 保存了当前的栈指针，计数器，还有 g 自身，这里记录自身 g 的指针的目的是为了<strong>能快速的访问到 goroutine 中的信息</strong>。gobuf 的结构如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> gobuf <span class="hljs-keyword">struct</span> &#123;<br>    sp   <span class="hljs-type">uintptr</span><br>    pc   <span class="hljs-type">uintptr</span><br>    g    guintptr<br>    ctxt unsafe.Pointer<br>    ret  sys.Uintreg<br>    lr   <span class="hljs-type">uintptr</span><br>    bp   <span class="hljs-type">uintptr</span> <span class="hljs-comment">// for goEXPERIMENT=framepointer</span><br>&#125;<br></code></pre></td></tr></table></figure><p>M(Machine)</p><p>M代表一个操作系统的主线程，对内核级线程的封装，数量对应真实的 CPU 数。一个 M 直接关联一个 os 内核线程，用于执行 G。M 会优先从关联的 P 的本地队列中直接获取待执行的 G。M 保存了 M 自身使用的栈信息、当前正在 M上执行的 G 信息、与之绑定的 P 信息。</p><p>结构体 M 中，curg代表结构体M当前绑定的结构体 G ；g0 是带有调度栈的 goroutine，普通的 goroutine 的栈是在<strong>堆上</strong>分配的可增长的栈，但是 g0 的栈是 <strong>M 对应的线程</strong>的栈。与调度相关的代码，会先切换到该 goroutine 的栈中再执行。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> m <span class="hljs-keyword">struct</span> &#123;<br>    g0      *g     <span class="hljs-comment">// 带有调度栈的goroutine</span><br><br>    gsignal       *g         <span class="hljs-comment">// 处理信号的goroutine</span><br>    tls           [<span class="hljs-number">6</span>]<span class="hljs-type">uintptr</span> <span class="hljs-comment">// thread-local storage</span><br>    mstartfn      <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span><br>    curg          *g       <span class="hljs-comment">// 当前运行的goroutine</span><br>    caughtsig     guintptr <br>    p             puintptr <span class="hljs-comment">// 关联p和执行的go代码</span><br>    nextp         puintptr<br>    id            <span class="hljs-type">int32</span><br>    mallocing     <span class="hljs-type">int32</span> <span class="hljs-comment">// 状态</span><br><br>    spinning      <span class="hljs-type">bool</span> <span class="hljs-comment">// m是否out of work</span><br>    blocked       <span class="hljs-type">bool</span> <span class="hljs-comment">// m是否被阻塞</span><br>    inwb          <span class="hljs-type">bool</span> <span class="hljs-comment">// m是否在执行写屏蔽</span><br><br>    printlock     <span class="hljs-type">int8</span><br>    incgo         <span class="hljs-type">bool</span><br>    fastrand      <span class="hljs-type">uint32</span><br>    ncgocall      <span class="hljs-type">uint64</span>      <span class="hljs-comment">// cgo调用的总数</span><br>    ncgo          <span class="hljs-type">int32</span>       <span class="hljs-comment">// 当前cgo调用的数目</span><br>    park          note<br>    alllink       *m <span class="hljs-comment">// 用于链接allm</span><br>    schedlink     muintptr<br>    mcache        *mcache <span class="hljs-comment">// 当前m的内存缓存</span><br>    lockedg       *g <span class="hljs-comment">// 锁定g在当前m上执行，而不会切换到其他m</span><br>    createstack   [<span class="hljs-number">32</span>]<span class="hljs-type">uintptr</span> <span class="hljs-comment">// thread创建的栈</span><br>&#125;<br></code></pre></td></tr></table></figure><p>P(Processor)</p><p>Processor 代表了 M 所需的上下文环境，代表 M 运行 G 所需要的资源。是处理用户级代码逻辑的处理器，可以将其看作一个局部调度器使 go 代码在一个线程上跑。当 P 有任务时，就需要创建或者唤醒一个系统线程来执行它队列里的任务，所以 P 和 M 是相互绑定的。P 可以根据实际情况开启协程去工作，它包含了运行 goroutine 的资源，如果线程想运行 goroutine，必须先获取 P，P 中还包含了可运行的 G 队列。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> p <span class="hljs-keyword">struct</span> &#123;<br>    lock mutex<br><br>    id          <span class="hljs-type">int32</span><br>    status      <span class="hljs-type">uint32</span> <span class="hljs-comment">// 状态，可以为pidle/prunning/...</span><br>    link        puintptr<br>    schedtick   <span class="hljs-type">uint32</span>     <span class="hljs-comment">// 每调度一次加1</span><br>    syscalltick <span class="hljs-type">uint32</span>     <span class="hljs-comment">// 每一次系统调用加1</span><br>    sysmontick  sysmontick <br>    m           muintptr   <span class="hljs-comment">// 回链到关联的m</span><br>    mcache      *mcache<br>    racectx     <span class="hljs-type">uintptr</span><br><br>    goidcache    <span class="hljs-type">uint64</span> <span class="hljs-comment">// goroutine的ID的缓存</span><br>    goidcacheend <span class="hljs-type">uint64</span><br><br>    <span class="hljs-comment">// 可运行的goroutine的队列</span><br>    runqhead <span class="hljs-type">uint32</span><br>    runqtail <span class="hljs-type">uint32</span><br>    runq     [<span class="hljs-number">256</span>]guintptr<br><br>    runnext guintptr <span class="hljs-comment">// 下一个运行的g</span><br><br>    sudogcache []*sudog<br>    sudogbuf   [<span class="hljs-number">128</span>]*sudog<br><br>    palloc persistentAlloc <span class="hljs-comment">// per-P to avoid mutex</span><br><br>    pad [sys.CacheLineSize]<span class="hljs-type">byte</span><br>&#125;<br><br></code></pre></td></tr></table></figure><h4 id="GMP的调度流程？"><a href="#GMP的调度流程？" class="headerlink" title="GMP的调度流程？"></a>GMP的调度流程？</h4><p><img src="/../imgs/21st-March/63e223e84757feff33526e36.jpg" alt="GMP调度"></p><ul><li>每个P有个局部队列，局部队列保存待执行的goroutine，当M绑定的P的局部队列已经满了之后就会把就会把goroutine放到全局队列</li><li>每个P和一个M绑定，M是真正的执行P中goroutine的实体，M从绑定的P中的局部队列获取G来执行</li><li>当M绑定的P的局部队列为空时，M会从全局队列获取到本地队列来执行G，当从全局队列中没有获取到可执行的G时候，M会从其他P的局部队列中偷取G来执行，这种从其他P偷的方式称为work stealing</li><li>当G因系统调用阻塞时会阻塞M，此时P回合M解绑即hand off，并寻找新的idle的M，若没有idle的M就会新建一个M</li><li>当G因 channel 或者 network I&#x2F;O 阻塞时，不会阻塞 M，M 会寻找其他 runnable 的 G；当阻塞的 G 恢复后会重新进入 runnable 进入 P 队列等待执行</li></ul><h2 id="Mysql"><a href="#Mysql" class="headerlink" title="Mysql"></a>Mysql</h2><h3 id="MySQL索引的对比"><a href="#MySQL索引的对比" class="headerlink" title="MySQL索引的对比"></a>MySQL索引的对比</h3><h4 id="怎样的索引的数据结构是好的？"><a href="#怎样的索引的数据结构是好的？" class="headerlink" title="怎样的索引的数据结构是好的？"></a>怎样的索引的数据结构是好的？</h4><p>MySQL 的数据是持久化的，意味着数据（索引+记录）是保存到磁盘上的，因为这样即使设备断电了，数据也不会丢失。</p><p>磁盘是一个慢的离谱的存储设备，有多离谱呢？</p><p>人家内存的访问速度是纳秒级别的，而磁盘访问的速度是毫秒级别的，也就是说读取同样大小的数据，磁盘中读取的速度比从内存中读取的速度要慢上万倍，甚至几十万倍。</p><p>磁盘读写的最小单位是<strong>扇区</strong>，扇区的大小只有 <code>512B</code> 大小，操作系统一次会读写多个扇区，所以**操作系统的最小读写单位是块（Block）。Linux 中的块大小为 <code>4KB</code>**，也就是一次磁盘 I&#x2F;O 操作会直接读写 8 个扇区。</p><p>由于数据库的索引是保存到磁盘上的，因此当我们通过索引查找某行数据的时候，就需要先从磁盘读取索引到内存，再通过索引从磁盘中找到某行数据，然后读入到内存，也就是说查询过程中会发生多次磁盘 I&#x2F;O，而磁盘 I&#x2F;O 次数越多，所消耗的时间也就越大。</p><p>所以，我们希望索引的数据结构能在尽可能少的磁盘的 I&#x2F;O 操作中完成查询工作，因为磁盘 I&#x2F;O 操作越少，所消耗的时间也就越小。</p><p>另外，MySQL 是支持范围查找的，所以索引的数据结构不仅要能高效地查询某一个记录，而且也要能高效地执行范围查找。</p><p>所以，要设计一个适合 MySQL 索引的数据结构，至少满足以下要求：</p><ul><li>能在尽可能少的磁盘的 I&#x2F;O 操作中完成查询工作；</li><li>要能高效地查询某一个记录，也要能高效地执行范围查找；</li></ul><p>分析完要求后，我们针对每一个数据结构分析一下。</p><h4 id="二分查找树"><a href="#二分查找树" class="headerlink" title="二分查找树"></a>二分查找树</h4><p>用数组来实现线性排序的数据虽然简单好用，但是插入新元素的时候性能太低。</p><p>因为插入一个元素，需要将这个元素之后的所有元素后移一位，如果这个操作发生在磁盘中呢？这必然是灾难性的。因为磁盘的速度比内存慢几十万倍，所以我们不能用一种线性结构将磁盘排序。</p><p>其次，有序的数组在使用二分查找的时候，每次查找都要不断计算中间的位置。</p><p><strong>二叉查找树的特点是一个节点的左子树的所有节点都小于这个节点，右子树的所有节点都大于这个节点</strong>，这样我们在查询数据时，不需要计算中间节点的位置了，只需将查找的数据与节点的数据进行比较。</p><p>假设，我们查找索引值为 key 的节点：</p><ol><li>如果 key 大于根节点，则在右子树中进行查找；</li><li>如果 key 小于根节点，则在左子树中进行查找；</li><li>如果 key 等于根节点，也就是找到了这个节点，返回根节点即可。</li></ol><p>另外，二叉查找树解决了插入新节点的问题，因为二叉查找树是一个跳跃结构，不必连续排列。这样在插入的时候，新节点可以放在任何位置，不会像线性结构那样插入一个元素，所有元素都需要向后排列。</p><p>因此，二叉查找树解决了连续结构插入新元素开销很大的问题，同时又保持着天然的二分结构。</p><p>那是不是二叉查找树就可以作为索引的数据结构了呢？</p><p>不行不行，二叉查找树存在一个极端情况，会导致它变成一个瘸子！</p><p><strong>当每次插入的元素都是二叉查找树中最大的元素，二叉查找树就会退化成了一条链表，查找数据的时间复杂度变成了 O(n)</strong></p><p>由于树是存储在磁盘中的，访问每个节点，都对应一次磁盘 I&#x2F;O 操作（<em>假设一个节点的大小「小于」操作系统的最小读写单位块的大小</em>），也就是说<strong>树的高度就等于每次查询数据时磁盘 IO 操作的次数</strong>，所以树的高度越高，就会影响查询性能。</p><p>二叉查找树由于存在退化成链表的可能性，会使得查询操作的时间复杂度从 O(logn) 升为 O(n)。</p><p>而且会随着插入的元素越多，树的高度也变高，意味着需要磁盘 IO 操作的次数就越多，这样导致查询性能严重下降，再加上不能范围查询，所以不适合作为数据库的索引结构。</p><h4 id="自平衡二叉树"><a href="#自平衡二叉树" class="headerlink" title="自平衡二叉树"></a>自平衡二叉树</h4><p>为了解决二叉查找树会在极端情况下退化成链表的问题，后面就有人提出<strong>平衡二叉查找树（AVL 树）</strong>。</p><p>主要是在二叉查找树的基础上增加了一些条件约束：<strong>每个节点的左子树和右子树的高度差不能超过 1</strong>。也就是说节点的左子树和右子树仍然为平衡二叉树，这样查询操作的时间复杂度就会一直维持在 O(logn) 。</p><p>除了平衡二叉查找树，还有很多自平衡的二叉树，比如红黑树，它也是通过一些约束条件来达到自平衡，不过红黑树的约束条件比较复杂，不是本篇的重点重点，大家可以看《数据结构》相关的书籍来了解红黑树的约束条件。</p><p>下面是红黑树插入节点的过程，这左旋右旋的操作，就是为了自平衡。</p><p><img src="/../imgs/21st-March/b2628d1248e41207a08871f7bfac3522.gif" alt="红黑树"></p><p><strong>不管平衡二叉查找树还是红黑树，都会随着插入的元素增多，而导致树的高度变高，这就意味着磁盘 I&#x2F;O 操作次数多，会影响整体数据查询的效率</strong>。</p><p>根本原因是因为它们都是二叉树，也就是每个节点只能保存 2 个子节点 ，如果我们把二叉树改成 M 叉树（M&gt;2）呢？</p><p>比如，当 M&#x3D;3 时，在同样的节点个数情况下，三叉树比二叉树的树高要矮。</p><p>因此，<strong>当树的节点越多的时候，并且树的分叉数 M 越大的时候，M 叉树的高度会远小于二叉树的高度</strong>。</p><h4 id="B树"><a href="#B树" class="headerlink" title="B树"></a>B树</h4><p>自平衡二叉树虽然能保持查询操作的时间复杂度在O(logn)，但是因为它本质上是一个二叉树，每个节点只能有 2 个子节点，那么当节点个数越多的时候，树的高度也会相应变高，这样就会增加磁盘的 I&#x2F;O 次数，从而影响数据查询的效率。</p><p>为了解决降低树的高度的问题，后面就出来了 B 树，它不再限制一个节点就只能有 2 个子节点，而是允许 M 个子节点 (M&gt;2)，从而降低树的高度。</p><p>B 树的每一个节点最多可以包括 M 个子节点，M 称为 B 树的阶，所以 B 树就是一个多叉树。</p><p>假设 M &#x3D; 3，那么就是一棵 3 阶的 B 树，特点就是每个节点最多有 2 个（M-1个）数据和最多有 3 个（M个）子节点，超过这些要求的话，就会分裂节点，</p><p>假设我们在上图一棵 3 阶的 B 树中要查找的索引值是 9 的记录那么步骤可以分为以下几步：</p><ol><li>与根节点的索引(4，8）进行比较，9 大于 8，那么往右边的子节点走；</li><li>然后该子节点的索引为（10，12），因为 9 小于 10，所以会往该节点的左边子节点走；</li><li>走到索引为9的节点，然后我们找到了索引值 9 的节点。</li></ol><p>可以看到，一棵 3 阶的 B 树在查询叶子节点中的数据时，由于树的高度是 3 ，所以在查询过程中会发生 3 次磁盘 I&#x2F;O 操作。</p><p>而如果同样的节点数量在平衡二叉树的场景下，树的高度就会很高，意味着磁盘 I&#x2F;O 操作会更多。所以，B 树在数据查询中比平衡二叉树效率要高。</p><p>但是 B 树的每个节点都包含数据（索引+记录），而用户的记录数据的大小很有可能远远超过了索引数据，这就需要花费更多的磁盘 I&#x2F;O 操作次数来读到「有用的索引数据」。</p><p>而且，在我们查询位于底层的某个节点（比如 A 记录）过程中，「非 A 记录节点」里的记录数据会从磁盘加载到内存，但是这些记录数据是没用的，我们只是想读取这些节点的索引数据来做比较查询，而「非 A 记录节点」里的记录数据对我们是没用的，这样不仅增多磁盘 I&#x2F;O 操作次数，也占用内存资源。</p><p>另外，如果使用 B 树来做范围查询的话，需要使用中序遍历，这会涉及多个节点的磁盘 I&#x2F;O 问题，从而导致整体速度下降。</p><h4 id="B-树"><a href="#B-树" class="headerlink" title="B+树"></a>B+树</h4><p>B+ 树就是对 B 树做了一个升级，MySQL 中索引的数据结构就是采用了 B+ 树，B+ 树结构如下图：</p><p><img src="/../imgs/21st-March/b6678c667053a356f46fc5691d2f5878.png" alt="B+树"></p><p>B+ 树与 B 树差异的点，主要是以下这几点：</p><ul><li>叶子节点（最底部的节点）才会存放实际数据（索引+记录），非叶子节点只会存放索引；</li><li>所有索引都会在叶子节点出现，叶子节点之间构成一个有序链表；</li><li>非叶子节点的索引也会同时存在在子节点中，并且是在子节点中所有索引的最大（或最小）。</li><li>非叶子节点中有多少个子节点，就有多少个索引；</li></ul><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><h3 id="单链表反转（acm模式）"><a href="#单链表反转（acm模式）" class="headerlink" title="单链表反转（acm模式）"></a>单链表反转（acm模式）</h3><p><img src="/../imgs/21st-March/image-20240321221955244.png" alt="单链表反转"></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;bits/stdc++.h&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">ListNode</span> &#123;<br>    <span class="hljs-type">int</span> val;<br>    ListNode *next;<br>    <span class="hljs-built_in">ListNode</span>(<span class="hljs-type">int</span> _val): <span class="hljs-built_in">val</span>(_val),<span class="hljs-built_in">next</span>(<span class="hljs-literal">nullptr</span>)&#123;&#125;;<br>&#125;;<br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">print</span><span class="hljs-params">(ListNode* head)</span> </span>&#123;<br>    <span class="hljs-keyword">while</span>(head) &#123;<br>        cout&lt;&lt;head-&gt;val&lt;&lt;<span class="hljs-string">&quot; &quot;</span>;<br>        head = head-&gt;next;<br>    &#125;<br>    cout&lt;&lt;<span class="hljs-string">&#x27;\n&#x27;</span>;<br>&#125;<br><span class="hljs-function">ListNode* <span class="hljs-title">reverse</span><span class="hljs-params">(ListNode *head)</span> </span>&#123;<br>    ListNode* pre = <span class="hljs-literal">nullptr</span>,*cur = head;<br>    <span class="hljs-keyword">while</span>(cur) &#123;<br>        ListNode* temp = cur-&gt;next;<br>        cur-&gt;next = pre;<br>        pre = cur;<br>        cur = temp;<br>    &#125;<br>    <span class="hljs-keyword">return</span> pre;<br>&#125;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-type">int</span> n;<br>    <span class="hljs-keyword">while</span>(cin&gt;&gt;n) &#123;<br>        <span class="hljs-keyword">if</span>(n==<span class="hljs-number">0</span>) &#123;<br>            cout&lt;&lt;<span class="hljs-string">&quot;list is empty&quot;</span>&lt;&lt;endl;<br>            <span class="hljs-keyword">break</span>;<br>        &#125;<br>        ListNode* dummyhead = <span class="hljs-keyword">new</span> <span class="hljs-built_in">ListNode</span>(<span class="hljs-number">-1</span>);<br>        ListNode* cur = dummyhead;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; n; i++) &#123;<br>            <span class="hljs-type">int</span> x;<br>            cin&gt;&gt;x;<br>            cur-&gt;next = <span class="hljs-keyword">new</span> <span class="hljs-built_in">ListNode</span>(x);<br>            cur = cur-&gt;next;<br>        &#125;<br>        <span class="hljs-built_in">print</span>(dummyhead-&gt;next);<br>        ListNode* rev = <span class="hljs-built_in">reverse</span>(dummyhead-&gt;next);<br>        <span class="hljs-built_in">print</span>(rev);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="最长公共子序列（acm模式）"><a href="#最长公共子序列（acm模式）" class="headerlink" title="最长公共子序列（acm模式）"></a>最长公共子序列（acm模式）</h3><p><img src="/../imgs/21st-March/image-20240321222257592.png" alt="最长公共子序列"></p><p>主要是状态转移方程</p><p><img src="/../imgs/21st-March/image-20240321230254740.png" alt="状态转移方程"></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;bits/stdc++.h&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>    string s1,s2;<br>    <span class="hljs-keyword">while</span>(cin&gt;&gt;s1&gt;&gt;s2)&#123;<br>        <span class="hljs-type">int</span> n1 = s1.<span class="hljs-built_in">size</span>(),n2 = s2.<span class="hljs-built_in">size</span>();<br>        vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; <span class="hljs-built_in">dp</span>(n1+<span class="hljs-number">1</span>,<span class="hljs-built_in">vector</span>&lt;<span class="hljs-type">int</span>&gt;(n2+<span class="hljs-number">1</span>,<span class="hljs-number">0</span>));<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>;i &lt;= n1;i++) &#123;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">1</span>;j &lt;= n2;j++) &#123;<br>                <span class="hljs-keyword">if</span>(s1[i<span class="hljs-number">-1</span>] == s2[j<span class="hljs-number">-1</span>]) &#123;<br>                    dp[i][j] = dp[i<span class="hljs-number">-1</span>][j<span class="hljs-number">-1</span>] + <span class="hljs-number">1</span>;<br>                &#125;<span class="hljs-keyword">else</span> &#123;<br>                    dp[i][j] = <span class="hljs-built_in">max</span>(dp[i<span class="hljs-number">-1</span>][j],dp[i][j<span class="hljs-number">-1</span>]);<br>                &#125;<br>            &#125;<br>        &#125;<br>        cout&lt;&lt;dp[n1][n2]&lt;&lt;endl;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="二叉树的高度"><a href="#二叉树的高度" class="headerlink" title="二叉树的高度"></a>二叉树的高度</h3><p><img src="/../imgs/21st-March/image-20240321232133046.png" alt="二叉树的高度"></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;bits/stdc++.h&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">TreeNode</span> &#123;<br>    <span class="hljs-type">char</span> val;<br>    TreeNode* left;<br>    TreeNode* right;<br>    <span class="hljs-built_in">TreeNode</span>(<span class="hljs-type">char</span> val) : <span class="hljs-built_in">val</span>(val), <span class="hljs-built_in">left</span>(<span class="hljs-literal">nullptr</span>), <span class="hljs-built_in">right</span>(<span class="hljs-literal">nullptr</span>) &#123;&#125;<br>&#125;;<br><span class="hljs-function">TreeNode* <span class="hljs-title">buildTree</span><span class="hljs-params">(string&amp; preorder,string&amp; inorder,<span class="hljs-type">int</span> preStart,<span class="hljs-type">int</span> inStart,<span class="hljs-type">int</span> inEnd,unordered_map&lt;<span class="hljs-type">char</span>, <span class="hljs-type">int</span>&gt;&amp; indexMap)</span> </span>&#123;<br>    <span class="hljs-keyword">if</span> (preStart &gt; preorder.<span class="hljs-built_in">size</span>() - <span class="hljs-number">1</span> || inStart &gt; inEnd) &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nullptr</span>;<br>    &#125;<br>    <br>    <span class="hljs-type">char</span> rootval = preorder[preStart];<br>    TreeNode *root= <span class="hljs-keyword">new</span> <span class="hljs-built_in">TreeNode</span>(rootval);<br>    <span class="hljs-type">int</span> rootIndex = indexMap[rootval];<br>    <br>    root-&gt;left = <span class="hljs-built_in">buildTree</span>(preorder,inorder,preStart+<span class="hljs-number">1</span>,inStart,rootIndex - <span class="hljs-number">1</span>,indexMap);<br>    root-&gt;right = <span class="hljs-built_in">buildTree</span>(preorder,inorder,preStart + rootIndex - inStart + <span class="hljs-number">1</span>,rootIndex + <span class="hljs-number">1</span>,inEnd,indexMap);<br><br>    <span class="hljs-keyword">return</span> root;<br>&#125;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">getHeight</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;<br>    <span class="hljs-keyword">if</span> (root == <span class="hljs-literal">nullptr</span>) &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>    &#125;<br><br>    <span class="hljs-type">int</span> leftHeight = <span class="hljs-built_in">getHeight</span>(root-&gt;left);<br>    <span class="hljs-type">int</span> rightHeight = <span class="hljs-built_in">getHeight</span>(root-&gt;right);<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">max</span>(leftHeight, rightHeight) + <span class="hljs-number">1</span>;<br>&#125;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-type">int</span> n;<br>    <span class="hljs-keyword">while</span>(cin&gt;&gt;n) &#123;<br>        string preorder, inorder;<br>        cin &gt;&gt; preorder &gt;&gt; inorder;<br>        unordered_map&lt;<span class="hljs-type">char</span>, <span class="hljs-type">int</span>&gt; indexMap;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i++) &#123;<br>            indexMap[inorder[i]] = i;<br>        &#125;<br>        TreeNode* root = <span class="hljs-built_in">buildTree</span>(preorder, inorder, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, n<span class="hljs-number">-1</span>, indexMap);<br>        <span class="hljs-type">int</span> height = <span class="hljs-built_in">getHeight</span>(root);<br>        cout &lt;&lt; height &lt;&lt; <span class="hljs-string">&#x27;\n&#x27;</span>;<br>    &#125;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>diary</category>
      
    </categories>
    
    
    <tags>
      
      <tag>diary</tag>
      
      <tag>八股</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>20th-March</title>
    <link href="/2024/03/20/20th-March/"/>
    <url>/2024/03/20/20th-March/</url>
    
    <content type="html"><![CDATA[<h1 id="每日八股"><a href="#每日八股" class="headerlink" title="每日八股"></a>每日八股</h1><h2 id="计网"><a href="#计网" class="headerlink" title="计网"></a>计网</h2><h3 id="HTTP-1-1、HTTP-2、HTTP-3演变"><a href="#HTTP-1-1、HTTP-2、HTTP-3演变" class="headerlink" title="HTTP&#x2F;1.1、HTTP&#x2F;2、HTTP&#x2F;3演变"></a>HTTP&#x2F;1.1、HTTP&#x2F;2、HTTP&#x2F;3演变</h3><h4 id="HTTP-1-1-相比-HTTP-1-0提高了什么性能？"><a href="#HTTP-1-1-相比-HTTP-1-0提高了什么性能？" class="headerlink" title="HTTP&#x2F;1.1 相比 HTTP&#x2F;1.0提高了什么性能？"></a>HTTP&#x2F;1.1 相比 HTTP&#x2F;1.0提高了什么性能？</h4><ul><li>使用长连接的方式改善了HTTP&#x2F;1.0短连接造成的性能开销</li><li>支持管道网络运输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。</li></ul><p>但HTTP&#x2F;1.1还是有性能瓶颈：</p><ul><li>请求&#x2F;响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩<code>Body</code>的部分</li><li>发送冗长的首部。每次互相发送相同的首部造成的浪费较多</li><li>服务器是按请求的顺序响应的，如果服务器响应慢，会导致客户端一直请求不到数据，也就是队头阻塞</li><li>没有请求优先级控制</li><li>请求只能从客户端开始，服务器只能被动响应</li></ul><h4 id="HTTP-2做了什么优化？"><a href="#HTTP-2做了什么优化？" class="headerlink" title="HTTP&#x2F;2做了什么优化？"></a>HTTP&#x2F;2做了什么优化？</h4><p>HTTP&#x2F;2协议是基于HTTPS的，所以HTTP&#x2F;2的安全性也是有保障的。</p><ul><li>头部压缩</li><li>二进制格式</li><li>并发传输</li><li>服务器主动推送资源</li></ul><p>1.头部压缩</p><p>HTTP&#x2F;2会压缩头，如果你同时发出多个请求，他们的头是一样的或是相似，那么，协议会帮你消除重复的部分。</p><p>这就是所谓的HPACK算法:在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送重复的字段了，只发送索引号，这样就提高速度了。</p><p>2.二进制格式</p><p>HTTP&#x2F;2不再像HTTP&#x2F;1.1里的纯文本形式的文本，而是全面采用了二进制格式，头信息和数据体都是二进制，并且统称为帧：头信息帧和数据帧</p><p>这样虽然对人不友好，但是对计算机非常友好，因为计算机只懂二进制，那么收到报文后，无需再将明文的报文转成二进制，而是直接解析二进制报文，这<strong>增加了数据传输的效率</strong>。</p><p>比如状态码 200 ，在 HTTP&#x2F;1.1 是用 ‘2’’0’’0’ 三个字符来表示（二进制：00110010 00110000 00110000），共用了 3 个字节，在 HTTP&#x2F;2 对于状态码 200 的二进制编码是 10001000，只用了 1 字节就能表示，相比于 HTTP&#x2F;1.1 节省了 2 个字节，</p><p>3.并发传输</p><p>我们都知道HTTP&#x2F;1.1的实现是基于请求-响应模型的。同一个连接中，HTTP完成一个事务（请求与响应），才能处理下一个事务，也就是说在发出请求等待响应的过程中，是没办法做其他事情的，如果响应迟迟不来，那么后续的请求是无法发送的，也造成了对头阻塞的问题</p><p>而HTTP&#x2F;2就引出了Stream概念，多个Stream复用在一条TCP连接</p><p><img src="/../imgs/20th-March/stream.png" alt="Stream"></p><p>从上图可以看到，1个TCP连接包含多个Stream，Stream里可以包含1个或多个Message，Message对应HTTP&#x2F;1中的请求或响应，由HTTP头部和Body构成。Message里包含一条或者多个Frame，Frame是HTTP&#x2F;2最小单位，以二进制压缩格式存放HTTP&#x2F;1中的内容。</p><p>针对不同的HTTP请求用独一无二的Stream ID来区分，接收端可以通过Stream ID有序组装成HTTP消息，不同Stream的帧是可以乱序发送的，因此可以并发不同的Stream，也就是HTTP&#x2F;2可以并行交错地发送请求和响应。</p><p>4.服务器推送</p><p>HTTP&#x2F;2还在一定程度上改善了传统的请求-应答工作模式，服务端不再是被动地响应，可以主动向客户端发送信息。</p><p>客户端和服务器<strong>双方都可以建立 Stream</strong>， Stream ID 也是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。</p><h4 id="HTTP-2有什么缺陷？"><a href="#HTTP-2有什么缺陷？" class="headerlink" title="HTTP&#x2F;2有什么缺陷？"></a>HTTP&#x2F;2有什么缺陷？</h4><p>HTTP&#x2F;2通过Stream的并发能力，解决了HTTP1&#x2F;1队头阻塞的问题，看似很完美了，但是HTTP&#x2F;2还是存在“队头阻塞”的问题，不过是在TCP这一层。</p><p><strong>HTTP&#x2F;2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP&#x2F;2 应用层才能从内核中拿到数据，这就是 HTTP&#x2F;2 队头阻塞问题。</strong></p><p><img src="/../imgs/20th-March/tcp%E9%98%9F%E5%A4%B4%E9%98%BB%E5%A1%9E.gif" alt="TCP队头阻塞"></p><p>图中发送方发送了很多个 packet，每个 packet 都有自己的序号，你可以认为是 TCP 的序列号，其中 packet 3 在网络中丢失了，即使 packet 4-6 被接收方收到后，由于内核中的 TCP 数据不是连续的，于是接收方的应用层就无法从内核中读取到，只有等到 packet 3 重传后，接收方的应用层才可以从内核中读取到数据，这就是 HTTP&#x2F;2 的队头阻塞问题，是在 TCP 层面发生的。</p><p>所以，一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的<strong>所有的 HTTP 请求都必须等待这个丢了的包被重传回来</strong>。</p><h4 id="HTTP-3-做了哪些优化？"><a href="#HTTP-3-做了哪些优化？" class="headerlink" title="HTTP&#x2F;3 做了哪些优化？"></a>HTTP&#x2F;3 做了哪些优化？</h4><p>从TCP改成了UDP</p><p>UDP 发送是不管顺序，也不管丢包的，所以不会出现像 HTTP&#x2F;2 队头阻塞的问题。大家都知道 UDP 是不可靠传输的，但基于 UDP 的 <strong>QUIC 协议</strong> 可以实现类似 TCP 的可靠性传输。</p><ul><li>无队头阻塞</li><li>更快的连接建立</li><li>连接迁移</li></ul><p>1.无队头阻塞</p><p>QUIC协议也有类似HTTP&#x2F;2 Stream与多路复用的概念，也是可以在同一条连接上并发传输多个Stream，Stream可以认为就是一条HTTP请求。</p><p>QUIC有自己的一套机制可以保证传输的可靠性的。当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题。这与HTTP&#x2F;2不同，HTTP&#x2F;2只要某个流中的数据包丢失了，其他流也会因此受影响。</p><p>所以，QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不受影响。</p><p><img src="/../imgs/20th-March/quic%E6%97%A0%E9%98%BB%E5%A1%9E.jpeg" alt="QUIC多路复用"></p><p><img src="/../imgs/20th-March/http2%E9%98%BB%E5%A1%9E.jpeg" alt="TCP队头阻塞"></p><p>2.更快的连接建立</p><p>对于HTTP&#x2F;1和HTTP&#x2F;2协议，TCP和TLS是分层的，分别属于内核实现的传输层，openssl层库实现的表示层，因此它们难以合并在一起，需要分批次来我收，先TCP握手再TLS握手。</p><p>HTTP&#x2F;3再传输数据前虽然需要QUIC协议握手，但是这个握手过程只需要1RTT，握手的目的是为确认双方的连接ID，连接迁移就是基于连接ID实现的。</p><p>但是HTTP&#x2F;3的QUIC协议并不是与TLS分层，而是QUIC内部包含了TLS，它再自己的帧会携带TLS里的“记录”，再加上QUIC使用的是TLS&#x2F;1.3，因此只需要1个RTT就可以同时完成建立连接与密钥协商</p><p><img src="/../imgs/20th-March/28-HTTP3%E4%BA%A4%E4%BA%92%E6%AC%A1%E6%95%B0.jpeg" alt="TCP HTTPS（TLS/1.3） 和 QUIC HTTPS "></p><p>3.连接迁移</p><p>基于TCP传输协议的HTTP协议，由于是通过四元组确定一条TCP连接。</p><p><img src="/../imgs/20th-March/format,png-20230309231026577.png" alt="TCP 四元组"></p><p>那么当移动设备的网络从4G切换到WIFI时，意味着IP地址变化了，那么久必须要断开连接，然后重新建立连接。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。</p><p>而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过<strong>连接 ID</strong> 来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了<strong>连接迁移</strong>的功能。</p><p>所以， QUIC 是一个在 UDP 之上的<strong>伪</strong> TCP + TLS + HTTP&#x2F;2 的多路复用的协议。</p><p>QUIC 是新协议，对于很多网络设备，根本不知道什么是 QUIC，只会当做 UDP，这样会出现新的问题，因为有的网络设备是会丢掉 UDP 包的，而 QUIC 是基于 UDP 实现的，那么如果网络设备无法识别这个是 QUIC 包，那么就会当作 UDP包，然后被丢弃。</p><h3 id="什么是TCP？"><a href="#什么是TCP？" class="headerlink" title="什么是TCP？"></a>什么是TCP？</h3><p>TCP是面向连接的、可靠的、基于字节流的传输层通信协议</p><ul><li>面向连接：一定是一对一才能连接，不能像UDP协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的</li><li>可靠的：无论网络链路中出现了怎样的链路变化，TCP都可以保证一个报文一定能够到达接收端</li><li>字节流：用户消息通过 TCP 协议传输时，消息可能会被操作系统「分组」成多个的 TCP 报文，如果接收方的程序如果不知道「消息的边界」，是无法读出一个有效的用户消息的。并且 TCP 报文是「有序的」，当「前一个」TCP 报文没有收到的时候，即使它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理，同时对「重复」的 TCP 报文会自动丢弃。</li></ul><h3 id="UDP和TCP有什么区别呢？分别的应用场景是？"><a href="#UDP和TCP有什么区别呢？分别的应用场景是？" class="headerlink" title="UDP和TCP有什么区别呢？分别的应用场景是？"></a>UDP和TCP有什么区别呢？分别的应用场景是？</h3><p>UDP不提供复杂的控制机制，利用IP提供面向无连接的通信服务。</p><ul><li>目标和源端口：主要是告诉UDP协议应该把报文发给哪个进程。</li><li>包长度：该字段保存了UDP首部的长度跟数据的长度之和</li><li>校验和：校验和是为了提供可靠的UDP首部和数据而设计，防止收到再网络传输中受损的UDP包</li></ul><p><img src="/../imgs/20th-March/format,png-20230309230439961.png" alt="UDP 头部格式"></p><p><img src="/../imgs/20th-March/format,png-20230309230534096.png" alt="TCP 头格式"></p><p>区别：</p><p>1.连接</p><ul><li>TCP是面向连接的传输层协议，传输数据前先要建立连接</li><li>UDP是不需要连接，即刻传输数据。</li></ul><p>2.服务对象</p><ul><li>TCP是一对一的两点服务，即一条连接只有两个端点</li><li>UDP支持一对一、一对多、多对多的交互通信</li></ul><p>3.可靠性</p><ul><li>TCP是可靠交付数据的，数据可以无差错、不丢失、不重复、按序到达。</li><li>UDP是尽最大努力交付，不保证可靠交付数据，但是可以基于UDP传输协议实现一个可靠的传输协议，比如QUIC协议</li></ul><p>4.拥塞控制，流量控制</p><ul><li>TCP由拥塞控制和流量控制机制，保证数据传输的安全性</li><li>UDP则没有，即使网络非常拥堵了，也不会影响UDP的发送速率。</li></ul><p>5.首部开销</p><ul><li>TCP首部长度较长，会有一定的开销，首部在没有使用选项时是20个字节，如果使用了选项字段则会变长的。</li><li>UDP首部只有8个字节，并且是固定不变的，开销较小</li></ul><ol start="6"><li>传输方式</li></ol><ul><li>TCP 是流式传输，没有边界，但保证顺序和可靠。</li><li>UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。</li></ul><p>7.分片不同</p><ul><li>TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。</li><li>UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。</li></ul><p><strong>TCP 和 UDP 应用场景：</strong></p><p>由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：</p><ul><li><code>FTP</code> 文件传输；</li><li>HTTP &#x2F; HTTPS；</li></ul><p>由于 UDP 面向无连接，它可以随时发送数据，再加上 UDP 本身的处理既简单又高效，因此经常用于：</p><ul><li>包总量较少的通信，如 <code>DNS</code> 、<code>SNMP</code> 等；</li><li>视频、音频等多媒体通信；</li><li>广播通信；</li></ul><h3 id="TCP重传、流量控制、拥塞控制"><a href="#TCP重传、流量控制、拥塞控制" class="headerlink" title="TCP重传、流量控制、拥塞控制"></a>TCP重传、流量控制、拥塞控制</h3><p>TCP 实现可靠传输的方式之一，是通过序列号与确认应答。</p><p>在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个确认应答消息，表示已收到消息。</p><p>但在错综复杂的网络，并不一定能如上图那么顺利能正常的数据传输，万一数据在传输过程中丢失了呢？</p><p>所以 TCP 针对数据包丢失的情况，会用<strong>重传机制</strong>解决。</p><p>接下来说说常见的重传机制：</p><ul><li>超时重传</li><li>快速重传</li><li>SACK</li><li>D-SACK</li></ul><h3 id="超时重传"><a href="#超时重传" class="headerlink" title="超时重传"></a>超时重传</h3><p>重传机制的其中一个方式，就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 <code>ACK</code> 确认应答报文，就会重发该数据，也就是我们常说的<strong>超时重传</strong>。</p><p>TCP 会在以下两种情况发生超时重传：</p><ul><li>数据包丢失</li><li>确认应答丢失</li></ul><p><img src="/../imgs/20th-March/5.jpg" alt="超时重传的两种情况"></p><p>超时触发重传存在的问题是，超时周期可能相对较长。那是不是可以有更快的方式呢？</p><p>于是就可以用「快速重传」机制来解决超时重发的时间等待。</p><h3 id="快速重传"><a href="#快速重传" class="headerlink" title="#快速重传"></a><a href="https://xiaolincoding.com/network/3_tcp/tcp_feature.html#%E5%BF%AB%E9%80%9F%E9%87%8D%E4%BC%A0">#</a>快速重传</h3><p>TCP 还有另外一种<strong>快速重传（Fast Retransmit）机制</strong>，它<strong>不以时间为驱动，而是以数据驱动重传</strong>。</p><p>快速重传机制，是如何工作的呢？其实很简单，一图胜千言。</p><p><img src="/../imgs/20th-March/10.jpg" alt="快速重传机制"></p><p>在上图，发送方发出了 1，2，3，4，5 份数据：</p><ul><li>第一份 Seq1 先送到了，于是就 Ack 回 2；</li><li>结果 Seq2 因为某些原因没收到，Seq3 到达了，于是还是 Ack 回 2；</li><li>后面的 Seq4 和 Seq5 都到了，但还是 Ack 回 2，因为 Seq2 还是没有收到；</li><li><strong>发送端收到了三个 Ack &#x3D; 2 的确认，知道了 Seq2 还没有收到，就会在定时器过期之前，重传丢失的 Seq2。</strong></li><li>最后，收到了 Seq2，此时因为 Seq3，Seq4，Seq5 都收到了，于是 Ack 回 6 。</li></ul><p>所以，快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。</p><p>快速重传机制只解决了一个问题，就是超时时间的问题，但是它依然面临着另外一个问题。就是<strong>重传的时候，是重传一个，还是重传所有的问题。</strong></p><p>举个例子，假设发送方发了 6 个数据，编号的顺序是 Seq1 ~ Seq6 ，但是 Seq2、Seq3 都丢失了，那么接收方在收到 Seq4、Seq5、Seq6 时，都是回复 ACK2 给发送方，但是发送方并不清楚这连续的 ACK2 是接收方收到哪个报文而回复的， 那是选择重传 Seq2 一个报文，还是重传 Seq2 之后已发送的所有报文呢（Seq2、Seq3、 Seq4、Seq5、 Seq6） 呢？</p><ul><li>如果只选择重传 Seq2 一个报文，那么重传的效率很低。因为对于丢失的 Seq3 报文，还得在后续收到三个重复的 ACK3 才能触发重传。</li><li>如果选择重传 Seq2 之后已发送的所有报文，虽然能同时重传已丢失的 Seq2 和 Seq3 报文，但是 Seq4、Seq5、Seq6 的报文是已经被接收过了，对于重传 Seq4 ～Seq6 折部分数据相当于做了一次无用功，浪费资源。</li></ul><p>可以看到，不管是重传一个报文，还是重传已发送的报文，都存在问题。</p><p>为了解决不知道该重传哪些 TCP 报文，于是就有 <code>SACK</code> 方法。</p><h3 id="SACK-方法"><a href="#SACK-方法" class="headerlink" title="SACK 方法"></a>SACK 方法</h3><p>还有一种实现重传机制的方式叫：<code>SACK</code>（ Selective Acknowledgment）， <strong>选择性确认</strong>。</p><p>这种方式需要在 TCP 头部「选项」字段里加一个 <code>SACK</code> 的东西，它<strong>可以将已收到的数据的信息发送给「发送方」</strong>，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以<strong>只重传丢失的数据</strong>。</p><p>如下图，发送方收到了三次同样的 ACK 确认报文，于是就会触发快速重发机制，通过 <code>SACK</code> 信息发现只有 <code>200~299</code> 这段数据丢失，则重发时，就只选择了这个 TCP 段进行重复。</p><p><img src="/../imgs/20th-March/11.jpg" alt="选择性确认"></p><h3 id="Duplicate-SACK"><a href="#Duplicate-SACK" class="headerlink" title="Duplicate SACK"></a>Duplicate SACK</h3><p>Duplicate SACK 又称 <code>D-SACK</code>，其主要<strong>使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。</strong></p><p>下面举例两个栗子，来说明 <code>D-SACK</code> 的作用。</p><p><img src="/../imgs/20th-March/12.jpg" alt="ACK 丢包"></p><ul><li>「接收方」发给「发送方」的两个 ACK 确认应答都丢失了，所以发送方超时后，重传第一个数据包（3000 ~ 3499）</li><li><strong>于是「接收方」发现数据是重复收到的，于是回了一个 SACK &#x3D; 3000~3500</strong>，告诉「发送方」 3000~3500 的数据早已被接收了，因为 ACK 都到了 4000 了，已经意味着 4000 之前的所有数据都已收到，所以这个 SACK 就代表着 <code>D-SACK</code>。</li><li>这样「发送方」就知道了，数据没有丢，是「接收方」的 ACK 确认报文丢了。</li></ul><p><img src="/../imgs/20th-March/13.jpg" alt="网络延时"></p><ul><li>数据包（1000~1499） 被网络延迟了，导致「发送方」没有收到 Ack 1500 的确认报文。</li><li>而后面报文到达的三个相同的 ACK 确认报文，就触发了快速重传机制，但是在重传后，被延迟的数据包（1000~1499）又到了「接收方」；</li><li><strong>所以「接收方」回了一个 SACK&#x3D;1000~1500，因为 ACK 已经到了 3000，所以这个 SACK 是 D-SACK，表示收到了重复的包。</strong></li><li>这样发送方就知道快速重传触发的原因不是发出去的包丢了，也不是因为回应的 ACK 包丢了，而是因为网络延迟了。</li></ul><p>可见，<code>D-SACK</code> 有这么几个好处：</p><ol><li>可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;</li><li>可以知道是不是「发送方」的数据包被网络延迟了;</li><li>可以知道网络中是不是把「发送方」的数据包给复制了;</li></ol><h2 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h2><p>发送方不能无脑的发数据给接收方，要考虑接收方处理能力。</p><p>如果一直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。</p><p>为了解决这种现象发生，<strong>TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。</strong></p><p>下面举个栗子，为了简单起见，假设以下场景：</p><ul><li>客户端是接收方，服务端是发送方</li><li>假设接收窗口和发送窗口相同，都为 <code>200</code></li><li>假设两个设备在整个传输过程中都保持相同的窗口大小，不受外界影响</li></ul><h2 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h2><blockquote><p>为什么要有拥塞控制呀，不是有流量控制了吗？</p></blockquote><p>前面的流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么。</p><p>一般来说，计算机网络都处在一个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。</p><p><strong>在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大….</strong></p><p>所以，TCP 不能忽略网络上发生的事，它被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量。</p><p>于是，就有了<strong>拥塞控制</strong>，控制的目的就是<strong>避免「发送方」的数据填满整个网络。</strong></p><p>为了在「发送方」调节所要发送数据的量，定义了一个叫做「<strong>拥塞窗口</strong>」的概念。</p><blockquote><p>什么是拥塞窗口？和发送窗口有什么关系呢？</p></blockquote><p><strong>拥塞窗口 cwnd</strong>是发送方维护的一个的状态变量，它会根据<strong>网络的拥塞程度动态变化的</strong>。</p><p>我们在前面提到过发送窗口 <code>swnd</code> 和接收窗口 <code>rwnd</code> 是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是swnd &#x3D; min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。</p><p>拥塞窗口 <code>cwnd</code> 变化的规则：</p><ul><li>只要网络中没有出现拥塞，<code>cwnd</code> 就会增大；</li><li>但网络中出现了拥塞，<code>cwnd</code> 就减少；</li></ul><blockquote><p>那么怎么知道当前网络是否出现了拥塞呢？</p></blockquote><p>其实只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是<strong>发生了超时重传，就会认为网络出现了拥塞。</strong></p><blockquote><p>拥塞控制有哪些控制算法？</p></blockquote><p>拥塞控制主要是四个算法：</p><ul><li>慢启动</li><li>拥塞避免</li><li>拥塞发生</li><li>快速恢复</li></ul><h4 id="慢启动"><a href="#慢启动" class="headerlink" title="慢启动"></a>慢启动</h4><p>TCP在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量如果一上来就发大量的数据，就是再给网络添堵。</p><p><strong>当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。</strong></p><ul><li>连接建立完成后，一开始初始化 <code>cwnd = 1</code>，表示可以传一个 <code>MSS</code> 大小的数据。</li><li>当收到一个 ACK 确认应答后，cwnd 增加 1，于是一次能够发送 2 个</li><li>当收到 2 个的 ACK 确认应答后， cwnd 增加 2，于是就可以比之前多发2 个，所以这一次能够发送 4 个</li><li>当这 4 个的 ACK 确认到来的时候，每个确认 cwnd 增加 1， 4 个确认 cwnd 增加 4，于是就可以比之前多发 4 个，所以这一次能够发送 8 个。</li></ul><p>可以看出慢启动算法，发包的个数是<strong>指数性的增长</strong>。</p><blockquote><p>那慢启动涨到什么时候是个头呢？</p></blockquote><p>有一个叫慢启动门限 <code>ssthresh</code> （slow start threshold）状态变量。</p><ul><li>当 <code>cwnd</code> &lt; <code>ssthresh</code> 时，使用慢启动算法。</li><li>当 <code>cwnd</code> &gt;&#x3D; <code>ssthresh</code> 时，就会使用「拥塞避免算法」。</li></ul><h4 id="拥塞避免算法"><a href="#拥塞避免算法" class="headerlink" title="拥塞避免算法"></a>拥塞避免算法</h4><p>前面说道，当拥塞窗口 <code>cwnd</code> 「超过」慢启动门限 <code>ssthresh</code> 就会进入拥塞避免算法。</p><p>一般来说 <code>ssthresh</code> 的大小是 <code>65535</code> 字节。</p><p>那么进入拥塞避免算法后，它的规则是：<strong>每当收到一个 ACK 时，cwnd 增加 1&#x2F;cwnd。</strong></p><p>接上前面的慢启动的栗子，现假定 <code>ssthresh</code> 为 <code>8</code>：</p><ul><li>当 8 个 ACK 应答确认到来时，每个确认增加 1&#x2F;8，8 个 ACK 确认 cwnd 一共增加 1，于是这一次能够发送 9 个 <code>MSS</code> 大小的数据，变成了<strong>线性增长。</strong></li></ul><p>所以，我们可以发现，拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长，还是增长阶段，但是增长速度缓慢了一些。</p><p>就这么一直增长着后，网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传。</p><p>当触发了重传机制，也就进入了「拥塞发生算法」。</p><h3 id="拥塞发生"><a href="#拥塞发生" class="headerlink" title="#拥塞发生"></a><a href="https://xiaolincoding.com/network/3_tcp/tcp_feature.html#%E6%8B%A5%E5%A1%9E%E5%8F%91%E7%94%9F">#</a>拥塞发生</h3><p>当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：</p><ul><li>超时重传</li><li>快速重传</li></ul><p>这两种使用的拥塞发送算法是不同的，接下来分别来说说。</p><blockquote><p>发生超时重传的拥塞发生算法</p></blockquote><p>当发生了「超时重传」，则就会使用拥塞发生算法。</p><p>这个时候，ssthresh 和 cwnd 的值会发生变化：</p><ul><li><code>ssthresh</code> 设为 <code>cwnd/2</code>，</li><li><code>cwnd</code> 重置为 <code>1</code> （是恢复为 cwnd 初始化值，我这里假定 cwnd 初始化值 1）</li></ul><p><img src="/../imgs/20th-March/29.jpg" alt="拥塞发送 —— 超时重传"></p><p>接着，就重新开始慢启动，慢启动是会突然减少数据流的。这真是一旦「超时重传」，马上回到解放前。但是这种方式太激进了，反应也很强烈，会造成网络卡顿。</p><p>就好像本来在秋名山高速漂移着，突然来个紧急刹车，轮胎受得了吗。。。</p><blockquote><p>发生快速重传的拥塞发生算法</p></blockquote><p>还有更好的方式，前面我们讲过「快速重传算法」。当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。</p><p>TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 <code>ssthresh</code> 和 <code>cwnd</code> 变化如下：</p><ul><li><code>cwnd = cwnd/2</code> ，也就是设置为原来的一半;</li><li><code>ssthresh = cwnd</code>;</li><li>进入快速恢复算法</li></ul><h3 id="快速恢复"><a href="#快速恢复" class="headerlink" title="快速恢复"></a>快速恢复</h3><p>快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 <code>RTO</code> 超时那么强烈。</p><p>正如前面所说，进入快速恢复之前，<code>cwnd</code> 和 <code>ssthresh</code> 已被更新了：</p><ul><li><code>cwnd = cwnd/2</code> ，也就是设置为原来的一半;</li><li><code>ssthresh = cwnd</code>;</li></ul><p>然后，进入快速恢复算法如下：</p><ul><li>拥塞窗口 <code>cwnd = ssthresh + 3</code> （ 3 的意思是确认有 3 个数据包被收到了）；</li><li>重传丢失的数据包；</li><li>如果再收到重复的 ACK，那么 cwnd 增加 1；</li><li>如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态；</li></ul><p>快速恢复算法的变化过程如下图：</p><p><img src="/../imgs/20th-March/%E6%8B%A5%E5%A1%9E%E5%8F%91%E7%94%9F-%E5%BF%AB%E9%80%9F%E9%87%8D%E4%BC%A0.drawio.png" alt="快速重传和快速恢复"></p><h2 id="Mysql"><a href="#Mysql" class="headerlink" title="Mysql"></a>Mysql</h2><h3 id="事务有哪些特性？"><a href="#事务有哪些特性？" class="headerlink" title="事务有哪些特性？"></a>事务有哪些特性？</h3><p>事务是由MySQL的引擎来实现的，我们常见的InnoDB引擎它是支持事务的。</p><p>不过并不是所有的引擎都能支持事务，比如 MySQL 原生的 MyISAM 引擎就不支持事务，也正是这样，所以大多数 MySQL 的引擎都是用 InnoDB。</p><p>事务看起来感觉简单，但是要实现事务必须要遵守 4 个特性，分别如下：</p><ul><li><strong>原子性（Atomicity）：</strong>一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间的某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态。</li><li><strong>一致性（Consistency）：</strong>是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态。比如，用户 A 和用户 B 在银行分别有 800 元和 600 元，总共 1400 元，用户 A 给用户 B 转账 200 元，分为两个步骤，从 A 的账户扣除 200 元和对 B 的账户增加 200 元。一致性就是要求上述步骤操作后，最后的结果是用户 A 还有 600 元，用户 B 有 800 元，总共 1400 元，而不会出现用户 A 扣除了 200 元，但用户 B 未增加的情况（该情况，用户 A 和 B 均为 600 元，总共 1200 元）。</li><li><strong>隔离性（Isolation）</strong>：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致，因为多个事务同时使用相同的数据时，不会相互干扰，每个事务都有一个完整的数据空间，对其他并发事务是隔离的。也就是说，消费者购买商品这个事务，是不影响其他消费者购买的。</li><li><strong>持久性（Durability）</strong>：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。</li></ul><p>InnoDB 引擎通过什么技术来保证事务的这四个特性的呢？</p><ul><li>持久性是通过 redo log （重做日志）来保证的；</li><li>原子性是通过 undo log（回滚日志） 来保证的；</li><li>隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的；</li><li>一致性则是通过持久性+原子性+隔离性来保证；</li></ul><h2 id="并行事务会引发什么问题？"><a href="#并行事务会引发什么问题？" class="headerlink" title="并行事务会引发什么问题？"></a>并行事务会引发什么问题？</h2><p>MySQL 服务端是允许多个客户端连接的，这意味着 MySQL 会出现同时处理多个事务的情况。</p><p>那么<strong>在同时处理多个事务的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题</strong>。</p><p>接下来，通过举例子给大家说明，这些问题是如何发生的。</p><h3 id="脏读"><a href="#脏读" class="headerlink" title="#脏读"></a><a href="https://xiaolincoding.com/mysql/transaction/mvcc.html#%E8%84%8F%E8%AF%BB">#</a>脏读</h3><p><strong>如果一个事务「读到」了另一个「未提交事务修改过的数据」，就意味着发生了「脏读」现象。</strong></p><p>假设有 A 和 B 这两个事务同时在处理，事务 A 先开始从数据库中读取小林的余额数据，然后再执行更新操作，如果此时事务 A 还没有提交事务，而此时正好事务 B 也从数据库中读取小林的余额数据，那么事务 B 读取到的余额数据是刚才事务 A 更新后的数据，即使没有提交事务。</p><p>因为事务 A 是还没提交事务的，也就是它随时可能发生回滚操作，<strong>如果在上面这种情况事务 A 发生了回滚，那么事务 B 刚才得到的数据就是过期的数据，这种现象就被称为脏读。</strong></p><h3 id="不可重复读"><a href="#不可重复读" class="headerlink" title="不可重复读"></a>不可重复读</h3><p><strong>在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了「不可重复读」现象。</strong></p><p>假设有 A 和 B 这两个事务同时在处理，事务 A 先开始从数据库中读取小林的余额数据，然后继续执行代码逻辑处理，<strong>在这过程中如果事务 B 更新了这条数据，并提交了事务，那么当事务 A 再次读取该数据时，就会发现前后两次读到的数据是不一致的，这种现象就被称为不可重复读。</strong></p><h3 id="幻读"><a href="#幻读" class="headerlink" title="幻读"></a>幻读</h3><p>在一个事务内多次查询某个符合查询条件的记录数量，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了幻读现象。</p><p>假设有 A 和 B 这两个事务同时在处理，事务 A 先开始从数据库查询账户余额大于 100 万的记录，发现共有 5 条，然后事务 B 也按相同的搜索条件也是查询出了 5 条记录。</p><p>接下来，事务 A 插入了一条余额超过 100 万的账号，并提交了事务，此时数据库超过 100 万余额的账号个数就变为 6。</p><p>然后事务 B 再次查询账户余额大于 100 万的记录，此时查询到的记录数量有 6 条，<strong>发现和前一次读到的记录数量不一样了，就感觉发生了幻觉一样，这种现象就被称为幻读。</strong></p><h2 id="事务的隔离级别有哪些？"><a href="#事务的隔离级别有哪些？" class="headerlink" title="事务的隔离级别有哪些？"></a>事务的隔离级别有哪些？</h2><p>前面我们提到，当多个事务并发执行时可能会遇到「脏读、不可重复读、幻读」的现象，这些现象会对事务的一致性产生不同程序的影响。</p><ul><li>脏读：读到其他事务未提交的数据；</li><li>不可重复读：前后读取的数据不一致；</li><li>幻读：前后读取的记录数量不一致。</li></ul><p>SQL 标准提出了四种隔离级别来规避这些现象，隔离级别越高，性能效率就越低，这四个隔离级别如下：</p><ul><li><strong>读未提交（*read uncommitted*）</strong>，指一个事务还没提交时，它做的变更就能被其他事务看到；</li><li><strong>读提交（*read committed*）</strong>，指一个事务提交之后，它做的变更才能被其他事务看到；</li><li><strong>可重复读（*repeatable read*）</strong>，指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，<strong>MySQL InnoDB 引擎的默认隔离级别</strong>；</li><li><strong>串行化（*serializable* ）</strong>；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；</li></ul><p>针对不同的隔离级别，并发事务时可能发生的现象也会不同。</p><ul><li>在「读未提交」隔离级别下，可能发生脏读、不可重复读和幻读现象；</li><li>在「读提交」隔离级别下，可能发生不可重复读和幻读现象，但是不可能发生脏读现象；</li><li>在「可重复读」隔离级别下，可能发生幻读现象，但是不可能脏读和不可重复读现象；</li><li>在「串行化」隔离级别下，脏读、不可重复读和幻读现象都不可能会发生。</li></ul><p>MySQL InnoDB 引擎的默认隔离级别虽然是「可重复读」，但是它很大程度上避免幻读现象（并不是完全解决了）解决的方案有两种：</p><ul><li>针对<strong>快照读</strong>（普通 select 语句），是<strong>通过 MVCC 方式解决了幻读</strong>，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。</li><li>针对<strong>当前读</strong>（select … for update 等语句），是<strong>通过 next-key lock（记录锁+间隙锁）方式解决了幻读</strong>，因为当执行 select … for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。</li></ul><h2 id="Read-View-在-MVCC-里如何工作的？"><a href="#Read-View-在-MVCC-里如何工作的？" class="headerlink" title="Read View 在 MVCC 里如何工作的？"></a>Read View 在 MVCC 里如何工作的？</h2><p>我们需要了解两个知识：</p><ul><li>Read View 中四个字段作用；</li><li>聚簇索引记录中两个跟事务有关的隐藏列；</li></ul><p>那 Read View 到底是个什么东西？</p><p><img src="/../imgs/20th-March/readview%E7%BB%93%E6%9E%84.drawio.png" alt="mvcc"></p><p>Read View 有四个重要的字段：</p><ul><li>m_ids ：指的是在创建 Read View 时，当前数据库中「活跃事务」的<strong>事务 id 列表</strong>，注意是一个列表，<strong>“活跃事务”指的就是，启动了但还没提交的事务</strong>。</li><li>min_trx_id ：指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 <strong>id 最小的事务</strong>，也就是 m_ids 的最小值。</li><li>max_trx_id ：这个并不是 m_ids 的最大值，而是<strong>创建 Read View 时当前数据库中应该给下一个事务的 id 值</strong>，也就是全局事务中最大的事务 id 值 + 1；</li><li>creator_trx_id ：指的是<strong>创建该 Read View 的事务的事务 id</strong>。</li></ul><p>知道了 Read View 的字段，我们还需要了解聚簇索引记录中的两个隐藏列。</p><p><img src="/../imgs/20th-March/f595d13450878acd04affa82731f76c5.png" alt="隐藏列"></p><p>对于使用 InnoDB 存储引擎的数据库表，它的聚簇索引记录中都包含下面两个隐藏列：</p><ul><li>trx_id，当一个事务对某条聚簇索引记录进行改动时，就会<strong>把该事务的事务 id 记录在 trx_id 隐藏列里</strong>；</li><li>roll_pointer，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后<strong>这个隐藏列是个指针，指向每一个旧版本记录</strong>，于是就可以通过它找到修改前的记录。</li></ul><p>在创建 Read View 后，我们可以将记录中的 trx_id 划分这三种情况：</p><p><img src="/../imgs/20th-March/ReadView.drawio.png" alt="trx_id"></p><p>一个事务去访问记录的时候，除了自己的更新记录总是可见之外，还有这几种情况：</p><ul><li>如果记录的 trx_id 值小于 Read View 中的 <code>min_trx_id</code> 值，表示这个版本的记录是在创建 Read View <strong>前</strong>已经提交的事务生成的，所以该版本的记录对当前事务<strong>可见</strong>。</li><li>如果记录的 trx_id 值大于等于 Read View 中的 <code>max_trx_id</code> 值，表示这个版本的记录是在创建 Read View <strong>后</strong>才启动的事务生成的，所以该版本的记录对当前事务<strong>不可见</strong>。</li><li>如果记录的 trx_id 值在 Read View 的<code>min_trx_id</code>和<code>max_trx_id</code>之间，需要判断 <code>trx_id</code> 是否在 m_ids 列表中：<ul><li>如果记录的 trx_id <strong>在</strong> <code>m_ids</code> 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务<strong>不可见</strong>。</li><li>如果记录的 trx_id <strong>不在</strong> <code>m_ids</code>列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务<strong>可见</strong>。</li></ul></li></ul><p><strong>这种通过「版本链」来控制并发事务访问同一个记录时的行为就叫 MVCC（多版本并发控制）。</strong></p><h2 id="可重复读是如何工作的？"><a href="#可重复读是如何工作的？" class="headerlink" title="可重复读是如何工作的？"></a>可重复读是如何工作的？</h2><p><strong>可重复读隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View</strong>。</p><p>假设事务 A （事务 id 为51）启动后，紧接着事务 B （事务 id 为52）也启动了，那这两个事务创建的 Read View 如下：</p><p><img src="/../imgs/20th-March/%E4%BA%8B%E5%8A%A1ab%E7%9A%84%E8%A7%86%E5%9B%BE-new.png" alt="可重复读ReadView"></p><p>事务 A 和 事务 B 的 Read View 具体内容如下：</p><ul><li>在事务 A 的 Read View 中，它的事务 id 是 51，由于它是第一个启动的事务，所以此时活跃事务的事务 id 列表就只有 51，活跃事务的事务 id 列表中最小的事务 id 是事务 A 本身，下一个事务 id 则是 52。</li><li>在事务 B 的 Read View 中，它的事务 id 是 52，由于事务 A 是活跃的，所以此时活跃事务的事务 id 列表是 51 和 52，<strong>活跃的事务 id 中最小的事务 id 是事务 A</strong>，下一个事务 id 应该是 53。</li></ul><p>接着，在可重复读隔离级别下，事务 A 和事务 B 按顺序执行了以下操作：</p><ul><li>事务 B 读取小林的账户余额记录，读到余额是 100 万；</li><li>事务 A 将小林的账户余额记录修改成 200 万，并没有提交事务；</li><li>事务 B 读取小林的账户余额记录，读到余额还是 100 万；</li><li>事务 A 提交事务；</li><li>事务 B 读取小林的账户余额记录，读到余额依然还是 100 万；</li></ul><p>事务 B 第一次读小林的账户余额记录，在找到记录后，它会先看这条记录的 trx_id，此时<strong>发现 trx_id 为 50，比事务 B 的 Read View 中的 min_trx_id 值（51）还小，这意味着修改这条记录的事务早就在事务 B 启动前提交过了，所以该版本的记录对事务 B 可见的</strong>，也就是事务 B 可以获取到这条记录。</p><p>接着，事务 A 通过 update 语句将这条记录修改了（还未提交事务），将小林的余额改成 200 万，这时 MySQL 会记录相应的 undo log，并以链表的方式串联起来，形成<strong>版本链</strong>，如下图：</p><p><img src="/../imgs/20th-March/%E4%BA%8B%E5%8A%A1ab%E7%9A%84%E8%A7%86%E5%9B%BE2.png" alt="版本链"></p><p>你可以在上图的「记录的字段」看到，由于事务 A 修改了该记录，以前的记录就变成旧版本记录了，于是最新记录和旧版本记录通过链表的方式串起来，而且最新记录的 trx_id 是事务 A 的事务 id（trx_id &#x3D; 51）。</p><p>然后事务 B 第二次去读取该记录，<strong>发现这条记录的 trx_id 值为 51，在事务 B 的 Read View 的 min_trx_id 和 max_trx_id 之间，则需要判断 trx_id 值是否在 m_ids 范围内，判断的结果是在的，那么说明这条记录是被还未提交的事务修改的，这时事务 B 并不会读取这个版本的记录。而是沿着 undo log 链条往下找旧版本的记录，直到找到 trx_id 「小于」事务 B 的 Read View 中的 min_trx_id 值的第一条记录</strong>，所以事务 B 能读取到的是 trx_id 为 50 的记录，也就是小林余额是 100 万的这条记录。</p><p>最后，当事物 A 提交事务后，<strong>由于隔离级别时「可重复读」，所以事务 B 再次读取记录时，还是基于启动事务时创建的 Read View 来判断当前版本的记录是否可见。所以，即使事物 A 将小林余额修改为 200 万并提交了事务， 事务 B 第三次读取记录时，读到的记录都是小林余额是 100 万的这条记录</strong>。</p><h2 id="读提交是如何工作的？"><a href="#读提交是如何工作的？" class="headerlink" title="读提交是如何工作的？"></a>读提交是如何工作的？</h2><p><strong>读提交隔离级别是在每次读取数据时，都会生成一个新的 Read View</strong>。</p><p>也意味着，事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致，因为可能这期间另外一个事务修改了该记录，并提交了事务。</p><p>那读提交隔离级别是怎么工作呢？我们还是以前面的例子来聊聊。</p><p>假设事务 A （事务 id 为51）启动后，紧接着事务 B （事务 id 为52）也启动了，接着按顺序执行了以下操作：</p><ul><li>事务 B 读取数据（创建 Read View），小林的账户余额为 100 万；</li><li>事务 A 修改数据（还没提交事务），将小林的账户余额从 100 万修改成了 200 万；</li><li>事务 B 读取数据（创建 Read View），小林的账户余额为 100 万；</li><li>事务 A 提交事务；</li><li>事务 B 读取数据（创建 Read View），小林的账户余额为 200 万；</li></ul><h2 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h2><h2 id="quicklist"><a href="#quicklist" class="headerlink" title="quicklist"></a>quicklist</h2><p>在 Redis 3.0 之前，List 对象的底层数据结构是双向链表或者压缩列表。然后在 Redis 3.2 的时候，List 对象的底层改由 quicklist 数据结构实现。</p><p>其实 quicklist 就是「双向链表 + 压缩列表」组合，因为一个 quicklist 就是一个链表，而链表中的每个元素又是一个压缩列表。</p><p>在前面讲压缩列表的时候，我也提到了压缩列表的不足，虽然压缩列表是通过紧凑型的内存布局节省了内存开销，但是因为它的结构设计，如果保存的元素数量增加，或者元素变大了，压缩列表会有「连锁更新」的风险，一旦发生，会造成性能下降。</p><p>quicklist 解决办法，<strong>通过控制每个链表节点中的压缩列表的大小或者元素个数，来规避连锁更新的问题。因为压缩列表元素越少或越小，连锁更新带来的影响就越小，从而提供了更好的访问性能。</strong></p><h3 id="quicklist-结构设计"><a href="#quicklist-结构设计" class="headerlink" title="#quicklist 结构设计"></a><a href="https://xiaolincoding.com/redis/data_struct/data_struct.html#quicklist-%E7%BB%93%E6%9E%84%E8%AE%BE%E8%AE%A1">#</a>quicklist 结构设计</h3><p>quicklist 的结构体跟链表的结构体类似，都包含了表头和表尾，区别在于 quicklist 的节点是 quicklistNode。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">quicklist</span> &#123;</span><br>    <span class="hljs-comment">//quicklist的链表头</span><br>    quicklistNode *head;      <span class="hljs-comment">//quicklist的链表头</span><br>    <span class="hljs-comment">//quicklist的链表尾</span><br>    quicklistNode *tail; <br>    <span class="hljs-comment">//所有压缩列表中的总元素个数</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> count;<br>    <span class="hljs-comment">//quicklistNodes的个数</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> len;       <br>    ...<br>&#125; quicklist;<br></code></pre></td></tr></table></figure><p>接下来看看，quicklistNode 的结构定义：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">quicklistNode</span> &#123;</span><br>    <span class="hljs-comment">//前一个quicklistNode</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">quicklistNode</span> *<span class="hljs-title">prev</span>;</span>     <span class="hljs-comment">//前一个quicklistNode</span><br>    <span class="hljs-comment">//下一个quicklistNode</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">quicklistNode</span> *<span class="hljs-title">next</span>;</span>     <span class="hljs-comment">//后一个quicklistNode</span><br>    <span class="hljs-comment">//quicklistNode指向的压缩列表</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> *zl;              <br>    <span class="hljs-comment">//压缩列表的的字节大小</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> sz;                <br>    <span class="hljs-comment">//压缩列表的元素个数</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> count : <span class="hljs-number">16</span>;        <span class="hljs-comment">//ziplist中的元素个数 </span><br>    ....<br>&#125; quicklistNode;<br></code></pre></td></tr></table></figure><p>可以看到，quicklistNode 结构体里包含了前一个节点和下一个节点指针，这样每个 quicklistNode 形成了一个双向链表。但是链表节点的元素不再是单纯保存元素值，而是保存了一个压缩列表，所以 quicklistNode 结构体里有个指向压缩列表的指针 *zl。</p><p><img src="/../imgs/20th-March/f46cbe347f65ded522f1cc3fd8dba549.png" alt="quicklist"></p><p>在向 quicklist 添加一个元素的时候，不会像普通的链表那样，直接新建一个链表节点。而是会检查插入位置的压缩列表是否能容纳该元素，如果能容纳就直接保存到 quicklistNode 结构里的压缩列表，如果不能容纳，才会新建一个新的 quicklistNode 结构。</p><p>quicklist 会控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来规避潜在的连锁更新的风险，但是这并没有完全解决连锁更新的问题。</p><h2 id="listpack"><a href="#listpack" class="headerlink" title="listpack"></a>listpack</h2><p>quicklist 虽然通过控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来减少连锁更新带来的性能影响，但是并没有完全解决连锁更新的问题。</p><p>因为 quicklistNode 还是用了压缩列表来保存元素，压缩列表连锁更新的问题，来源于它的结构设计，所以要想彻底解决这个问题，需要设计一个新的数据结构。</p><p>于是，Redis 在 5.0 新设计一个数据结构叫 listpack，目的是替代压缩列表，它最大特点是 listpack 中每个节点不再包含前一个节点的长度了，压缩列表每个节点正因为需要保存前一个节点的长度字段，就会有连锁更新的隐患。</p><p><strong>我看了 Redis 的 Github，在最新 6.2 发行版本中，Redis Hash 对象、ZSet 对象的底层数据结构的压缩列表还未被替换成 listpack，而 Redis 的最新代码（还未发布版本）已经将所有用到压缩列表底层数据结构的 Redis 对象替换成 listpack 数据结构来实现，估计不久将来，Redis 就会发布一个将压缩列表为 listpack 的发行版本</strong>。</p><h3 id="listpack-结构设计"><a href="#listpack-结构设计" class="headerlink" title="#listpack 结构设计"></a><a href="https://xiaolincoding.com/redis/data_struct/data_struct.html#listpack-%E7%BB%93%E6%9E%84%E8%AE%BE%E8%AE%A1">#</a>listpack 结构设计</h3><p>listpack 采用了压缩列表的很多优秀的设计，比如还是用一块连续的内存空间来紧凑地保存数据，并且为了节省内存的开销，listpack 节点会采用不同的编码方式保存不同大小的数据。</p><p>我们先看看 listpack 结构：</p><p><img src="/../imgs/20th-March/4d2dc376b5fd68dae70d9284ae82b73a.png" alt="listpack结构"></p><p>listpack 头包含两个属性，分别记录了 listpack 总字节数和元素数量，然后 listpack 末尾也有个结尾标识。图中的 listpack entry 就是 listpack 的节点了。</p><p>每个 listpack 节点结构如下：</p><p><img src="/../imgs/20th-March/c5fb0a602d4caaca37ff0357f05b0abf.png" alt="listpack entry"></p><p>主要包含三个方面内容：</p><ul><li>encoding，定义该元素的编码类型，会对不同长度的整数和字符串进行编码；</li><li>data，实际存放的数据；</li><li>len，encoding+data的总长度；</li></ul><p>可以看到，<strong>listpack 没有压缩列表中记录前一个节点长度的字段了，listpack 只记录当前节点的长度，当我们向 listpack 加入一个新元素的时候，不会影响其他节点的长度字段的变化，从而避免了压缩列表的连锁更新问题</strong>。</p><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p><a href="https://www.nowcoder.com/practice/886370fe658f41b498d40fb34ae76ff9?tpId=295&tqId=1377477&ru=/exam/company&qru=/ta/format-top101/question-ranking&sourceUrl=/exam/company"><strong>链表中倒数最后k个结点</strong></a></p><p><img src="/../imgs/20th-March/image-20240320214547723.png" alt="链表中倒数最后k个节点"></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs C++"><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">ListNode</span> &#123;<br> *<span class="hljs-type">int</span> val;<br> *<span class="hljs-keyword">struct</span> <span class="hljs-title class_">ListNode</span> *next;<br> *<span class="hljs-built_in">ListNode</span>(<span class="hljs-type">int</span> x) : <span class="hljs-built_in">val</span>(x), <span class="hljs-built_in">next</span>(<span class="hljs-literal">nullptr</span>) &#123;&#125;<br>&#125;;<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 代码中的类名、方法名、参数名已经指定，请勿修改，直接返回方法规定的值即可</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * </span><br><span class="hljs-comment">     * @param pHead ListNode类 </span><br><span class="hljs-comment">     * @param k int整型 </span><br><span class="hljs-comment">     * @return ListNode类</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-function">ListNode* <span class="hljs-title">FindKthToTail</span><span class="hljs-params">(ListNode* pHead, <span class="hljs-type">int</span> k)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span>(pHead == <span class="hljs-literal">nullptr</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">nullptr</span>;<br>        ListNode* fast = pHead,*slow = pHead;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; k; i++) &#123;<br>            fast = fast-&gt;next;<br>            <span class="hljs-keyword">if</span>(fast == <span class="hljs-literal">nullptr</span>&amp;&amp;i!=k<span class="hljs-number">-1</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">nullptr</span>;<br>        &#125;<br>        <span class="hljs-keyword">while</span>(fast) &#123;<br>            fast = fast-&gt;next;<br>            slow = slow-&gt;next;<br>        &#125;<br>        <span class="hljs-keyword">return</span> slow;<br>    &#125;<br>&#125;;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-type">int</span> n;<br>    cin&gt;&gt;n;<br>    ListNode* dummyhead = <span class="hljs-keyword">new</span> <span class="hljs-built_in">ListNode</span>(<span class="hljs-number">-1</span>);<br>    ListNode* curr = dummyhead;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i++) &#123;<br>        <span class="hljs-type">int</span> x;<br>        cin&gt;&gt;x;<br>        curr-&gt;next = <span class="hljs-keyword">new</span> <span class="hljs-built_in">ListNode</span>(x);<br>      curr = curr-&gt;next;<br>    &#125;<br>    Solution sol1;<br>    <span class="hljs-type">int</span> k;<br>    cin&gt;&gt;k;<br>    ListNode* ans = sol.<span class="hljs-built_in">FindKthToTail</span>(dummyhead-&gt;next,k);<br>    <span class="hljs-keyword">while</span>(ans) &#123;<br>        cout&lt;&lt;ans-&gt;val&lt;&lt;<span class="hljs-string">&quot; &quot;</span>;<br>      ans = ans-&gt;next;<br>    &#125;<br>    cout&lt;&lt;<span class="hljs-string">&#x27;\n&#x27;</span>;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>今天感觉体验还不错 但是不知道过没过 不过过了也得考虑去不去吧</p><p>周五字节 先抠八股和算法 周一美团 重点sql和算法 周二快手 重点看看824</p>]]></content>
    
    
    <categories>
      
      <category>八股</category>
      
    </categories>
    
    
    <tags>
      
      <tag>diary</tag>
      
      <tag>八股</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>19th-March</title>
    <link href="/2024/03/19/19th-March/"/>
    <url>/2024/03/19/19th-March/</url>
    
    <content type="html"><![CDATA[<h1 id="面经"><a href="#面经" class="headerlink" title="面经"></a>面经</h1><p>刚好都是字节国际电商？ 估计问的就差不多，所以偷一下看看</p><h2 id="OS"><a href="#OS" class="headerlink" title="OS"></a>OS</h2><h3 id="虚拟内存相关"><a href="#虚拟内存相关" class="headerlink" title="虚拟内存相关"></a>虚拟内存相关</h3><h4 id="内存虚拟化是什么，有什么目的？"><a href="#内存虚拟化是什么，有什么目的？" class="headerlink" title="内存虚拟化是什么，有什么目的？"></a>内存虚拟化是什么，有什么目的？</h4><p>内存虚拟化是一种将物理内存资源抽象、管理和分配的技术。它允许将计算机的物理内存划分为独立的、隔离的虚拟内存块，每个虚拟内存块都有操作系统或虚拟机管理。内存虚拟化可以在多个层次实现，如硬件层、操作系统层或应用程序层。</p><p>目的：</p><ul><li><strong>资源隔离与共享：</strong>内存虚拟化可以在不同的进程、应用程序或虚拟机之间隔离内存资源，从而提高系统的稳定性和安全性。同时，内存虚拟化还支持灵活地共享内存资源，以实现负载均衡和资源利用率最大化。</li><li><strong>易用性：</strong>内存虚拟化简化了内存管理，使得程序员无需关注物理内存的具体细节。程序员可以专注于编写代码，而操作系统和硬件负责处理内存分配、回收等问题。</li><li><strong>容错和回复：</strong>内存虚拟化有助于实现容错和故障恢复。当系统发生故障时，可以将虚拟内存的状态保存到磁盘上，然后再另一台计算机上恢复虚拟内存状态，以实现快速恢复（没太懂？）</li><li><strong>内存优化：</strong>内存虚拟化支持一些内存优化技术，如按需分配、内存去重和内存压缩。这些技术可以提高内存资源的利用率，降低内存成本。</li><li><strong>进程保护：</strong>每个进程都有自己的虚拟地址空间，这样就能防止一个进程意外或恶意的访问另一个进程的内存。提高系统的稳定性和安全性。</li></ul><h4 id="物理内存与虚拟内存的映射机制"><a href="#物理内存与虚拟内存的映射机制" class="headerlink" title="物理内存与虚拟内存的映射机制"></a>物理内存与虚拟内存的映射机制</h4><p>物理内存和虚拟内存的映射机制是计算机系统中实现内存虚拟化的关键技术。虚拟内存到物理内存的映射方式一般有分段和分页两种，由于分段机制内存碎片较多，常用的是分页机制。映射过程有内存管理单元（MMU）和操作系统共同完成。</p><ul><li><p><strong>分页机制：</strong>在分页系统中，虚拟内存和物理内存都被划分为固定大小的单元，称为页。虚拟页的大小和物理页相同，通常为4KB或更大。分页系统的主要目的是将虚拟内存中的页映射到物理内存中的页。</p></li><li><p><strong>页表：</strong>页表是一种数据结构，用于存储虚拟页到物理页的映射关系。每个进程都有自己的页表，由操作系统管理。页表中的每个条目包含一个虚拟页号和对应的物理页号。当CPU访问虚拟内存时，MMU会使用页表将虚拟地址转换为物理地址。</p></li><li><p><strong>地址转换：</strong>虚拟地址通常由两部分组成：虚拟页号（VPN）和页内偏移（offset）。虚拟页号用于查找页表中相应的物理页号，而页内偏移表示在物理页中的具体位置。地址抓换过程如下：</p><ol><li>CPU生成一个虚拟地址</li><li>MMU从虚拟地址中提取虚拟页号和页内偏移</li><li>MMU使用VPN在页表中查找对应的物理页号（PPN）</li><li>MMU将物理页号与页内偏移组合成物理地址</li><li>CPU使用物理地址访问物理内存</li></ol></li><li><p>页面置换和缺页中断：当虚拟页尚未加载到物理内存时，发生页面缺失（page fault）。在这种情况下，操作系统需要从磁盘或其他存储设备中加载所需的虚拟页，并将其映射到物理内存。为了腾出空间，操作系统可能需要选择一个已加载的页面，将其换出到磁盘。页面置换算法用于决定哪个页面应该被换出</p></li><li><p>多级页表：多级页表使一种用于减少页表大小的技术。在具有大量虚拟地址空间的系统中，使用单级页表可能导致浪费大量内存。多级页表通过将虚拟地址空间划分为多个层次来减小页表的大小。每个层次都有自己的页表，只有在需要时才会分配。这样可以大大减小内存开销。</p></li><li><p>快表（TLB）：快表，也称为转换后援缓冲（Translation Lookaside Buffer），是一种硬件缓存，用于加速虚拟地址到物理地址的转换过程。TLB将最近使用过的虚拟地址到物理地址的映射存储在高速缓存中，以便快速查找。当MMU需要转换一个虚拟地址时，它首先检查TLB是否包含所需的映射。如何TLB中存在映射，MMU可以避免访问内存中的页表，从而加速地址转换过程。</p></li><li><p>内存分配策略：操作系统使用不同的内存分配策略来管理虚拟内存和物理内存之间的映射。按需分配是一种常用的策略，它旨在进程实际访问虚拟内存时才将虚拟页加载到物理内存。预取是另一种策略，它根据进程的访问模式提前加载可能需要的虚拟页，以减少页面缺失的开销。</p></li><li><p>内存共享：内存共享是一种允许多个进程访问相同物理内存区域的技术。通过将不同 进程的虚拟地址映射到同一物理页，操作系统可以实现内存共享。这种技术在共享库、进程间通信和内存去重等场景中非常有用。</p></li></ul><p>物理内存和虚拟内存的映射机制通过分页、页表、地址转换、多级页表、TLB、内存分配策略等技术实现。这种映射提供了内存虚拟化、进程隔离和内存优化等关键功能。</p><h3 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h3><h4 id="进程、线程、协程区别与联系"><a href="#进程、线程、协程区别与联系" class="headerlink" title="进程、线程、协程区别与联系"></a>进程、线程、协程区别与联系</h4><p>进程、线程和协程是计算机程序执行的三个不同层次</p><p><strong>进程：</strong>进程是操作系统进行资源分配和调度的基本单位，是一个独立运行的程序实体。每个进程拥有独立的内存空间、文件描述符、寄存器状态等资源。进程之间的资源是相互隔离的，因此进程间通信需要通过操作系统提供的特定机制（如管道、消息队列、共享内存等）进行。由于进程拥有独立的资源，所以进程间的切换调度开销较大</p><p><strong>线程：</strong>线程是操作系统调度执行的最小单位，是进程内的一个执行流。一个进程可以拥有多个线程，这些线程共享进程的资源（如内存空间、文件描述符等）。由于线程共享相同的资源，线程间通信相对简单，可以直接通过共享变量、锁等方式进行。线程相较于进程，上下文切换和调度开销较小。但多个线程并行执行时，需要处理好同步和互斥问题，以避免数据不一致或竞争条件。</p><p><strong>协程：</strong>协程是一种用户态的轻量级线程，它的调度和切换完全由程序控制，不依赖于操作系统的调度。协程之间共享线程的资源，因此协程间通信也可以通过共享变量、锁等方式进行。协程的优势在于可以轻松地实现高并发，因此协程切换和调度的开销非常小。协程适用于I&#x2F;O密集型任务，通过异步I&#x2F;O可以有效地提高程序的性能。</p><p><strong>联系</strong></p><ul><li>线程属于进程，多个线程共享进程的资源，一个进程可以包含多个线程，这些线程共同完成任务，提高程序的并发性。</li><li>协程属于线程，多个协程共享线程的资源。一个线程可以包含多个协程，这些协程共同完成任务，提高程序的并发性。</li><li>进程、线程和协程在执行程序时，都需要面对异步、互斥和通信等问题。在实际应用中，可以根据需求和场景选择合适的执行实体来实现最优的性能和资源利用。</li></ul><h2 id="计网"><a href="#计网" class="headerlink" title="计网"></a>计网</h2><h3 id="TCP的确认机制"><a href="#TCP的确认机制" class="headerlink" title="TCP的确认机制"></a>TCP的确认机制</h3><p>1.确认的作用</p><p>TCP的确认机制用于确保数据的可靠传输。当接收端成功接收到一个数据包时，它会返回一个确认信号（ACK）给发送端。这个确认信号包含了接收端期望接受的下一个数据包的序号。发送端收到确认信号后，就知道之前发送的数据包已经被成功接收，并可以继续发送后续的数据包。</p><p>2.确认的实现方式</p><p>确认信号是通过TCP数据包中的ACK标志位来实现。当ACK标志位被设置为1时，表示该数据包时一个确认信号。确认信号中还包含一个32位的确认号字段，用于指示接收端期望接受的下一个数据包的序号。</p><h3 id="TCP流量控制"><a href="#TCP流量控制" class="headerlink" title="TCP流量控制"></a>TCP流量控制</h3><p>发送方不能无脑的发数据给接收方，要考虑接收方处理能力。</p><p>如果一直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。</p><p>为了解决这种现象发生，TCP提供了一种机制可以让发送放根据接收方的实际接受能力控制发送的数据量，这就是所谓的流量控制。</p><p><img src="/../imgs/19th-March/21.png" alt="流量控制"></p><ol><li>客户端向服务端发送请求数据报文。</li><li>服务端收到请求报文后，发送确认报文和80字节的数据，于是可用窗口 <code>Usable</code> 减少为 120 字节，同时<code>SND.NXT</code>指针页向右偏移80字节，这意味着下次发送数据的时候，序列号时321.</li><li>客户端收到80字节数据后，于是接收窗口往右移动80字节，<code>RCV.NXT</code>也就指向321，这意味着客户端期望的下一个报文的序列号时321，接着发送确认报文给服务端。</li><li>服务端再次发送了120字节数据，于是可用窗口耗尽为0，服务端无法再继续发送数据。</li><li>客户端收到120字节的数据后，于是接收窗口往右移动 120 字节，<code>RCV.NXT</code> 也就指向 441，接着发送确认报文给服务端。</li><li>服务端收到对 80 字节数据的确认报文后，<code>SND.UNA</code> 指针往右偏移后指向 321，于是可用窗口 <code>Usable</code> 增大到 80。</li><li>服务端收到对 120 字节数据的确认报文后，<code>SND.UNA</code> 指针往右偏移后指向 441，于是可用窗口 <code>Usable</code> 增大到 200。</li><li>服务端可以继续发送了，于是发送了 160 字节的数据后，<code>SND.NXT</code> 指向 601，于是可用窗口 <code>Usable</code> 减少到 40。</li><li>客户端收到 160 字节后，接收窗口往右移动了 160 字节，<code>RCV.NXT</code> 也就是指向了 601，接着发送确认报文给服务端。</li><li>服务端收到对 160 字节数据的确认报文后，发送窗口往右移动了 160 字节，于是 <code>SND.UNA</code> 指针偏移了 160 后指向 601，可用窗口 <code>Usable</code> 也就增大至了 200。</li></ol><h3 id="HTTPS是如何建立连接的？"><a href="#HTTPS是如何建立连接的？" class="headerlink" title="HTTPS是如何建立连接的？"></a>HTTPS是如何建立连接的？</h3><p>1.ClientHello</p><p>首先由客户端向服务器发起加密通信请求，也就是CLientHello请求。</p><p>在这一步，客户端主要向服务器发送以下信息：</p><ul><li>客户端支持的TLS协议版本</li><li>客户端产生的随机数，后面用于生成会话密钥条件之一</li><li>客户端支持的密码套件列表</li></ul><p>2。ServerHello</p><p>服务器收到客户端请求后，向客户端发出相应，主要内容</p><ul><li>确认TLS协议版本，如果浏览器不支持，则关闭加密通信</li><li>服务器生产的随机数，也就是后面用于生成会话密钥的条件之一</li><li>确认的密码套件列表</li><li>服务器的数字证书</li></ul><p>3.客户端回应</p><p>客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的CA公钥，确认服务器的数字证书的真实性。</p><p>如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使用它加密报文，向服务器发送如下信息：</p><ul><li>一个随机数，会被服务器公钥加密</li><li>加密通信算法改变通知，表示随后信息都将用会话密钥加密通信</li><li>客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。</li></ul><p>上面第一项的随机数是整个握手阶段的第三个随机数，会发给服务端，所以这个随机数客户端和服务端都是一样的。</p><p>服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」。</p><p>4.服务器的最后回应</p><p>服务器收到客户端的第三个随机数（<code>pre-master key</code>）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。</p><p>然后，向客户端发送最后的信息：</p><p>（1）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。</p><p>（2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。</p><p>至此，整个 TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。</p><h2 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h2><h3 id="zset底层原理"><a href="#zset底层原理" class="headerlink" title="zset底层原理"></a>zset底层原理</h3><p>Zset 类型的底层数据结构是由<strong>压缩列表或跳表</strong>实现的：</p><ul><li>如果有序集合的元素个数小于 <code>128</code> 个，并且每个元素的值小于 <code>64</code> 字节时，Redis 会使用<strong>压缩列表</strong>作为 Zset 类型的底层数据结构；</li><li>如果有序集合的元素不满足上面的条件，Redis 会使用<strong>跳表</strong>作为 Zset 类型的底层数据结构；</li></ul><p><strong>在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。</strong></p><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p><a href="https://leetcode.cn/problems/copy-list-with-random-pointer/">138. 随机链表的复制</a></p><p><img src="/../imgs/19th-March/image-20240320000304343.png" alt="随机链表的复制"></p><p>哈希表实现：</p><p>用哈希表存储每个链表节点 然后再串联next和random</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">/*</span><br><span class="hljs-comment">// Definition for a Node.</span><br><span class="hljs-comment">class Node &#123;</span><br><span class="hljs-comment">public:</span><br><span class="hljs-comment">    int val;</span><br><span class="hljs-comment">    Node* next;</span><br><span class="hljs-comment">    Node* random;</span><br><span class="hljs-comment">    </span><br><span class="hljs-comment">    Node(int _val) &#123;</span><br><span class="hljs-comment">        val = _val;</span><br><span class="hljs-comment">        next = NULL;</span><br><span class="hljs-comment">        random = NULL;</span><br><span class="hljs-comment">    &#125;</span><br><span class="hljs-comment">&#125;;</span><br><span class="hljs-comment">*/</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">Node* <span class="hljs-title">copyRandomList</span><span class="hljs-params">(Node* head)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span>(head == <span class="hljs-literal">nullptr</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">nullptr</span>;<br>        Node* cur = head;<br>        unordered_map&lt;Node*,Node*&gt; map;<br>        <span class="hljs-keyword">while</span>(cur != <span class="hljs-literal">nullptr</span>)&#123;<br>            map[cur] = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Node</span>(cur-&gt;val);<br>            cur = cur-&gt;next;<br>        &#125;<br>        cur = head;<br>        <span class="hljs-keyword">while</span>(cur != <span class="hljs-literal">nullptr</span>)&#123;<br>            map[cur]-&gt;next = map[cur-&gt;next];<br>            map[cur]-&gt;random = map[cur-&gt;random];<br>            cur = cur-&gt;next;<br>        &#125;<br>        <span class="hljs-keyword">return</span> map[head];<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><p>明天实现一下在节点后面添加新的节点再脱离一下</p>]]></content>
    
    
    <categories>
      
      <category>diary</category>
      
    </categories>
    
    
    <tags>
      
      <tag>diary</tag>
      
      <tag>八股</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>18th-March</title>
    <link href="/2024/03/18/18th-March/"/>
    <url>/2024/03/18/18th-March/</url>
    
    <content type="html"><![CDATA[<h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1 简介"></a>1 简介</h1><p>晚上收到字节周五约面，所以专心准备项目八股和算法，今天先抠一下项目的细节，从6.824开始</p><h1 id="2-6-824"><a href="#2-6-824" class="headerlink" title="2 6.824"></a>2 6.824</h1><h2 id="可能会问的问题"><a href="#可能会问的问题" class="headerlink" title="可能会问的问题"></a>可能会问的问题</h2><h3 id="mapreduce-Q-A"><a href="#mapreduce-Q-A" class="headerlink" title="mapreduce Q&amp;A"></a>mapreduce Q&amp;A</h3><p><font color='red'>1.简单介绍一下mapreduce（开始乱吹）</font></p><p>在二十年以前，分布式系统和分布式计算并不普及，很多公司只是用一台计算机进行操作，但是随着互联网的飞速发展，一台机器的算力已经不足以支撑起快速的计算了，所以就有了分布式这个概念，多台电脑一起完成一个工作。谷歌作为一个国际大公司也是对这方面有着很深刻的研究，他们也会经常要使用并行的计算，而计算必须分布在数百台或者上千台机器，以便在合理的时间内完成，如何并行化计算、分布数据和处理故障等问题，使得单机变成多机的问题十分的复杂。所以就这样，他们受到了map和reduce原语的启发，也就有了mapreduce这么一个简单但强大的支持大规模计算的自动并行化和分布的接口</p><p><font color = 'red'>2.mapreduce是怎么操作的</font></p><p>首先mapreduce库将输入文件分成m个16-64mb的小文件 然后再一个机器集群上启动该程序的副本</p><p>这些副本中有一份是特别的就是master，其余的就是master分配工作的worker。</p><p>被分配map任务的worker线程读取相应输入分割的内容。它们从输入数据中解析键值对，并将每对传递给用户定义的map函数，map产生中间键值对再内存中进行缓冲</p><p>周期性地将缓冲对写入本地磁盘，并通过分区函数划分R个区域。这些缓冲对再本地磁盘上的位置被传递回主服务器，然后再将位置转发给reduce worker</p><p>它使用远程过程调用从map worker的本地磁盘读取缓冲数据。当reduce工作程序读取了所有中间数据后，它按中间键对数据进行排序，以便将所有出现的相同键分组在一起。排序是必要的，因为通常有许多不同的键映射到相同的reduce任务。如果中间数据量太大，内存无法容纳，则使用外部排序。</p><p>reduce worker遍历已排序的中间数据，对于遇到的每个唯一的中间键，它将键和相应的中间值集传递给用户的reduce函数。Reduce函数的输出被附加到这个Reduce分区的最终输出文件中。</p><p>当所有map任务和reduce任务完成后，主程序唤醒用户程序。此时，用户程序中的MapReduce调用返回到用户代码。</p><p><font color = 'red'>3.mapreduce的优化点？</font></p><p>combiner </p><p>状态信息</p><p>我们从这项工作中学到了一些东西。首先，限制编程模型使其易于并行化和分布计算，并使此类计算具有容错性。第二，网络带宽是一种稀缺资源。因此，我们系统中的许多优化都以减少通过网络发送的数据量为目标:局域优化允许我们从本地磁盘读取数据，并将中间数据的单个副本写入本地磁盘以节省网络带宽。第三，冗余执行可用于减少慢机的影响，并处理机器故障和数据丢失</p><h3 id="Raft-Q-A"><a href="#Raft-Q-A" class="headerlink" title="Raft Q&amp;A"></a>Raft Q&amp;A</h3><p><font color='red'>简单讲讲Raft？</font></p><p>他是从多副本状态机的角度提出来的，用于管理多副本状态机的日志复制，分为多个子问题：Leader选举，日志同步，安全性，日志压缩，成员变更等</p><p>raft将系统中的角色分为leader，follower，和candidate</p><p>leader：接受客户端请求，并向Follower同步请求日志，当日志同步到大多数节点上后告诉Follower提交日志</p><p>Follower：接受并持久化Leader同步的日志，再Leader告知日志可以提交之后便提交</p><p>Candidate：Leader选举过程中的临时角色</p><p><font color = 'red'>Raft选举过程 日志复制？</font></p><p>Raft 使用心跳（heartbeat）触发Leader选举。当服务器启动时，初始化为Follower。Leader向所有Followers周期性发送heartbeat。如果Follower在选举超时时间内没有收到Leader的heartbeat，就会等待一段随机的时间后发起一次Leader选举。</p><p>Follower将其当前term加一然后转换为Candidate。它首先给自己投票并且给集群中的其他服务器发送 RequestVote RPC （RPC细节参见八、Raft算法总结）。结果有以下三种情况：</p><ul><li>赢得了多数的选票，成功选举为Leader；</li><li>收到了Leader的消息，表示有其它服务器已经抢先当选了Leader；</li><li>没有服务器赢得多数的选票，Leader选举失败，等待选举时间超时后发起下一次选举。</li></ul><p>Leader选出后，就开始接收客户端的请求。Leader把请求作为日志条目（Log entries）加入到它的日志中，然后并行的向其他服务器发起 AppendEntries RPC 复制日志条目。当这条日志被复制到大多数服务器上，Leader将这条日志应用到它的状态机并向客户端返回执行结果。</p><p>快照 持久化 快速恢复</p><p>可以让Follower在回复Leader的AppendEntries消息中，携带3个额外的信息，来加速日志的恢复。这里的回复是指，Follower因为Log信息不匹配，拒绝了Leader的AppendEntries之后的回复。这里的三个信息是指：</p><ul><li>XTerm：这个是Follower中与Leader冲突的Log对应的任期号。在之前（7.1）有介绍Leader会在prevLogTerm中带上本地Log记录中，前一条Log的任期号。如果Follower在对应位置的任期号不匹配，它会拒绝Leader的AppendEntries消息，并将自己的任期号放在XTerm中。如果Follower在对应位置没有Log，那么这里会返回 -1。</li><li>XIndex：这个是Follower中，对应任期号为XTerm的第一条Log条目的槽位号。</li><li>XLen：如果Follower在对应位置没有Log，那么XTerm会返回-1，XLen表示空白的Log槽位数。</li></ul><p>线性一致</p><p>目前看完2B 看明天怎么看一下2C和2D 争取把这个干完有时间再看其他两个</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>算法 八股 项目 都得看看 </p><p>算法把那几个dp干完看csview上的 但是记得字节应该是得自己new样例的</p><p>八股 先小林 然后再看其他的怎么说</p><p>今天就先这样吧</p>]]></content>
    
    
    <categories>
      
      <category>diary</category>
      
    </categories>
    
    
    <tags>
      
      <tag>diary</tag>
      
      <tag>6.824</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>15th-March</title>
    <link href="/2024/03/15/15th-March/"/>
    <url>/2024/03/15/15th-March/</url>
    
    <content type="html"><![CDATA[<h1 id="To-do-List"><a href="#To-do-List" class="headerlink" title="To-do List"></a>To-do List</h1><ul><li><p><input checked="" disabled="" type="checkbox"> 算法</p><ul><li><input disabled="" type="checkbox"> </li></ul></li><li><p><input disabled="" type="checkbox"> 项目</p><ul><li><input disabled="" type="checkbox"> cmu15445</li><li><input checked="" disabled="" type="checkbox"> mit6.824</li><li><input disabled="" type="checkbox"> mit6.081</li></ul></li><li><p><input disabled="" type="checkbox"> 八股</p><ul><li><input disabled="" type="checkbox"> 操作系统</li><li><input disabled="" type="checkbox"> 计算机网络</li><li><input disabled="" type="checkbox"> 数据库</li><li><input disabled="" type="checkbox"> redis</li></ul></li><li><p><input checked="" disabled="" type="checkbox"> 日常总结</p></li></ul><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p>今天没写。。。 心态有点小崩 等会随便找个题练个手吧</p><h2 id="项目"><a href="#项目" class="headerlink" title="项目"></a>项目</h2><h3 id="6-824"><a href="#6-824" class="headerlink" title="6.824"></a>6.824</h3><p>完成了mapreduce</p><p>主要是coordinator mapworker和reduceworker的协调，感觉还是表达能力差了点</p><p>放点主要代码吧</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">DoMap</span><span class="hljs-params">(mapf <span class="hljs-keyword">func</span>(<span class="hljs-type">string</span>, <span class="hljs-type">string</span>)</span></span> []KeyValue, task *Task) &#123;<br><span class="hljs-comment">//读入每个输入文件，将其传给map，累积中间Map输出。</span><br>fmt.Println(<span class="hljs-string">&quot;Begin map function,task information(TaskType Filename NReduce TaskId Finished Start):&quot;</span>, task)<br>intermediate := []KeyValue&#123;&#125;<br>filename := task.Filename<br>file, err := os.Open(filename)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>log.Fatalf(<span class="hljs-string">&quot;cannot open %v&quot;</span>, filename)<br>&#125;<br>content, err := ioutil.ReadAll(file)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>log.Fatalf(<span class="hljs-string">&quot;cannot read %v&quot;</span>, filename)<br>&#125;<br>file.Close()<br>kva := mapf(filename, <span class="hljs-type">string</span>(content))<br><span class="hljs-comment">//中间key</span><br>intermediate = <span class="hljs-built_in">append</span>(intermediate, kva...)<br>fmt.Println(<span class="hljs-string">&quot;map生成的中间key:&quot;</span>, intermediate)<br>intermediateMap := <span class="hljs-built_in">make</span>([][]KeyValue, task.NReduce)<br><span class="hljs-keyword">for</span> _, tmp := <span class="hljs-keyword">range</span> intermediate &#123;<br>intermediateMap[ihash(tmp.Key)%task.NReduce] = <span class="hljs-built_in">append</span>(intermediateMap[ihash(tmp.Key)%task.NReduce], tmp)<br>&#125;<br>sort.Sort(ByKey(intermediate))<br>i := <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> i &lt; task.NReduce &#123;<br>oname := <span class="hljs-string">&quot;mr-&quot;</span> + strconv.Itoa(task.TaskId) + <span class="hljs-string">&quot;-&quot;</span> + strconv.Itoa(i)<br>ofile, _ := os.Create(oname)<br>enc := json.NewEncoder(ofile)<br><span class="hljs-keyword">for</span> _, kv := <span class="hljs-keyword">range</span> intermediateMap[i] &#123;<br>enc.Encode(&amp;kv)<br>&#125;<br>i++<br>ofile.Close()<br>&#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">DoReduce</span><span class="hljs-params">(reducef <span class="hljs-keyword">func</span>(<span class="hljs-type">string</span>, []<span class="hljs-type">string</span>)</span></span> <span class="hljs-type">string</span>, task *Task) &#123;<br>i := <span class="hljs-number">0</span><br>intermediate := []KeyValue&#123;&#125;<br><span class="hljs-keyword">for</span> i &lt; task.NReduce &#123;<br>filepath := task.Filename + strconv.Itoa(i) + <span class="hljs-string">&quot;-&quot;</span> + strconv.Itoa(task.TaskId)<br>fmt.Println(<span class="hljs-string">&quot;Begin map function,task information(TaskType Filename NReduce TaskId Finished Start):&quot;</span>, task, <span class="hljs-string">&quot;\nfilepath:&quot;</span>, filepath)<br>file, _ := os.Open(filepath)<br>dec := json.NewDecoder(file)<br><span class="hljs-comment">//解码</span><br><span class="hljs-keyword">for</span> &#123;<br><span class="hljs-keyword">var</span> kv KeyValue<br><span class="hljs-keyword">if</span> err := dec.Decode(&amp;kv); err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">break</span><br>&#125;<br>intermediate = <span class="hljs-built_in">append</span>(intermediate, kv)<br>&#125;<br>file.Close()<br>i++<br>&#125;<br>sort.Sort(ByKey(intermediate))<br>i = <span class="hljs-number">0</span><br>oname := <span class="hljs-string">&quot;mr-out-&quot;</span> + strconv.Itoa(task.TaskId)<br>ofile, _ := os.Create(oname)<br><br><span class="hljs-keyword">for</span> i &lt; <span class="hljs-built_in">len</span>(intermediate) &#123;<br>j := i + <span class="hljs-number">1</span><br><span class="hljs-keyword">for</span> j &lt; <span class="hljs-built_in">len</span>(intermediate) &amp;&amp; intermediate[j].Key == intermediate[i].Key &#123;<br>j++<br>&#125;<br>values := []<span class="hljs-type">string</span>&#123;&#125;<br><span class="hljs-comment">//将相同的Key收集到一起</span><br><span class="hljs-keyword">for</span> k := i; k &lt; j; k++ &#123;<br>values = <span class="hljs-built_in">append</span>(values, intermediate[k].Value)<br>&#125;<br>output := reducef(intermediate[i].Key, values)<br>fmt.Fprintf(ofile, <span class="hljs-string">&quot;%v %v\n&quot;</span>, intermediate[i].Key, output)<br>i = j<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="八股"><a href="#八股" class="headerlink" title="八股"></a>八股</h2><h3 id="Golang-切片的容量是怎样增长的"><a href="#Golang-切片的容量是怎样增长的" class="headerlink" title="Golang-切片的容量是怎样增长的"></a>Golang-切片的容量是怎样增长的</h3><p>一般都是在向slice追加了元素之后，才会引起扩容，追加元素调用的是append函数</p><p>先来看看append函数的原型：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">append</span><span class="hljs-params">(slice []Type, elems ...Type)</span></span> []Type<br></code></pre></td></tr></table></figure><p>append函数的参数长度可变，因此可以追加多个值到slice中，还可以用…传入slice，直接追加一个切片</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs go">slice = <span class="hljs-built_in">append</span>(slice, elem1, elem2)<br>slice = <span class="hljs-built_in">append</span>(slice, anotherSlice...)<br></code></pre></td></tr></table></figure><p>append函数返回值是一个新的slice，Go编译器不允许调用了append函数后不使用返回值。</p><p>使用 append 可以向 slice 追加元素，实际上是往底层数组添加元素。但是底层数组的长度是固定的，如果索引 <code>len-1</code> 所指向的元素已经是底层数组的最后一个元素，就没法再添加了。</p><p>这时，slice 会迁移到新的内存位置，新底层数组的长度也会增加，这样就可以放置新增的元素。同时，为了应对未来可能再次发生的 append 操作，新的底层数组的长度，也就是新 <code>slice</code> 的容量是留了一定的 <code>buffer</code> 的。否则，每次添加元素的时候，都会发生迁移，成本太高。</p><p>新 slice 预留的 <code>buffer</code> 大小是有一定规律的。在golang1.18版本更新之前网上大多数的文章都是这样描述slice的扩容策略的：</p><blockquote><p>当原 slice 容量小于 <code>1024</code> 的时候，新 slice 容量变成原来的 <code>2</code> 倍；原 slice 容量超过 <code>1024</code>，新 slice 容量变成原来的<code>1.25</code>倍。</p></blockquote><p>在1.18版本更新之后，slice的扩容策略变为了：</p><blockquote><p>当原slice容量(oldcap)小于256的时候，新slice(newcap)容量为原来的2倍；原slice容量超过256，新slice容量newcap &#x3D; oldcap+(oldcap+3*256)&#x2F;4</p></blockquote><p>举例：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> <span class="hljs-string">&quot;fmt&quot;</span><br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>s := <span class="hljs-built_in">make</span>([]<span class="hljs-type">int</span>, <span class="hljs-number">0</span>)<br><br>oldCap := <span class="hljs-built_in">cap</span>(s)<br><br><span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">2048</span>; i++ &#123;<br>s = <span class="hljs-built_in">append</span>(s, i)<br><br>newCap := <span class="hljs-built_in">cap</span>(s)<br><br><span class="hljs-keyword">if</span> newCap != oldCap &#123;<br>fmt.Printf(<span class="hljs-string">&quot;[%d -&gt; %4d] cap = %-4d  |  after append %-4d  cap = %-4d\n&quot;</span>, <span class="hljs-number">0</span>, i<span class="hljs-number">-1</span>, oldCap, i, newCap)<br>oldCap = newCap<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>我先创建了一个空的 <code>slice</code>，然后，在一个循环里不断往里面 <code>append</code> 新的元素。然后记录容量的变化，并且每当容量发生变化的时候，记录下老的容量，以及添加完元素之后的容量，同时记下此时 <code>slice</code> 里的元素。这样，我就可以观察，新老 <code>slice</code> 的容量变化情况，从而找出规律。</p><p>运行结果(1.18版本之前)：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-section">[0 -&gt;   -1]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">0</span>     |  after append <span class="hljs-number">0</span>     cap = <span class="hljs-number">1</span>   <br><span class="hljs-section">[0 -&gt;    0]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">1</span>     |  after append <span class="hljs-number">1</span>     cap = <span class="hljs-number">2</span>   <br><span class="hljs-section">[0 -&gt;    1]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">2</span>     |  after append <span class="hljs-number">2</span>     cap = <span class="hljs-number">4</span>   <br><span class="hljs-section">[0 -&gt;    3]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">4</span>     |  after append <span class="hljs-number">4</span>     cap = <span class="hljs-number">8</span>   <br><span class="hljs-section">[0 -&gt;    7]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">8</span>     |  after append <span class="hljs-number">8</span>     cap = <span class="hljs-number">16</span>  <br><span class="hljs-section">[0 -&gt;   15]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">16</span>    |  after append <span class="hljs-number">16</span>    cap = <span class="hljs-number">32</span>  <br><span class="hljs-section">[0 -&gt;   31]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">32</span>    |  after append <span class="hljs-number">32</span>    cap = <span class="hljs-number">64</span>  <br><span class="hljs-section">[0 -&gt;   63]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">64</span>    |  after append <span class="hljs-number">64</span>    cap = <span class="hljs-number">128</span> <br><span class="hljs-section">[0 -&gt;  127]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">128</span>   |  after append <span class="hljs-number">128</span>   cap = <span class="hljs-number">256</span> <br><span class="hljs-section">[0 -&gt;  255]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">256</span>   |  after append <span class="hljs-number">256</span>   cap = <span class="hljs-number">512</span> <br><span class="hljs-section">[0 -&gt;  511]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">512</span>   |  after append <span class="hljs-number">512</span>   cap = <span class="hljs-number">1024</span><br><span class="hljs-section">[0 -&gt; 1023]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">1024</span>  |  after append <span class="hljs-number">1024</span>  cap = <span class="hljs-number">1280</span><br><span class="hljs-section">[0 -&gt; 1279]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">1280</span>  |  after append <span class="hljs-number">1280</span>  cap = <span class="hljs-number">1696</span><br><span class="hljs-section">[0 -&gt; 1695]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">1696</span>  |  after append <span class="hljs-number">1696</span>  cap = <span class="hljs-number">2304</span><br></code></pre></td></tr></table></figure><p>运行结果(1.18版本)：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-section">[0 -&gt;   -1]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">0</span>     |  after append <span class="hljs-number">0</span>     cap = <span class="hljs-number">1</span><br><span class="hljs-section">[0 -&gt;    0]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">1</span>     |  after append <span class="hljs-number">1</span>     cap = <span class="hljs-number">2</span>   <br><span class="hljs-section">[0 -&gt;    1]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">2</span>     |  after append <span class="hljs-number">2</span>     cap = <span class="hljs-number">4</span>   <br><span class="hljs-section">[0 -&gt;    3]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">4</span>     |  after append <span class="hljs-number">4</span>     cap = <span class="hljs-number">8</span>   <br><span class="hljs-section">[0 -&gt;    7]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">8</span>     |  after append <span class="hljs-number">8</span>     cap = <span class="hljs-number">16</span>  <br><span class="hljs-section">[0 -&gt;   15]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">16</span>    |  after append <span class="hljs-number">16</span>    cap = <span class="hljs-number">32</span>  <br><span class="hljs-section">[0 -&gt;   31]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">32</span>    |  after append <span class="hljs-number">32</span>    cap = <span class="hljs-number">64</span>  <br><span class="hljs-section">[0 -&gt;   63]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">64</span>    |  after append <span class="hljs-number">64</span>    cap = <span class="hljs-number">128</span> <br><span class="hljs-section">[0 -&gt;  127]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">128</span>   |  after append <span class="hljs-number">128</span>   cap = <span class="hljs-number">256</span> <br><span class="hljs-section">[0 -&gt;  255]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">256</span>   |  after append <span class="hljs-number">256</span>   cap = <span class="hljs-number">512</span> <br><span class="hljs-section">[0 -&gt;  511]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">512</span>   |  after append <span class="hljs-number">512</span>   cap = <span class="hljs-number">848</span> <br><span class="hljs-section">[0 -&gt;  847]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">848</span>   |  after append <span class="hljs-number">848</span>   cap = <span class="hljs-number">1280</span><br><span class="hljs-section">[0 -&gt; 1279]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">1280</span>  |  after append <span class="hljs-number">1280</span>  cap = <span class="hljs-number">1792</span><br><span class="hljs-section">[0 -&gt; 1791]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">1792</span>  |  after append <span class="hljs-number">1792</span>  cap = <span class="hljs-number">2560</span><br></code></pre></td></tr></table></figure><p>根据上面的结果我们可以看出在<code>1.18</code>版本之前：</p><p>在原来的slice容量<code>oldcap</code>小于1024的时候，新 slice 的容量<code>newcap</code>的确是<code>oldcap</code>的2倍。</p><p>但是，当<code>oldcap</code>大于等于 <code>1024</code> 的时候，情况就有变化了。当向 slice 中添加元素 <code>1280</code> 的时候，原来的slice 的容量为 <code>1280</code>，之后<code>newcap</code>变成了 <code>1696</code>，两者并不是 <code>1.25</code> 倍的关系（1696&#x2F;1280&#x3D;1.325）。添加完 <code>1696</code> 后，新的容量 <code>2304</code> 当然也不是 <code>1696</code> 的 <code>1.25</code> 倍。</p><p>在<code>1.18</code>版本之后：</p><p>在原来的slice 容量<code>oldcap</code>小于256的时候，新 slice 的容量<code>newcap</code>的确是<code>oldcap</code> 的2倍。</p><p>但是，当<code>oldcap</code>容量大于等于 <code>256</code> 的时候，情况就有变化了。当向 slice 中添加元素 <code>512</code> 的时候，老 slice 的容量为 <code>512</code>，之后变成了 <code>8</code>48，两者并没有符合<code>newcap = oldcap+(oldcap+3*256)/4</code> 的策略（512+（512+3*256）&#x2F;4）&#x3D;832。添加完 <code>848</code> 后，新的容量 <code>1280</code> 当然也不是 按照之前策略所计算出的的1252。</p><p>难道现在网上各种文章中的扩容策略并不是正确的吗。我们直接搬出源码：源码面前，了无秘密。</p><p>从前面汇编代码我们也看到了，向 slice 追加元素的时候，若容量不够，会调用 <code>growslice</code> 函数，所以我们直接看它的代码。</p><p><strong>golang版本1.9.5</strong></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// go 1.9.5 src/runtime/slice.go:82</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">growslice</span><span class="hljs-params">(et *_type, old slice, <span class="hljs-built_in">cap</span> <span class="hljs-type">int</span>)</span></span> slice &#123;<br>    <span class="hljs-comment">// ……</span><br>    newcap := old.<span class="hljs-built_in">cap</span><br>doublecap := newcap + newcap<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">cap</span> &gt; doublecap &#123;<br>newcap = <span class="hljs-built_in">cap</span><br>&#125; <span class="hljs-keyword">else</span> &#123;<br><span class="hljs-keyword">if</span> old.<span class="hljs-built_in">len</span> &lt; <span class="hljs-number">1024</span> &#123;<br>newcap = doublecap<br>&#125; <span class="hljs-keyword">else</span> &#123;<br><span class="hljs-keyword">for</span> newcap &lt; <span class="hljs-built_in">cap</span> &#123;<br>newcap += newcap / <span class="hljs-number">4</span><br>&#125;<br>&#125;<br>&#125;<br><span class="hljs-comment">// ……</span><br><br>capmem = roundupsize(<span class="hljs-type">uintptr</span>(newcap) * ptrSize)<br>newcap = <span class="hljs-type">int</span>(capmem / ptrSize)<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>golang版本1.18</strong></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// go 1.18 src/runtime/slice.go:178</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">growslice</span><span class="hljs-params">(et *_type, old slice, <span class="hljs-built_in">cap</span> <span class="hljs-type">int</span>)</span></span> slice &#123;<br>    <span class="hljs-comment">// ……</span><br>    newcap := old.<span class="hljs-built_in">cap</span><br>doublecap := newcap + newcap<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">cap</span> &gt; doublecap &#123;<br>newcap = <span class="hljs-built_in">cap</span><br>&#125; <span class="hljs-keyword">else</span> &#123;<br><span class="hljs-keyword">const</span> threshold = <span class="hljs-number">256</span><br><span class="hljs-keyword">if</span> old.<span class="hljs-built_in">cap</span> &lt; threshold &#123;<br>newcap = doublecap<br>&#125; <span class="hljs-keyword">else</span> &#123;<br><span class="hljs-keyword">for</span> <span class="hljs-number">0</span> &lt; newcap &amp;&amp; newcap &lt; <span class="hljs-built_in">cap</span> &#123;<br>                <span class="hljs-comment">// Transition from growing 2x for small slices</span><br><span class="hljs-comment">// to growing 1.25x for large slices. This formula</span><br><span class="hljs-comment">// gives a smooth-ish transition between the two.</span><br>newcap += (newcap + <span class="hljs-number">3</span>*threshold) / <span class="hljs-number">4</span><br>&#125;<br><span class="hljs-keyword">if</span> newcap &lt;= <span class="hljs-number">0</span> &#123;<br>newcap = <span class="hljs-built_in">cap</span><br>&#125;<br>&#125;<br>&#125;<br><span class="hljs-comment">// ……</span><br>    <br>capmem = roundupsize(<span class="hljs-type">uintptr</span>(newcap) * ptrSize)<br>newcap = <span class="hljs-type">int</span>(capmem / ptrSize)<br>&#125;<br></code></pre></td></tr></table></figure><p>如果只看前半部分，现在网上各种文章里说的 <code>newcap</code> 的规律是对的。现实是，后半部分还对 <code>newcap</code> 作了一个<code>内存对齐</code>，这个和内存分配策略相关。进行内存对齐之后，新 slice 的容量是要 <code>大于等于</code> 按照前半部分生成的<code>newcap</code>。</p><p>之后，向 Go 内存管理器申请内存，将老 slice 中的数据复制过去，并且将 append 的元素添加到新的底层数组中。</p><p>最后，向 <code>growslice</code> 函数调用者返回一个新的 slice，这个 slice 的长度并没有变化，而容量却增大了。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>。。。失败 但是差不多能知道哪里不足了 可以尝试一下 明天笔试加油</p>]]></content>
    
    
    <categories>
      
      <category>diary</category>
      
    </categories>
    
    
    <tags>
      
      <tag>diary</tag>
      
      <tag>八股</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>raft</title>
    <link href="/2024/03/15/raft-1/"/>
    <url>/2024/03/15/raft-1/</url>
    
    <content type="html"><![CDATA[<h1 id="一种可理解的共识算法的寻找-扩展版"><a href="#一种可理解的共识算法的寻找-扩展版" class="headerlink" title="一种可理解的共识算法的寻找(扩展版)"></a>一种可理解的共识算法的寻找(扩展版)</h1><h2 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h2><p>​<strong>Raft</strong>是用于管理复制日志的共识算法。它产生的结果相当于(多)Paxos，效率和Paxos一样，但结构与Paxos不同;这使得Raft比Paxos更容易理解，也为构建实用系统提供了更好的基础。为了增强可理解性，Raft分离了共识的关键元素，如leader选举、日志复制和安全性，并且它强制执行更强的一致性，以减少必须考虑的状态的数量。用户研究的结果表明，对于学生来说，Raft比Paxos更容易学习。Raft还包含了一个改变集群成员的新机制，它使用重叠大多数来保证安全。</p><h2 id="I-介绍"><a href="#I-介绍" class="headerlink" title="I.介绍"></a>I.介绍</h2><p>​共识算法允许一组机器作为一个连贯的群体工作，可以在其中一些成员出现故障时幸存下来。正因为如此，它们在构建可靠的大型软件系统中起着关键作用。Paxos[15,16]在过去十年中主导了共识算法的讨论:大多数共识的实现都基于Paxos或受其影响，Paxos已成为教授学生共识的主要工具。</p><p>​不幸的是，Paxos很难理解，尽管有许多尝试使它更容易理解。此外，它的体系结构需要进行复杂的更改以支持实际系统。因此，系统构建者和学生使用Paxos都很困难。</p><p>​在与Paxos斗争之后，我们开始寻找一种新的共识算法，可以为系统构建和教育提供更好的基础。我们的方法是不同寻常的，因为我们的主要目标是可理解性:我们能否为实际系统定义一个共识算法，并以一种比Paxos更容易学习的方式来描述它?此外，我们希望算法能够促进对系统构建者至关重要的直觉的发展。重要的不仅是算法能起作用，还在于它为什么能起作用。</p><p>​这项工作的结果是一个被称为Raft的共识算法。在设计Raft时，我们应用了特定的技术来提高可理解性，包括分解(Raft将领导者选举、日志复制和安全性分开)和状态空间缩减(相对于Paxos, Raft降低了不确定性的程度和服务器之间可能不一致的方式)。一项针对两所大学43名学生的用户研究表明，Raft比Paxos更容易理解:在学习了这两种算法后，其中33名学生能够更好地回答关于Raft的问题，而不是关于Paxos的问题。</p><p>​Raft在许多方面与现有的共识算法相似(最值得注意的是Oki和Liskov的Viewstamped Replication)，但它有几个新特性:</p><ul><li><strong>强大的leader</strong>:Raft使用比其他共识算法更强大的领导形式。例如，日志条目只从leader流向其他服务器。这简化了复制日志的管理，使Raft更容易理解。</li><li><strong>leader选举</strong>:Raft使用随机计时器来选举首领。这只给任何共识算法已经需要的心跳增加了少量的机制，同时简单快速地解决冲突。</li><li><strong>成员变更</strong>:Raft用于更改集群中服务器集的机制使用了一种新的联合共识方法，在这种方法中，两种不同配置的大多数在转换期间重叠。这允许集群在配置更改期间继续正常运行。</li></ul><p>​我们相信Raft优于Paxos和其他共识算法，无论是出于教育目的还是作为实现的基础。它比其他算法更简单，更容易理解;它的描述足够完整，足以满足实际系统的需要;它有几个开源实现，并被几家公司使用;其安全性能已经过正式规定和证明;其效率与其他算法相当。</p><p>​本文的其余部分介绍了复制状态机问题(第2节)，讨论了Paxos的优缺点(第3节)，描述了我们实现可理解性的一般方法(第4节)，介绍了Raft共识算法(第5-8节)，评估了Raft(第9节)，并讨论了相关工作(第10节)。</p><h2 id="II-复制状态机"><a href="#II-复制状态机" class="headerlink" title="II.复制状态机"></a>II.复制状态机</h2><p><img src="/../imgs/raft-1/image-20240315211045665.png" alt="图1:复制状态机架构。一致性算法管理包含来自客户机的状态机命令的复制日志。状态机处理来自日志的相同命令序列，因此它们产生相同的输出。"></p><p>​共识算法通常出现在复制状态机的环境中。在这种方法中，一组服务器上的状态机计算相同状态的相同副本，并且即使某些服务器关闭也可以继续运行。复制状态机用于解决分布式系统中的各种容错问题。例如，具有单个集群领导者的大型系统，如GFS， HDFS和RAMCloud，通常使用单独的复制状态机来管理领导者选举和存储必须在领导者崩溃时存活的配置信息。复制状态机的例子包括Chubby和ZooKeeper。</p><p>​复制状态机通常使用复制日志来实现，如图1所示。每个服务器存储包含一系列命令的日志，其状态机按顺序执行这些命令。每个日志以相同的顺序包含相同的命令，因此每个状态机处理相同的命令序列。由于状态机是确定性的，因此每个状态机都计算相同的状态和相同的输出序列。</p><p>​保持复制日志的一致性是一致性算法的工作。服务器上的consensus模块接收来自客户端的命令并将其添加到日志中。它与其他服务器上的共识模块通信，以确保每个日志最终以相同的顺序包含相同的请求，即使某些服务器失败。一旦正确地复制了命令，每个服务器的状态机将按日志顺序处理它们，并将输出返回给客户机。因此，这些服务器似乎形成了一个单一的、高度可靠的状态机。</p><p>​实际系统的共识算法通常具有以下性质:</p><ul><li>它们确保在所有非拜占庭条件下的安全性(永远不会返回错误的结果)，包括网络延迟、分区、数据包丢失、重复和重新排序。</li><li>只要任何大多数服务器都是可操作的，并且可以相互通信并与客户端通信，它们就具有完整的功能(可用)。因此，典型的五台服务器集群可以容忍任意两台服务器的故障。通过停止假定服务器失败;它们可能稍后从稳定存储上的状态恢复并重新加入集群。</li><li>它们不依赖于定时来确保日志的一致性:错误的时钟和极端的消息延迟在最坏的情况下会导致可用性问题。</li><li>在通常情况下，只要集群的大多数响应了一轮远程过程调用，命令就可以完成;少数慢速服务器不需要影响整体系统性能。</li></ul><h2 id="III-What’s-wrong-with-Paxos"><a href="#III-What’s-wrong-with-Paxos" class="headerlink" title="III.What’s wrong with Paxos???"></a>III.What’s wrong with Paxos???</h2><p>​在过去的十年里，Leslie Lamport的Paxos协议几乎已经成为共识的代名词:它是课程中最常教授的协议，大多数共识的实现都将其作为起点。Paxos首先定义了一个能够就单个决策达成一致的协议，比如单个复制的日志条目。我们将这个子集称为单命令Paxos。然后，Paxos结合该协议的多个实例来促进一系列决策，例如日志(多Paxos)。Paxos确保了安全性和活动性，并且支持更改集群成员。该方法的正确性得到了验证，在一般情况下是有效的。</p><p>​不幸的是，Paxos有两个明显的缺点。第一个缺点是Paxos非常难以理解。完整的解释[15]是出了名的不透明;只有付出巨大努力的人才能理解它。因此，已经有人尝试用更简单的术语来解释Paxos。这些解释集中于单一法令子集，但它们仍然具有挑战性。在对2012年NSDI与会者的非正式调查中，我们发现很少有人对Paxos感到满意，即使是经验丰富的研究人员。我们自己也在努力开发Paxos;直到阅读了几个简化的解释并设计了我们自己的替代协议之后，我们才能够理解完整的协议，这个过程花了将近一年的时间。</p><p>​我们假设Paxos的不透明性源于它选择单一法令子集作为其基础。单一法令的Paxos是密集而微妙的:它分为两个阶段，没有简单的直观解释，无法独立理解。正因为如此，很难对单一法令协议的工作原理做出直观的解释。多paxos的组合规则增加了额外的复杂性和微妙性。我们相信，在多个决策上达成共识的整体问题(即，一个日志而不是单个条目)可以用其他更直接和明显的方式分解。</p><p>​Paxos的第二个问题是，它没有为构建实际实现提供良好的基础。其中一个原因是，对于多paxos，还没有得到广泛认可的算法。兰波特的描述主要是关于单一法令的Paxos;他概述了实现多paxos的可能方法，但缺少许多细节。已经有几次尝试充实和优化Paxos，但这些彼此不同，也不同于Lamport的草图。像Chubby这样的系统已经实现了类似paxos的算法，但在大多数情况下，它们的细节还没有公布。</p><p>​此外，Paxos架构对于构建实际系统来说是一个糟糕的架构;这是单一法令分解的另一个后果。例如，独立地选择一组日志条目，然后将它们合并到一个顺序日志中，这几乎没有什么好处;这只会增加复杂性。围绕日志设计系统更简单、更有效，在日志中，新条目以受限的顺序依次挂起。另一个问题是Paxos在其核心使用了对称的点对点方法(尽管它最终提出了一种弱形式的领导作为性能优化)。这在只需要做出一个决策的简化世界中是有意义的，但是很少有实际的系统使用这种方法。如果必须做出一系列决策，那么首先选举一个领导者，然后让领导者协调决策是更简单和更快的方法。</p><p>​因此，实际系统与Paxos几乎没有相似之处。每个实现都从Paxos开始，发现实现它的困难，然后开发一个截然不同的体系结构。这既耗时又容易出错，而且理解Paxos的困难加剧了这个问题。Paxos的公式对于证明其正确性的定理可能是一个很好的公式，但是实际实现与Paxos如此不同，以至于证明几乎没有价值。以下是Chubby实现者的典型评论:</p><p>​<font color = 'red'><strong>在Paxos算法的描述和真实系统的需求之间有很大的差距…最终的系统将基于一个未经验证的协议</strong></font></p><p>​由于这些问题，我们得出结论，Paxos不能为系统构建或教育提供良好的基础。考虑到共识在大型软件系统中的重要性，我们决定看看是否可以设计一个具有比Paxos更好属性的替代共识算法。Raft就是那次实验的结果。</p><h2 id="IV-为可理解性而设计"><a href="#IV-为可理解性而设计" class="headerlink" title="IV.为可理解性而设计"></a>IV.为可理解性而设计</h2><p>​我们在设计Raft时有几个目标:它必须为系统构建提供一个完整和实用的基础，这样它就可以显著减少开发人员所需的设计工作量;它必须在所有条件下都是安全的，并在典型的操作条件下可用;对于一般的操作，它必须是有效的。但我们最重要的目标——也是最困难的挑战——是可理解性。它必须能够让大量的观众轻松地理解算法。此外，必须能够开发关于算法的直觉，以便系统构建者可以进行在实际实现中不可避免的扩展。</p><p>​在Raft的设计过程中，我们需要在不同的方法中做出选择。在这些情况下，我们根据可理解性来评估备选方案:解释每个备选方案有多难(例如，其状态空间有多复杂，它是否有微妙的含义?)，读者完全理解该方法及其含义有多容易?</p><p>​我们认识到，在这种分析中有高度的主观性;尽管如此，我们还是使用了两种普遍适用的技术。第一种技术是众所周知的问题分解方法:只要有可能，我们就把问题分成可以相对独立地解决、解释和理解的独立部分。例如，在Raft中，我们分离了leader选举、日志复制、安全性和成员变更。</p><p>​我们的第二种方法是通过减少要考虑的状态数量来简化状态空间，使系统更加连贯，并在可能的情况下消除不确定性。具体来说，原木不允许有孔，Raft限制了原木相互不一致的方式。尽管在大多数情况下我们试图消除非确定性，但在某些情况下，非确定性实际上提高了可理解性。特别是，随机方法引入了不确定性，但它们倾向于通过以类似的方式处理所有可能的选择(“随便选没关系”)。我们使用随机化来简化Raft leader的选举算法。</p><h2 id="V-Raft共识算法"><a href="#V-Raft共识算法" class="headerlink" title="V.Raft共识算法"></a>V.Raft共识算法</h2><p><img src="/../imgs/raft-1/image-20240315213252013.png" alt="图2:Raft共识算法的简明摘要(不包括成员变更和日志压缩)。左上角框中的服务器行为被描述为一组独立且重复触发的规则。章节编号，如§5.2表示讨论特定特征的地方。正式规范更精确地描述了该算法。"></p><p>​Raft是一种算法，用于管理第2节中描述的形式的复制日志。图2对算法进行了简明总结，以供参考，图3列出了算法的关键属性;这些数字的元素将在本节的其余部分逐条讨论。</p><p>​Raft通过首先选举一个杰出的领导者来实现共识，然后让领导者完全负责管理复制的日志。leader接受来自客户机的日志条目，在其他服务器上复制它们，并告诉服务器何时可以安全地将日志条目应用到它们的状态机。拥有一个leader可以简化对复制日志的管理。例如，leader可以在不咨询其他服务器的情况下决定在日志中放置新条目的位置，并且数据以一种简单的方式从leader流向其他服务器。leader可能会失败或与其他服务器断开连接，在这种情况下，会选举一个新的leader。</p><p>​在leader方法下，Raft将共识问题分解为三个相对独立的子问题，并在以下小节中进行讨论:</p><ul><li>领导人选举:当现有领导人失败时，必须选择新的领导人(第5.2节)。</li><li>日志复制:leader必须接受来自客户端的日志条目，并在整个集群中复制它们，迫使其他日志与自己的日志一致(第5.3节)。</li><li>安全性:Raft的关键安全属性是图3中的状态机安全属性:如果任何服务器将特定的日志条目应用到其状态机，那么其他服务器就不能对相同的日志索引应用不同的命令。第5.4节描述了Raft如何确保此属性;该解决方案涉及对第5.2节中描述的选举机制的额外限制。</li></ul><p><img src="/../imgs/raft-1/image-20240315213333387.png" alt="图3:Raft保证这些属性在任何时候都是正确的。节号表示讨论每个属性的位置。"></p><p>​在介绍了共识算法之后，本节将讨论可用性问题和定时在系统中的作用。</p><h3 id="V-1-Raft基础"><a href="#V-1-Raft基础" class="headerlink" title="V.1 Raft基础"></a>V.1 Raft基础</h3><p>​Raft集群包含多个服务器;5是一个典型的数字，它允许系统容忍两次故障。在任何给定时间，每个服务器都处于以下三种状态之一:领导者、追随者或候选人。在正常操作中，只有一个领导者，所有其他服务器都是追随者。追随者是被动的:他们自己不发出任何要求，只是对领导和候选人的要求做出回应。leader处理所有客户端请求(如果客户端联系了follower, follower会将其重定向到leader)。第三个状态，candidate，用于选举新的领导人，如第5.2节所述。图4显示了状态及其转换;下面将讨论这些转换。</p><p><img src="/../imgs/raft-1/image-20240315213542054.png" alt="图4:服务器状态。追随者只响应来自其他服务器的请求。如果追随者没有收到任何通信，它就成为候选人并发起选举。获得整个集群大多数选票的候选人成为新的领导者。领导者通常会一直工作到失败。"></p><p><img src="/../imgs/raft-1/image-20240315213607650.png" alt="图5:时间分为任期，每任期以选举开始。在一次成功的选举之后，一个单一的领导者管理集群直到任期结束。有些选举失败，在这种情况下，任期结束时没有选出领导人。在不同的服务器上，可以在不同的时间观察到术语之间的转换。"></p><p>​Raft将时间划分为任意长度，如图5所示。任期用连续整数编号。每个任期以选举开始，其中一个或多个候选人试图成为第5.2节所述的领导人。如果一位候选人赢得选举，那么他将在剩下的任期内担任领导人。在某些情况下，选举会导致票数不一致。在这种情况下，任期结束时将没有领导人;新任期(有新的选举)即将开始。Raft保证在给定的任期内最多有一个leader。</p><p>​不同的服务器可能会在不同的时间观察任期之间的过渡，在某些情况下，服务器可能不会观察选举甚至整个任期。术语在Raft中充当逻辑时钟，它们允许服务器检测过时的信息，如过时的leader。每个服务器存储一个当前术语号，该术语号随时间单调增加。每当服务器通信时，都会交换当前条款;如果一台服务器的当前项小于另一台服务器的，则将其当前项更新为较大的值。如果候选人或领导人发现自己的任期已经过期，</p><p>​Raft服务器使用远程过程调用(rpc)进行通信，基本的一致性算法只需要两种类型的rpc。RequestVote rpc是由候选人在选举期间发起的(第5.2节)，而追加条目rpc是由领导者发起的，用于复制日志条目并提供心跳形式(第5.3节)。第7节添加了第三个RPC，用于在服务器之间传输快照。如果服务器没有及时收到响应，它们会重试rpc，并并行地发出rpc以获得最佳性能。</p><h3 id="V-2-领导选举"><a href="#V-2-领导选举" class="headerlink" title="V.2 领导选举"></a>V.2 领导选举</h3><p>​Raft使用心跳机制来触发领导人选举。当服务器启动时，它们从追随者开始。只要从leader或candidate接收到有效的rpc，服务器就保持follower状态。领导者定期向所有追随者发送心跳(AppendEntries rpc，不携带日志条目)，以维护他们的权威。如果一个follower在一段称为选举超时的时间内没有收到任何通信，那么它假设没有可见的leader，并开始选举以选择一个新的leader。</p><p>​要开始选举，追随者增加其当前任期并过渡到候选人状态。然后，它为自己投票，并并行地向集群中的每个其他服务器发出RequestVote rpc。候选人一直处于这种状态，直到发生以下三种情况之一:(A)它赢得了选举，(b)另一个服务器确立了自己的领导地位，或者(c)一段时间过去了，没有赢家。这些结果将在下文各段分别讨论。</p><p>​如果候选人在同一任期内获得整个集群中大多数服务器的投票，则该候选人赢得选举。在给定的任期内，每个服务器将以先到先得的方式投票给最多一个候选人(注意:第5.4节增加了对投票的额外限制)。多数决定原则确保最多有一名候选人能够赢得特定任期的选举(图3中的选举安全属性)。一旦候选人赢得选举，它就成为领导者。然后，它向所有其他服务器发送心跳消息，以建立其权威并防止新的选举。</p><p>​在等待投票期间，候选人可能会从另一个声称是领导者的服务器接收AppendEntries RPC。如果领导者的任期(包含在其RPC中)至少与候选人的当前任期一样长，则候选人将承认领导者是合法的，并返回到追随者状态。如果RPC中的术语小于候选者的当前术语，则候选者拒绝RPC并继续处于候选者状态。</p><p>​第三种可能的结果是候选人既不赢也不输:如果许多追随者同时成为候选人，选票可能会被分割，因此没有候选人获得多数。当这种情况发生时，每个候选人将超时并通过增加其任期并启动另一轮请求-投票rpc来开始新的选举。然而，如果不采取额外措施，分裂投票可能会无限期地重复。</p><p>​Raft使用随机选举超时来确保分裂投票很少，并且可以快速解决。为了首先防止分裂投票，选举超时从固定间隔(例如150-300ms)中随机选择。这将分散服务器，因此在大多数情况下，只有一个服务器会超时;它赢得了选举，并在任何其他服务器超时之前发送心跳。同样的机制也用于处理分裂投票。每个候选人在选举开始时重新启动其随机选举超时，并等待该超时结束后再开始下一次选举;这降低了在新选举中再次出现分裂投票的可能性。9.3节表明，这种方法可以快速地选出领导者。</p><p><img src="/../imgs/raft-1/image-20240315214258232.png" alt="图6:日志由条目组成，条目按顺序编号。每个条目包含创建它时使用的术语(每个框中的数字)和用于状态机的命令。如果将一个条目应用于状态机是安全的，则认为该条目已提交。"></p><p>​选举是一个例子，说明可理解性如何指导我们在设计方案之间做出选择。最初我们计划使用一个排名系统:每个候选人被分配一个唯一的排名，用于在竞争候选人之间进行选择。如果一个候选人发现了另一个排名更高的候选人，它就会回到追随者状态，这样排名更高的候选人就更容易赢得下一次选举。我们发现这种方法在可用性方面产生了微妙的问题(如果排名较高的服务器失败，排名较低的服务器可能需要超时并再次成为候选服务器，但如果它这样做得太快，它可能会重置选举领导者的进度)。我们对算法进行了几次调整，但每次调整后都会出现新的拐角案例。最终我们得出结论，随机重试方法更明显，更容易理解。</p><h3 id="V-3-日志复制"><a href="#V-3-日志复制" class="headerlink" title="V.3 日志复制"></a>V.3 日志复制</h3><p>​一旦选出领导者，它就开始服务客户端请求。每个客户端请求都包含一个要由复制状态机执行的命令。leader将该命令作为一个新条目追加到它的日志中，然后将AppendEntries rpc与其他每个服务器并行，以复制该条目。当条目被安全复制后(如下所述)，leader将该条目应用于其状态机，并将执行的结果返回给客户机。如果follower崩溃或运行缓慢，或者如果网络数据包丢失，leader会无限期地重试追加条目rpc(即使在它已经响应客户端之后)，直到所有follower最终存储所有日志条目。</p><p>​日志组织如图6所示。每个日志记录存储一个状态机命令以及leader接收到该条目时的术语号。日志条目中的术语编号用于检测日志之间的不一致性，并确保图3中的一些属性。每个日志条目还有一个整数索引，用于标识其在日志中的位置。</p><p>​领导者决定何时对状态机应用日志记录是安全的;这样的条目称为committed。Raft保证提交的条目是持久的，并且最终将由所有可用的状态机执行。一旦创建条目的leader在大多数服务器上复制了该条目(例如，图6中的条目7)，日志条目就会被提交。这也会提交leader日志中所有之前的条目，包括之前的leader创建的条目。第5.4节讨论了在领导者更换后应用此规则时的一些微妙之处，并表明此承诺定义是安全的。leader跟踪它知道要提交的最高索引，并将该索引包含在未来的AppendEntries rpc中(包括心跳)，以便其他服务器最终发现。一旦追随者了解到日志条目已提交，它将该条目应用于其本地状态机(按日志顺序)。</p><p>​我们设计Raft日志机制是为了在不同服务器上的日志之间保持高度的一致性。这不仅简化了系统的行为，使其更可预测，而且是确保安全的重要组成部分。Raft维护以下属性，它们共同构成了图3中的日志匹配属性:</p><ul><li>如果不同日志中的两个条目具有相同的索引和期限，则它们存储相同的命令。</li><li>如果不同日志中的两个条目具有相同的索引和期限，则前面所有条目的日志都相同。</li></ul><p>​第一个属性源于这样一个事实，即leader在给定的期限内最多创建一个具有给定日志索引的条目，并且日志条目永远不会改变其在日志中的位置。第二个属性由AppendEntries执行的简单一致性检查保证。当发送AppendEntries RPC时，leader在其日志中包含条目的索引和期限，该条目立即位于新条目之前。如果跟随者在其日志中没有找到具有相同索引和期限的条目，则拒绝新条目。一致性检查作为一个归纳步骤:日志的初始空状态满足日志匹配属性，无论何时扩展日志，一致性检查都保持日志匹配属性。因此，每当AppendEntries成功返回时，leader就知道follower的日志与它自己的日志通过新条目相同。</p><p>​正常运行时，leader和follower的日志是一致的，所以AppendEntries一致性检查不会失败。但是，leader崩溃可能导致日志不一致(旧leader可能没有完全复制其日志中的所有条目)。这些不一致可能会在一系列领导者和追随者的崩溃中加剧。图7说明了追随者的日志可能与新领导者的不同之处。follower可能缺少leader上存在的条目，也可能有leader上没有的额外条目，或者两者兼而有之。日志中缺少的和无关的条目可能跨越多个术语。</p><p>​在Raft中，领导者通过强迫追随者的日志复制自己的日志来处理不一致。这意味着跟随者日志中的冲突条目将被来自领导者日志的条目覆盖。第5.4节将说明，如果加上另外一个限制，这样做是安全的。</p><p>​为了使追随者的日志与自己的日志保持一致，领导者必须找到两个日志一致的最新日志条目，删除追随者日志中在该点之后的任何条目，并将领导者在该点之后的所有条目发送给追随者。所有这些操作都是对AppendEntries rpc执行的一致性检查的响应。leader为每个follower维护一个nextindex，这是leader将发送给该follower的下一个日志条目的索引。当leader首次掌权时，它将所有nextIndex值初始化为日志中最后一个值之后的索引(图7中的11)。如果follower的日志与leader的日志不一致，AppendEntries一致性检查将在下一个AppendEntries RPC中失败。拒绝后，leader减少nextIndex并重试AppendEntries RPC。最终nextIndex将达到领导者和追随者日志匹配的点。当这种情况发生时，AppendEntries将成功，它将删除follower日志中的任何冲突条目，并从leader日志中添加条目(如果有的话)。一旦AppendEntries成功，跟随者的日志与领导者的日志一致，并且在任期的剩余时间内保持这种状态。</p><p>​如果需要，可以优化协议以减少被拒绝的AppendEntries rpc的数量。例如，在拒绝AppendEntries请求时，follower可以包含冲突条目的项和它为该项存储的第一个索引。有了这些信息，leader就可以对nextIndex进行减量以绕过该项中所有冲突的表项;每个有冲突条目的术语需要一个AppendEntries RPC，而不是每个条目一个RPC。在实践中，我们怀疑这种优化是否必要，因为故障很少发生，而且不太可能有许多不一致的条目。</p><p>​有了这种机制，当涉及到权力时，领导者不需要采取任何特殊操作来恢复日志一致性。它只是开始正常操作，并且日志会自动收敛，以响应追加条目一致性检查失败。leader永远不会覆盖或删除自己日志中的条目(图3中的leader追加属性)。</p><p>​这种日志复制机制展示了第2节中描述的理想的共识属性:只要大多数服务器正常运行，Raft就可以接受、复制和应用新的日志条目;在正常情况下，一个新条目可以通过一轮rpc复制到集群的大多数;一个缓慢的追随者不会影响你的表现。</p><h3 id="V-4-安全"><a href="#V-4-安全" class="headerlink" title="V.4 安全"></a>V.4 安全</h3><p>​前面的小节描述了Raft如何选择leader和复制日志条目。然而，到目前为止所描述的机制还不足以确保每个状态机以相同的顺序执行完全相同的命令。例如，当leader提交多个日志条目时，follower可能不可用，那么它可以被选为leader并用新的条目覆盖这些条目;因此，不同的状态机可能执行不同的命令序列。</p><p>​本节通过添加服务器可以被选为领导者的限制来完成Raft算法。该限制确保任何给定任期的leader包含在前一任期中提交的所有条目(图3中的leader完整性属性)。考虑到选举限制，我们将使提交规则更加精确。最后，我们给出了Leader完备性的证明草图，并展示了它如何导致复制状态机的正确行为。</p><h4 id="V-4-1-选举限制"><a href="#V-4-1-选举限制" class="headerlink" title="V.4.1 选举限制"></a>V.4.1 选举限制</h4><p>​在任何基于领导者的共识算法中，领导者最终必须存储所有已提交的日志条目。在一些共识算法中，如Viewstamped replication，即使leader最初没有包含所有提交的条目，也可以被选举出来。这些算法包含额外的机制来识别缺失的条目，并在选举过程中或之后不久将它们传输给新的领导者。不幸的是，这会导致相当多的附加机制和复杂性。Raft使用了一种更简单的方法，它保证从每一个新的leader被选举的那一刻起，所有以前的承诺条目都存在于leader上，而不需要将这些条目转移到leader上。这意味着日志条目只在一个方向上流动，从领导者到追随者，并且领导者永远不会覆盖其日志中的现有条目。</p><p>​Raft使用投票过程来阻止候选人赢得选举，除非其日志包含所有已提交的条目。候选人必须与集群的大多数成员联系才能当选，这意味着每个提交的条目必须至少出现在其中一台服务器中。如果候选日志至少与大多数日志中的任何其他日志一样最新(“最新”的定义在下面)，那么它将保存所有已提交的条目。RequestVote RPC实现了这个限制:RPC包含关于候选人日志的信息，如果投票人自己的日志比候选人的日志更新，投票人就拒绝投票。</p><p>​Raft通过比较日志中最后条目的索引和期限来确定两个日志中哪一个是最新的。如果日志的最后条目具有不同的术语，那么具有后一个术语的日志是最新的。如果日志以相同的期限结束，那么哪个日志越长，哪个日志就越最新。</p><h4 id="V-4-2-提交以前的条目"><a href="#V-4-2-提交以前的条目" class="headerlink" title="V.4.2 提交以前的条目"></a>V.4.2 提交以前的条目</h4><p><img src="/../imgs/raft-1/image-20240315215118470.png" alt="图8"></p><p>​如5.3节所述，leader知道，一旦条目被存储在大多数服务器上，它当前期限的条目就被提交。如果leader在提交条目之前崩溃，未来的leader将尝试完成对条目的复制。然而，一个leader不能立即得出结论，一个前一个term的条目一旦存储在大多数服务器上就被提交了。图8说明了一种情况，其中旧日志条目存储在大多数服务器上，但仍然可以被未来的领导者覆盖。</p><p>​为了消除图8所示的问题，Raft不会通过计算副本来提交以前条目中的日志条目。通过计算副本，只提交leader当前任期内的日志条目;一旦以这种方式提交了当前项中的一个条目，那么由于日志匹配属性，所有先前的条目都将间接提交。在某些情况下，leader可以安全地得出一个较旧的日志条目已提交的结论(例如，如果该条目存储在每个服务器上)，但是Raft为了简单起见采用了更保守的方法。</p><p>​Raft在承诺规则中引入了这种额外的复杂性，因为当leader复制前一项的条目时，日志条目保留其原始的条目编号。在其他共识算法中，如果一个新的leader从先前的“term”中重复复制条目，它必须使用新的“term number”。Raft的方法可以更容易地推断日志条目，因为它们在不同的时间和日志中保持相同的项数。此外，Raft中的新leader发送的以前条目的日志条目比其他算法少(其他算法必须发送冗余的日志条目来重新编号，然后才能提交)。</p><h4 id="V-4-3-安全论证"><a href="#V-4-3-安全论证" class="headerlink" title="V.4.3 安全论证"></a>V.4.3 安全论证</h4><p><img src="/../imgs/raft-1/image-20240315215633177.png" alt="图9:如果S1(任期T的领导者)从其任期提交了一个新的日志条目，并且S5被选为下一个任期U的领导者，那么必须至少有一个服务器(S3)接受该日志条目并投票给S5。"></p><p>​给定完整的Raft算法，我们现在可以更精确地论证Leader完备性成立(这个论证是基于安全证明;参见9.2节)。我们假设领先者完备性不成立，然后我们证明了一个矛盾。假设任期T的leader (leaderT)提交了一个来自其术语的日志条目，但是该日志条目没有被某个未来术语的leader存储。考虑最小的任期 U &gt; T，其leader (leaderU)不存储条目。</p><ol><li>承诺的条目必须在其选举时从领导u的日志中消失(领导永远不会删除或覆盖条目)。</li><li>leaderT在大多数集群上复制条目，而leaderU收到大多数集群的投票。因此，至少有一个服务器(“投票人”)接受了来自leaderT的条目并投票给了leadu，如图9所示。选民是达成矛盾的关键。</li><li>投票人必须在投票给leadt之前接受leadt的承诺条目;否则，它将拒绝来自leaderT的AppendEntries请求(其当前项将高于T)。</li><li>投票人在投票给领导u时仍然存储该条目，因为每个介入的领导都包含该条目(假设)，领导永远不会删除条目，而追随者只有在与领导冲突时才删除条目。</li><li>投票人将其选票授予了leaderU，因此leaderU的日志必须与投票人的日志一样是最新的。这导致了两个矛盾之一。</li><li>首先，如果投票者和leaderU共享相同的最后一个日志项，那么leaderU的日志必须至少和投票者的日志一样长，所以它的日志包含投票者日志中的每一个条目。这是一个矛盾，因为选民包含承诺的条目，而领导人被认为没有。</li><li>否则，领导人u的上一个对数项一定大于选民的对数项。而且，它比T大，因为投票人的最后一个日志项至少是T(它包含来自项T的承诺条目)。创建leadu的最后一个日志项的较早的领导者必须在其日志中包含承诺条目(通过假设)。那么，根据日志匹配属性，leaderU的日志必须也包含提交的条目，这是一个矛盾。</li><li>这就解决了矛盾。因此，所有大于T的项的前导必须包含所有在T项中提交的来自T项的项。</li><li>Log Matching Property保证未来的leader也将包含间接提交的条目，如图8(d)中的索引2。</li></ol><p>​间接地，如图8(d)中的索引2。给定Leader完整性属性，我们可以证明图3中的状态机安全属性，该属性表明，如果服务器在给定索引上应用了一个日志条目到其状态机，那么其他服务器将不会为相同的索引应用不同的日志条目。当服务器将一个日志条目应用到它的状态机时，它的日志必须与该条目之前的领导日志相同，并且该条目必须提交。现在考虑任何服务器应用给定日志索引的最低期限;日志完整性属性保证所有较高项的leader将存储相同的日志条目，因此在较低项中应用索引的服务器将应用相同的值。因此，状态机安全属性保持不变。</p><p>​最后，Raft要求服务器按照日志索引顺序应用条目。结合状态机安全属性，这意味着所有服务器将以相同的顺序向其状态机应用完全相同的日志条目集。</p><h3 id="V-5-追随者和候选人崩溃"><a href="#V-5-追随者和候选人崩溃" class="headerlink" title="V.5 追随者和候选人崩溃"></a>V.5 追随者和候选人崩溃</h3><p>​到目前为止，我们关注的是领导者的失败。跟随者和候选者崩溃比领导者崩溃更容易处理，它们的处理方式是一样的。如果一个follower或candidate崩溃，那么以后发送给它的RequestVote和AppendEntries rpc将失败。Raft通过无限重试来处理这些失败;如果崩溃的服务器重新启动，那么RPC将成功完成。如果服务器在完成RPC之后但在响应之前崩溃，那么它将在重新启动后再次接收相同的RPC。Raft rpc是幂等的，所以这不会造成伤害。例如，如果追随者接收到一个AppendEntries请求，该请求包含其日志中已经存在的日志条目，那么它将忽略新请求中的这些条目。</p><h3 id="V-6-时间和可用性"><a href="#V-6-时间和可用性" class="headerlink" title="V.6 时间和可用性"></a>V.6 时间和可用性</h3><p>​我们对Raft的要求之一是安全性不能依赖于时间:系统不能仅仅因为某些事件发生得比预期的快或慢而产生不正确的结果。然而，可用性(系统及时响应客户机的能力)必须不可避免地依赖于时间。例如，如果消息交换的时间比服务器崩溃之间的典型时间长，候选人就不会坚持足够长的时间来赢得选举;没有稳定的领导，Raft就无法前进。</p><p>​领袖选举是Raft中最关键的环节。只要系统满足以下时间要求，Raft就能够选出并维持一个稳定的leader:</p><p>​<font color='red'>broadcastTime≪ electionTimeout ≪ MTBF</font> </p><p>​在这个不等式中，broadcastTime是服务器向集群中的每个服务器并行发送rpc并接收它们的响应所需的平均时间;electionTime-out是5.2节中描述的选举超时;MTBF是单个服务器的平均故障间隔时间。广播时间应该比选举超时时间少一个数量级，这样领导者才能可靠地发送心跳消息，以防止追随者开始选举;考虑到用于选举暂停的随机方法，这种不平等也使得分裂投票不太可能。选举超时应该比MTBF小几个数量级，这样系统才能稳步前进。当leader崩溃时，系统将在选举超时期间不可用;我们希望这只代表总时间的一小部分。</p><p>​广播时间和MTBF是底层系统的属性，而选举超时是我们必须选择的。Raft的rpc通常要求接收方将信息持久化到稳定的存储中，因此广播时间可能在0.5ms到20ms之间，具体取决于存储技术。因此，选举超时可能在10ms到500ms之间。典型的服务器mtbf是几个月或更长时间，这很容易满足时间需求。</p><h2 id="VI-集群成员变更"><a href="#VI-集群成员变更" class="headerlink" title="VI 集群成员变更"></a>VI 集群成员变更</h2><p><img src="/../imgs/raft-1/image-20240315220334863.png" alt="图10"></p><p>​到目前为止，我们已经假设集群配置(参与共识算法的服务器集)是固定的。在实践中，有时需要更改配置，例如在服务器发生故障时更换服务器或更改复制的程度。虽然这可以通过使整个集群脱机、更新配置文件、然后重新启动集群来实现，但这会使集群在转换期间不可用。此外，如果有任何手动步骤，则有操作员出错的风险。为了避免这些问题，我们决定将配置更改自动化，并将其合并到Raft共识算法中。</p><p>​为了保证配置变更机制的安全性，在过渡期间不可能出现两名领导人在同一任期内当选的情况。不幸的是，服务器直接从旧配置切换到新配置的任何方法都是不安全的。一次自动切换所有服务器是不可能的，因此集群可能在转换期间分裂成两个独立的多数(参见图10)。</p><p>​为了确保安全，配置更改必须使用两阶段方法。有多种方法可以实现这两个阶段。例如，一些系统(例如，[22])使用第一阶段禁用旧配置，因此它不能处理客户端请求;然后，第二阶段启用新配置。在Raft中，集群首先切换到我们称之为联合共识的过渡配置;一旦联合共识被提交，系统就会转换到新的配置。联合共识结合了新旧两种配置:</p><ul><li>日志条目被复制到两种配置中的所有服务器。</li><li>任一配置中的任何服务器都可以作为leader。</li><li>协议(对于选举和进入承诺)需要从旧的和新的配置中分离多数。</li></ul><p>​联合共识允许单个服务器在不同的时间在配置之间转换，而不会出现安全问题。此外，联合共识允许集群在整个配置更改期间继续为客户机请求提供服务。</p><p>​集群配置使用复制日志中的特殊条目进行存储和通信;图11说明了配置更改过程。当leader接收到将配置从Cold更改为C（new）的请求时，它将联合共识(图中为C（old,new）)的配置存储为日志条目，并使用前面描述的机制复制该条目。一旦给定的服务器将新的配置条目添加到其日志中，它就会在以后的所有决策中使用该配置(服务器总是在其日志中使用最新的配置，而不管该条目是否已提交)。这意味着领导者将使用C（old,new）的规则来确定何时提交C（old,new）的日志条目。如果leader崩溃，根据获胜的候选人是否收到了Cold,new，来选择一个新的leader。无论如何，在此期间，中国不能做出单方面的决定。</p><p><img src="/../imgs/raft-1/image-20240315225354334.png" alt="图11"></p><p>​一旦提交了Cold,new，两个服务器都不能在未经对方批准的情况下做出决定，并且Leader完整性属性确保只有具有C（old,new）日志条目的服务器才能被选为Leader。现在，leader可以安全地创建描述C（new）的日志条目并将其复制到集群中。同样，一旦看到此配置，该配置将在每个服务器上生效。当在C（new）规则下提交新配置时，旧配置是不相关的，不在新配置中的服务器可以关闭。如图11所示，不存在C（old）和C（new）同时做出单边决策的情况;这保证了安全。</p><p>​对于重新配置，还有三个问题需要解决。第一个问题是，新服务器最初可能不存储任何日志条目。如果以这种状态将它们添加到集群中，它们可能需要一段时间才能赶上进度，在此期间可能无法提交新的日志条目。为了避免可用性差距，Raft在配置更改之前引入了一个额外的阶段，在这个阶段中，新服务器作为无投票成员加入集群(leader向它们复制日志条目，但它们不被认为是majority)。一旦新服务器赶上了集群的其余部分，就可以按照上面的描述进行重新配置。</p><p>​第二个问题是集群领导者可能不是新配置的一部分。在这种情况下，leader一旦提交了C（new）日志条目，就会退出(返回到follower状态)。这意味着会有一段时间(当它正在提交C(new)时)，当leader管理一个不包括它自己的集群时;它复制日志条目，但不认为自己占多数。leader转换发生在C（new）提交时，因为这是新配置可以独立操作的第一个点(总是可以从C(new)中选择leader)。在此之前，可能只有来自C(old)的服务器可以被选为leader。</p><p>​第三个问题是被移除的服务器(不在C(new)中的服务器)可能会破坏集群。这些服务器将不会接收到心跳，因此它们将超时并开始新的选举。然后，它们将发送带有新术语号的RequestVote rpc，这将导致当前的领导者恢复到追随者状态。新的领导人最终会被选举出来，但是被移除的服务器会再次超时，这个过程会重复，导致可用性差。</p><p>​为了防止这个问题，当服务器认为当前的leader存在时，它们会忽略RequestVote rpc。具体地说，如果服务器在听取当前领导者的最小选举超时时间内收到RequestVote RPC，则它不会更新其任期或授予其投票。这不会影响正常的选举，其中每个服务器在开始选举之前至少等待最小的选举超时。然而，它有助于避免被移除的服务器造成的中断:如果一个leader能够将心跳传送到它的集群，那么它就不会被更大的term number所取代。</p><h2 id="VII-日志压缩"><a href="#VII-日志压缩" class="headerlink" title="VII 日志压缩"></a>VII 日志压缩</h2><p>​Raft的日志在正常运行期间会增长，以包含更多的客户端请求，但在实际系统中，它不能无限制地增长。随着日志变长，它会占用更多的空间，并且需要更多的时间来重放。如果没有某种机制来丢弃日志中积累的过时信息，这将最终导致可用性问题。</p><p>​快照是最简单的压缩方法。在快照中，整个当前系统状态被写入稳定存储上的快照，然后直到该点的整个日志被丢弃。快照在Chubby和ZooKeeper中使用，本节的其余部分描述了Raft中的快照。</p><p>​增量压缩方法，如日志清理和日志结构合并树，也是可能的。它们一次对一小部分数据进行操作，因此它们随着时间的推移更均匀地分散了压缩的负载。它们首先选择一个数据区域，该区域累积了许多已删除和覆盖的对象，然后更紧凑地重写该区域的活动对象，并释放该区域。与快照相比，这需要大量额外的机制和复杂性，快照通过始终对整个数据集进行操作来简化问题。虽然日志清理需要修改Raft，但状态机可以使用与快照相同的接口实现LSM树。</p><p><img src="/../imgs/raft-1/image-20240315225801111.png" alt="图12"></p><p>​图12显示了Raft中快照的基本思想。每个服务器独立地获取快照，只覆盖其日志中提交的条目。大部分工作包括状态机将其当前状态写入快照。Raft还在快照中包含少量元数据:最后包含的索引是快照替换的日志中最后一个条目的索引(状态机应用的最后一个条目)，最后包含的术语是该条目的术语。保留这些内容是为了支持对快照之后的第一个日志条目进行AppendEntries一致性检查，因为该条目需要之前的日志索引和期限。为了启用集群成员变更(第6节)，快照还包括日志中上次包含索引时的最新配置。一旦服务器完成对快照的写入，它可能会删除直到最后包含的索引的所有日志条目，以及任何先前的快照。</p><p>​虽然服务器通常会独立地拍摄快照，但领导者偶尔必须向落后的追随者发送快照。当领导者已经丢弃了它需要发送给追随者的下一个日志条目时，就会发生这种情况。幸运的是，在正常操作中不太可能出现这种情况:跟随领导者的追随者已经有了这个条目。但是，异常缓慢的追随者或加入集群的新服务器(第6节)不会这样做。让这样的追随者与时俱进的方法是，领导者通过网络向其发送快照。</p><p><img src="/../imgs/raft-1/image-20240315225927519.png" alt="图13:InstallSnapshot RPC的摘要。快照被分成块进行传输;这为follower提供了每个块的生命迹象，因此它可以重置其选举计时器。"></p><p>​leader使用一个名为InstallSnapshot的新RPC向远远落后的follower发送快照;参见图13。当跟踪者接收到带有此RPC的快照时，它必须决定如何处理其现有的日志条目。通常，快照将包含收件人日志中尚未包含的新信息。在这种情况下，追随者丢弃其整个日志;它全部被快照取代，并且可能有与快照冲突的未提交条目。如果跟随者接收到描述其日志前缀的快照(由于重传或错误)，则快照所涵盖的日志条目将被删除，但快照后面的条目仍然有效，必须保留。</p><p>​这种快照方法违背了Raft的强领导原则，因为追随者可以在领导者不知情的情况下拍摄快照。然而，我们认为这种离开是合理的。虽然有一个领导者有助于在达成共识时避免冲突的决策，但在快照时已经达成了共识，因此没有决策冲突。数据仍然只能从领导者流向追随者，现在只有追随者可以重组他们的数据。</p><p>​我们考虑了另一种基于领导者的方法，其中只有领导者创建快照，然后将此快照发送给其每个追随者。然而，这有两个缺点。首先，将快照发送给每个关注者会浪费网络带宽并减慢快照进程。每个follower都已经拥有了生成自己的快照所需的信息，对于服务器来说，从其本地状态生成快照通常比通过网络发送和接收快照要便宜得多。其次，领导人的执行将更加复杂。例如，领导者需要向追随者发送快照，同时向他们复制新的日志条目，以便不阻止新的客户机请求。</p><p>​还有两个问题会影响快照性能。首先，服务器必须决定何时快照。如果服务器快照太频繁，会浪费磁盘带宽和能量;如果它的快照频率太低，就有耗尽存储容量的风险，并且会增加重新启动期间重播日志所需的时间。一个简单的策略是在日志达到固定大小(以字节为单位)时拍摄快照。如果将此大小设置为明显大于快照的预期大小，则用于快照的磁盘带宽开销将很小。</p><p>​第二个性能问题是，编写快照可能会花费大量时间，我们不希望这会延迟正常操作。解决方案是使用写时复制(copy-on-write)技术，这样就可以接受新的更新，而不会影响正在写入的快照。例如，用函数数据结构构建的状态机自然支持这一点。或者，可以使用操作系统的写时复制支持(例如Linux上的fork)来创建整个状态机的内存快照(我们的实现使用这种方法)。</p><h2 id="IIX-客户端交互"><a href="#IIX-客户端交互" class="headerlink" title="IIX 客户端交互"></a>IIX 客户端交互</h2><p>​本节描述客户端如何与Raft交互，包括客户端如何找到集群领导者以及Raft如何支持线性化语义。这些问题适用于所有基于共识的系统，Raft的解决方案与其他系统类似。</p><p>​Raft的客户将他们所有的请求发送给leader。当客户机第一次启动时，它连接到一个随机选择的服务器。如果客户端的第一选择不是leader，服务器将拒绝客户端的请求，并提供最近收到的leader的信息(AppendEntries请求包括leader的网络地址)。如果leader崩溃，客户端请求将超时;然后客户端使用随机选择的服务器再次尝试。</p><p>​Raft的目标是实现可线性化的语义(每个操作在调用和响应之间的某个点上似乎是瞬间执行的，只执行一次)。然而，正如目前所描述的，Raft可以多次执行命令:例如，如果leader在提交日志条目之后崩溃，但在响应客户端之前，客户端将使用新的leader重试命令，导致它被执行第二次。解决方案是让客户端为每个命令分配唯一的序列号。然后，状态机跟踪为每个客户机处理的最新序列号，以及相关的响应。如果它接收到一个序列号已经被执行的命令，它会立即响应而不重新执行请求。</p><p>​可以在不向日志中写入任何内容的情况下处理只读操作。然而，如果没有额外的措施，这将有返回陈旧数据的风险，因为响应请求的leader可能已经被它不知道的新leader所取代。可linearizable读一定不能返回陈旧的数据，Raft需要两个额外的预防措施来保证这一点，而不使用日志。首先，leader必须拥有提交条目的最新信息。Leader完整性属性保证Leader拥有所有已提交的条目，但在其任期开始时，Leader可能不知道哪些是已提交的条目。为了找出答案，它需要提交其任期中的一个条目。Raft通过让每个leader在其任期开始时提交一个空白的无操作条目到日志中来处理这个问题。其次，leader必须在处理一个只读请求之前检查它是否已经被废弃(如果一个最近的leader被选举出来，它的信息可能是陈旧的)。Raft通过让leader在响应只读请求之前与大多数集群交换心跳消息来处理这个问题。或者，leader可以依赖心跳机制来提供一种形式的租约[9]，但这将依赖于安全的定时(它假设有界时钟倾斜)。</p><h2 id="IX-执行与评估"><a href="#IX-执行与评估" class="headerlink" title="IX 执行与评估"></a>IX 执行与评估</h2><p>​我们已经将Raft作为复制状态机的一部分实现，该状态机存储RAMCloud的配置信息，并协助RAMCloud协调器的故障转移。Raft实现包含大约2000行c++代码，不包括测试、注释或空白行。源代码是免费提供的。根据本文的草稿，目前大约有25个独立的第三方开源的Raft实现[34]处于不同的开发阶段。此外，许多公司正在部署基于raft的系统。</p><p>​本节的其余部分使用三个标准来评估Raft:可理解性、正确性和性能。</p><h3 id="IX-1-可理解性"><a href="#IX-1-可理解性" class="headerlink" title="IX.1 可理解性"></a>IX.1 可理解性</h3><p><img src="/../imgs/raft-1/image-20240315230558611.png" alt="图15"></p><p>​为了衡量Raft相对于Paxos的可理解性，我们对斯坦福大学高级操作系统课程和加州大学伯克利分校分布式计算课程的高年级本科生和研究生进行了一项实验研究。我们录制了Raft和Paxos的视频讲座，并制作了相应的小测验。Raft讲座涵盖了这篇论文的内容，除了原木的压缩;Paxos讲座涵盖了足够的材料来创建一个等效的复制状态机，包括单命令Paxos、多命令Paxos、重新配置和实践中需要的一些优化(例如领导者选举)。这些测试测试了学生对算法的基本理解，也要求他们对极端情况进行推理。每个学生看了一个视频，做了相应的测试，看了第二个视频，做了第二个测试。大约一半的参与者先做了Paxos部分，另一半先做了Raft部分，以解释个人在表现和从第一部分研究中获得的经验上的差异。我们比较了参与者在每个测验中的得分，以确定参与者是否对Raft有更好的理解。</p><p>​我们试图在Paxos和Raft之间进行尽可能公平的比较。实验在两个方面对Paxos有利:43名参与者中有15人报告说他们之前有过Paxos的一些经验，Paxos的视频比Raft的视频长14%。如表1所示，我们已采取措施减轻潜在的偏倚来源。我们所有的资料都可以查阅。</p><p>​平均而言，参与者在Raft测试中的得分比Paxos测试高4.9分(在可能的60分中，Raft的平均得分为25.7分，Paxos的平均得分为20.8分);图14显示了他们的个人分数。配对t检验表明，在95%的置信度下，Raft分数的真实分布均值至少比Paxos分数的真实分布均值大2.5分。</p><p>​我们还创建了一个线性回归模型，可以根据三个因素预测新学生的测验分数:他们参加的测验，他们之前Paxos的经验程度，以及他们学习算法的顺序。该模型预测，测验的选择会产生12.5分的差异，从而有利于Raft。这明显高于观察到的4.9分的差异，因为许多实际学生之前都有Paxos的经验，这对Paxos有很大帮助，而对Raft的帮助略小。奇怪的是，该模型还预测，已经参加过Paxos测试的人在Raft上的得分要低6.3分;虽然我们不知道为什么，但这在统计上确实很重要。</p><p>​我们还在测试结束后对参与者进行了调查，看看他们觉得哪种算法更容易实现或解释;这些结果如图15所示。绝大多数参与者表示Raft更容易实现和解释(每个问题41个中有33个)。然而，这些自我报告的感觉可能不如参与者的测验分数可靠，参与者可能因为我们的假设(Raft更容易理解)而有偏见。</p><h3 id="IX-2-正确性"><a href="#IX-2-正确性" class="headerlink" title="IX.2 正确性"></a>IX.2 正确性</h3><p>​我们已经开发了第5节中描述的共识机制的正式规范和安全性证明。正式规范[31]使用TLA+规范语言[17]使得图2中总结的信息完全精确。它大约有400行，是证明的主体。对于任何实现Raft的人来说，它本身也很有用。我们已经用TLA证明系统[7]机械地证明了对数完备性。然而，这种证明依赖于没有经过机械检查的不变量(例如，我们还没有证明规范的类型安全性)。此外，我们已经写了一个状态机安全属性的非正式证明[31]，它是完整的(它只依赖于规范)和相对精确的(大约3500字长)。</p><h3 id="IX-3-性能"><a href="#IX-3-性能" class="headerlink" title="IX.3 性能"></a>IX.3 性能</h3><p><img src="/../imgs/raft-1/image-20240315230821442.png" alt="图16:检测和替换崩溃的leader的时间。顶部的图改变了选举超时的随机性，底部的图缩放了最小的选举超时。每条线代表1000次试验(“150-150ms”的100次试验除外)，对应于一个特定的选举超时选择;例如，“150-155ms”表示在150ms到155ms之间随机且均匀地选择选举超时。这些测量是在一个由5个服务器组成的集群上进行的，广播时间大约为15毫秒。对于包含9台服务器的集群，结果类似。"></p><p>​Raft的性能与Paxos等其他共识算法类似。对于性能来说，最重要的情况是当一个已建立的leader复制新的日志条目时。Raft使用最少数量的消息(从leader到一半集群的单次往返)实现了这一点。也有可能进一步提高Raft的性能。例如，它很容易支持批处理和流水线请求，以获得更高的吞吐量和更低的延迟。文献中对其他算法提出了各种优化;其中许多可以应用到Raft中，但我们将其留给未来的工作。</p><p>​我们使用Raft实现来衡量Raft领导者选举算法的性能，并回答了两个问题。首先，选举过程会很快趋同吗?其次，在leader崩溃后可以实现的最小停机时间是多少?</p><p>​为了测量leader的选举，我们反复地使一个由5个服务器组成的集群的leader崩溃，并计算检测到崩溃和选举新leader所花费的时间(参见图16)。为了产生最坏的情况，每个试验中的服务器具有不同的日志长度，因此一些候选人没有资格成为领导者。此外，为了鼓励分裂投票，我们的测试脚本在终止其进程之前触发了来自leader的心跳rpc的同步广播(这近似于leader在崩溃之前复制新日志条目的行为)。leader在心跳间隔内均匀随机崩溃，心跳间隔为所有测试的最小选举超时的一半。因此，最小的可能停机时间大约是最小选举超时的一半。</p><p>​图16中最上面的图表显示，选举超时中的少量随机化足以避免选举中的分裂投票。在没有随机性的情况下，在我们的测试中，由于许多选票分裂，领导人选举持续花费超过10秒的时间。仅仅增加5ms的随机性就有很大帮助，导致停机时间中值为287ms。使用更多的随机性可以改善最坏情况下的行为:当随机性为50ms时，最坏情况下的完成时间(超过1000次试验)为513ms。</p><p>​图16底部的图表显示，可以通过减少选举超时来减少停机时间。在选举超时为12-24ms的情况下，平均只需35ms就能选出一个leader(最长的一次试验花费了152ms)。然而，将超时时间降低到超过这个点违反了Raft的时间要求:在其他服务器开始新的选举之前，领导者很难广播心跳。这可能导致不必要的领导更改，并降低整个系统的可用性。我们建议使用保守的选举超时，例如150-300ms;这样的暂停不太可能导致不必要的领导人变动，而且仍然会提供良好的可用性。</p><h2 id="X-总结"><a href="#X-总结" class="headerlink" title="X 总结"></a>X 总结</h2><p>​算法的设计通常以正确性、效率和&#x2F;或简洁性为主要目标。虽然这些都是有价值的目标，但我们相信可理解性同样重要。在开发人员将算法转化为实际实现之前，其他目标都无法实现，而实际实现将不可避免地偏离并扩展已发布的形式。除非开发人员对算法有深刻的理解，并且能够创建关于它的直觉，否则他们很难在实现中保留其理想的属性。</p><p>​在本文中，我们讨论了分布式共识的问题，其中一个被广泛接受但难以理解的算法Paxos多年来一直挑战着学生和开发人员。我们开发了一种新的算法Raft，我们已经证明它比Paxos更容易理解。我们也相信Raft为系统构建提供了更好的基础。将可理解性作为主要设计目标改变了我们设计《Raft》的方式;随着设计的进展，我们发现自己重复使用了一些技术，比如分解问题和简化状态空间。这些技术不仅提高了Raft的可理解性，而且使我们更容易相信它的正确性。</p>]]></content>
    
    
    <categories>
      
      <category>mit6.824</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式系统</tag>
      
      <tag>mit6.824</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>mapreduce</title>
    <link href="/2024/03/14/mapreduce/"/>
    <url>/2024/03/14/mapreduce/</url>
    
    <content type="html"><![CDATA[<h1 id="MapReduce-在大型集群上的简易数据处理"><a href="#MapReduce-在大型集群上的简易数据处理" class="headerlink" title="MapReduce:在大型集群上的简易数据处理"></a>MapReduce:在大型集群上的简易数据处理</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>​MapReduce是一种用于处理和生成大型数据集的编程模型和相关实现。用户使用map函数处理kv对，生成一个中间value和中间key，使用reduce函数merge所有的中间kv键。很多现实世界任务都可以用这个模型来表示。</p><p>​用这种函数式风格编写的程序被自动并行化，并在大量的商用机器上执行。运行时系统负责对输入数据进行分区、在一组机器上调度程序的执行、处理机器故障以及管理所需的机器间通信等细节。这让程序员不需要理解并行和分布式系统就能很轻易地使用大型分布式系统的资源。</p><h2 id="1-介绍-sweat-drops"><a href="#1-介绍-sweat-drops" class="headerlink" title="1 介绍:sweat_drops:"></a>1 介绍:sweat_drops:</h2><p>​在过去的五年中，作者和谷歌的许多其他人已经实现了数百种特殊用途的计算，这些计算处理大量的原始数据，如抓取的文档、web请求日志等，以计算各种派生数据，如倒排索引、web文档的图形结构的各种表示、每个主机抓取的页面数量的摘要、给定一天中最频繁的查询集等。大多数这样的计算在概念上是直截了当的。然而，输入数据通常很大，计算必须分布在数百或数千台机器上，以便在合理的时间内完成。如何并行化计算、分布数据和处理故障等问题，使得原始的简单计算用大量复杂的代码来处理这些问题变得模糊不清。</p><p>​作为对这种复杂性的反应，我们设计了一个新的抽象，它允许我们表达我们试图执行的简单计算，但隐藏了库中并行化、容错、数据分布和负载平衡的混乱细节。我们的抽象受到Lisp和其他函数式语言中map和reduce原语的启发。我们意识到，大多数计算涉及对输入中每个逻辑“记录”应用map操作，以计算一组中间键&#x2F;值对，然后对共享同一键的所有值应用reduce操作，以便适当地组合派生数据。通过使用带有用户指定map和reduce操作的功能模型，我们能够轻松并行化大型计算，并将重新执行作为主要容错机制。</p><p>​这个工作的主要贡献是一个简单但强大的支持大规模计算的自动并行化和分布的接口。与此接口的实现相结合，在大型商用pc集群上实现高性能。第2节描述了基本的编程模型，并给出了几个示例。第3节描述了针对基于集群的计算环境量身定制的MapReduce接口的实现。第4节描述了我们认为有用的编程模型的几个改进。第5节对各种任务的实现进行了性能度量。第6节探讨了MapReduce在Google中的使用，包括我们使用它作为重写我们的生产索引系统的基础的经验。第7节讨论了相关的和未来的工作。</p><h2 id="2-编程模型-sweat-drops"><a href="#2-编程模型-sweat-drops" class="headerlink" title="2 编程模型:sweat_drops:"></a>2 编程模型:sweat_drops:</h2><p>​计算需要一组kv对输入，并且输出一组kv对。<strong>mapreduce</strong>主要是两个函数：<strong>Map</strong>和<strong>Reduce</strong>。</p><p>​<strong>Map</strong>接受一个输入对并且产生一个中间kv对。MapReduce库将与中间key<strong>I</strong>相同的的所有中间值分组，并且把它们传递到Reduce函数中。</p><p>​<strong>Reduce</strong>函数接受一个中间key<strong>I</strong>和一组与key相对应的value，它将这些value合并起来形成一个可能更小的值集，一般是输出一个key一个value。中间值通过迭代器提供给用户的reduce函数。这允许我们处理大到内存无法容纳的值列表。</p><h3 id="2-1-Example"><a href="#2-1-Example" class="headerlink" title="2.1 Example"></a>2.1 Example</h3><p>​单词计数器，伪代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">map</span>(String key, String value): <br>// key: document name <br>// value: document contents <br><span class="hljs-keyword">for</span> each word w <span class="hljs-keyword">in</span> value: <br>EmitIntermediate(w, <span class="hljs-string">&quot;1&quot;</span>); <br><br>reduce(String key, Iterator values): <br>// key: a word <br>// values: a <span class="hljs-built_in">list</span> of counts <span class="hljs-built_in">int</span> result = <span class="hljs-number">0</span>; <br><span class="hljs-keyword">for</span> each v <span class="hljs-keyword">in</span> values: <br>result += ParseInt(v); <br>Emit(AsString(result));<br></code></pre></td></tr></table></figure><p>​map函数发出每个单词加上相关的出现次数计数,reduce函数将针对特定单词发出的所有计数求和。</p><p>​此外，用户编写代码，用输入和输出文件的名称以及可选的调优参数填充mapreduce规范对象。然后，用户调用MapReduce函数，将规范对象传递给它。用户的代码与MapReduce库(用c++实现)链接在一起。附录A包含这个示例的完整程序文本。</p><h3 id="2-2-Types"><a href="#2-2-Types" class="headerlink" title="2.2 Types"></a>2.2 Types</h3><p>​尽管前面的伪代码是根据字符串输入和输出编写的，但从概念上讲，用户提供的map和reduce函数具有相关的类型:</p><p><img src="/../imgs/mapreduce/image-20240314162209411.png" alt="image-20240314162209411"></p><p>​输入键和值是从与输出键和值不同的域中绘制的。此外，中间键和值与输出键和值来自相同的domain。</p><p>​我们的c++实现将字符串传递给用户定义函数，并将其留给用户代码在字符串和适当类型之间进行转换。</p><h3 id="2-3-More-Examples"><a href="#2-3-More-Examples" class="headerlink" title="2.3 More Examples"></a>2.3 More Examples</h3><p>​Distributed Grep: 如果map函数匹配提供的模式，则会发出一行。reduce函数是一个恒等函数，它只是将提供的中间数据复制到输出。</p><p>​Count of URL Access Frequency: map函数处理web页面请求日志，输出&lt;URL,1&gt;。reduce函数将同一URL的所有值相加，并发出一个&lt; RL,total count&gt;对。</p><p>​Reverse Web-Link Graph: map函数为在名为source的页面中找到的每个指向目标URL的链接输出&lt;target,source&gt;对。reduce函数将与给定目标URL相关联的所有源URL的列表连接起来，并发出对:&lt;target, list(source)&gt;</p><p>​Term-Vector per Host: 术语向量是将文档或一组文档中最重要的单词总结为&lt;word, frequency&gt;对的列表。map函数会针对每个输入文档生成一个&lt;hostname, term vector&gt;对（其中主机名从文档的URL中提取）。reduce函数会合并给定主机下所有文档的术语向量，将它们相加，并丢弃不常见的术语，最终输出&lt;hostname, term vector&gt;对。</p><p>​Inverted Index: map函数解析每个文档，并发出&lt;word,document ID&gt;对的序列。reduce函数接受给定单词的所有对，对相应的文档ID进行排序并发出&lt;word, list(文档ID)&gt;对。所有输出对的集合形成一个简单的倒排索引。很容易增加这个计算来跟踪单词的位置。</p><p>​Distributed Sort: map函数从每个记录中提取键，并发出一个&lt;key,record&gt;对。reduce函数不加更改地发出所有对。这种计算依赖于第4.1节中描述的分区工具和第4.2节中描述的排序属性。</p><h2 id="3-实现"><a href="#3-实现" class="headerlink" title="3 实现"></a>3 实现</h2><p><img src="/../imgs/mapreduce/image-20240314163016983.png" alt="图1：执行概述"></p><p>​MapReduce接口可能有许多不同的实现。正确的选择取决于环境。例如，一种实现可能适用于小型共享内存机器，另一种适用于大型NUMA多处理器，还有一种适用于更大的联网机器集合。</p><p>​本节描述了针对Google广泛使用的计算环境的实现:大型商用pc集群通过交换以太网连接在一起。在我们的环境中:</p><ol><li>机器通常是运行Linux的双处理器x86处理器，每台机器有2-4 GB内存。</li><li>使用的是商用网络硬件——通常在机器级别上是100兆比特&#x2F;秒或1千兆比特&#x2F;秒，但总体对分带宽平均要少得多。</li><li>集群由数百或数千台机器组成，因此机器故障很常见。</li><li>存储由直接连接到单个机器上的廉价IDE磁盘提供。内部开发的分布式文件系统用于管理存储在这些磁盘上的数据。文件系统使用复制在不可靠的硬件之上提供可用性和可靠性。</li><li>用户向调度系统提交作业。每个作业由一组任务组成，并由调度器映射到集群中的一组可用机器。</li></ol><h3 id="3-1-执行概述"><a href="#3-1-执行概述" class="headerlink" title="3.1 执行概述"></a>3.1 执行概述</h3><p>​通过自动将输入数据划分为M段，Map调用可以在多台机器上进行分布式处理。不同的机器可以并行处理输入分割。Reduce调用是通过使用分区函数（例如hash(key) mod R）将中间键空间划分为R块来进行分发的。用户可以指定要使用的分区数量(R)和分区函数。</p><p>​图1显示了我们实现中MapReduce操作的整体流程。当用户程序调用MapReduce函数时，会发生以下一系列动作(图1中的编号标签对应于下面列表中的数字):</p><ol><li>MapReduce库将输入文件从m个16-64mb的小文件，然后，它在一个机器集群上启动该程序的许多副本。</li><li>这个节目的其中一份拷贝是特别的——master。其余的是由master分配工作的worker。有M个map任务和R个reduce任务要分配。主机选择空闲的worker，并为每个worker分配一个map任务或reduce任务。</li><li>被分配映射任务的worker线程读取相应输入分割的内容。它从输入数据中解析键&#x2F;值对，并将每对传递给用户定义的Map函数。Map函数产生的中间键&#x2F;值对在内存中进行缓冲。</li><li>周期性地将缓冲对写入本地磁盘，并通过分区函数划分为R个区域。这些缓冲对在本地磁盘上的位置被传递回主服务器，主服务器负责将这些位置转发给reduce worker。</li><li>当主服务器通知reduce worker有关这些位置时，它使用远程过程调用从map worker的本地磁盘读取缓冲数据。当reduce工作程序读取了所有中间数据后，它按中间键对数据进行排序，以便将所有出现的相同键分组在一起。排序是必要的，因为通常有许多不同的键映射到相同的reduce任务。如果中间数据量太大，内存无法容纳，则使用外部排序。</li><li>reduce worker遍历已排序的中间数据，对于遇到的每个唯一的中间键，它将键和相应的中间值集传递给用户的reduce函数。Reduce函数的输出被附加到这个Reduce分区的最终输出文件中。</li><li>当所有map任务和reduce任务完成后，主程序唤醒用户程序。此时，用户程序中的MapReduce调用返回到用户代码。</li></ol><p>​成功完成后，maprereduce执行的输出在R输出文件中可用(每个reduce任务一个，文件名由用户指定)。通常，用户不需要将这些R输出文件合并到一个文件中——他们经常将这些文件作为输入传递给另一个MapReduce调用，或者从另一个能够处理分区为多个文件的输入的分布式应用程序中使用它们。</p><h3 id="3-2-master数据结构"><a href="#3-2-master数据结构" class="headerlink" title="3.2 master数据结构"></a>3.2 master数据结构</h3><p>​master保留了几个数据结构。对于每个map任务和reduce任务，它存储状态(空闲、正在进行或已完成)以及工作机器的标识(对于非空闲任务)。</p><p>​主节点是将中间文件区域的位置从map任务传播到reduce任务的通道。因此，对于每一个完成的map任务，master存储由map任务产生的R个中间文件区域的位置和大小。当地图任务完成时，会收到对该位置和大小信息的更新。这些信息被逐步推送给正在执行减少任务的工作人员。</p><h3 id="3-3-容错性"><a href="#3-3-容错性" class="headerlink" title="3.3 容错性"></a>3.3 容错性</h3><p>​由于MapReduce库的设计目的是帮助处理使用数百或数千台机器的大量数据，因此库必须优雅地容忍机器故障。</p><h4 id="worker"><a href="#worker" class="headerlink" title="worker"></a>worker</h4><p>​主服务器定期ping每个worker。如果在一定时间内没有收到来自worker的响应，则主程序将该worker标记为失败。该worker完成的任何map任务都将被重置回其初始空闲状态，因此可以在其他worker上进行调度。类似地，在失败的worker上正在进行的任何map任务或reduce任务也被重置为空闲，并有资格重新调度。</p><p>​完成的映射任务在发生故障时重新执行，因为它们的输出存储在故障机器的本地磁盘上，因此无法访问。完成的reduce任务不需要重新执行，因为它们的输出存储在全局文件系统中。</p><p>​当一个映射任务首先由工人a执行，然后由工人B执行(因为a失败了)，所有的执行reduce任务的worker会收到重新执行的通知。任何尚未从worker A读取数据的reduce任务都将从worker B读取数据。</p><p>​MapReduce对大规模worker故障具有弹性。例如，在一次MapReduce操作期间，正在运行的集群上的网络维护导致80台机器组成的组在几分钟内无法访问。MapReduce主节点只是重新执行无法到达的工作机器所做的工作，并继续向前推进，最终完成MapReduce操作。</p><h4 id="master"><a href="#master" class="headerlink" title="master"></a>master</h4><p>​让主写入上述主数据结构的定期检查点是很容易的。如果主任务终止，则可以从最后一个检查点状态开始新的副本。然而，考虑到只有一个主人，它不太可能失败;因此，如果主节点失败，我们当前的实现会中止MapReduce的计算。客户端可以检查这种情况，如果需要的话，可以重试MapReduce操作。</p><h4 id="故障时的语义表现"><a href="#故障时的语义表现" class="headerlink" title="故障时的语义表现"></a>故障时的语义表现</h4><p>​当用户提供的map和reduce操作符是其输入值的确定性函数时，我们的分布式实现产生的输出与整个程序的非错误顺序执行所产生的输出相同。</p><p>​我们依靠map的原子提交和reduce任务输出来实现这个属性。每个正在进行的任务将其输出写入私有临时文件。一个reduce任务生成一个这样的文件，一个map任务生成R个这样的文件(每个reduce任务生成一个)。当map任务完成时，worker向master发送一条消息，并在消息中包含R临时文件的名称。如果主机接收到已经完成的映射任务的完成消息，则忽略该消息。否则，它将在主数据结构中记录R文件的名称。</p><p>​当reduce任务完成时，reduce worker自动将其临时输出文件重命名为最终输出文件。如果在多台机器上执行相同的reduce任务，则将对相同的最终输出文件执行多个重命名调用。我们依赖底层文件系统提供的原子重命名操作来保证最终文件系统状态只包含一次reduce任务执行所产生的数据。</p><p>​我们的绝大多数map和reduce操作符都是确定性的，在这种情况下，我们的语义等同于顺序执行，这使得程序员很容易推断他们的程序行为。当map和&#x2F;或reduce操作符不确定时，我们提供较弱但仍然合理的语义。在存在非确定性操作符的情况下，特定reduce任务R1的输出相当于非确定性程序的顺序执行对R1产生的输出。然而，不同的reduce任务R2的输出可能对应于不确定性程序的不同顺序执行所产生的R2的输出。</p><p>​考虑map任务M和reduce任务R1和R2。设e(Ri)为所提交的Ri的执行(只有一次这样的执行)较弱的语义出现是因为e(R1)可能读取了一次M执行产生的输出，而e(R2)可能读取了另一次M执行产生的输出。</p><h3 id="3-4-Locality"><a href="#3-4-Locality" class="headerlink" title="3.4 Locality"></a>3.4 Locality</h3><p>​网络带宽在我们的计算环境中是一种相对稀缺的资源。我们利用输入数据(由GFS管理)存储在组成集群的机器的本地磁盘这一事实来节省网络带宽。GFS将每个文件划分为64 MB的块，并在不同的机器上存储每个块的几个副本(通常是3个副本)。MapReduce主程序将输入文件的位置信息考虑在内，并尝试在包含相应输入数据副本的机器上调度地图任务。如果失败，它会尝试在该任务输入数据的副本附近调度一个map任务(例如，在与包含数据的机器位于同一网络交换机上的工作机器上)。当在集群中相当一部分worker上运行大型MapReduce操作时，大多数输入数据都是在本地读取的，不消耗网络带宽。</p><h3 id="3-5-任务粒度"><a href="#3-5-任务粒度" class="headerlink" title="3.5 任务粒度"></a>3.5 任务粒度</h3><p>​我们将map阶段细分为M个片段，reduce阶段细分为R个片段，如上所述。理想情况下，M和R应该比工作机器的数量大得多。让每个worker执行许多不同的任务可以改善动态负载平衡，并且还可以在一个worker失败时加快恢复速度:它完成的许多map任务可以分散到所有其他worker机器上。</p><p>​在我们的实现中，M和R的大小是有实际限制的，因为主机必须做出O(M + R)个调度决策，并如上所述在内存中保持O(M * R)个状态。(然而，内存使用的恒定因素很小:状态的O(M * R)块由每个map任务&#x2F;reduce任务对大约一个字节的数据组成。)</p><p>​此外，R经常受到用户的约束，因为每个reduce任务的输出最终都在一个单独的输出文件中。在实践中，我们倾向于选择M，这样每个单独的任务大约有16 MB到64 MB的输入数据(这样上面描述的局部性优化是最有效的)，我们让R是我们期望使用的工作机器数量的一个小倍数。我们经常使用2000台工作机器，在M &#x3D; 200000和R &#x3D; 5000的情况下执行MapReduce计算。</p><h3 id="3-6-备份任务"><a href="#3-6-备份任务" class="headerlink" title="3.6 备份任务"></a>3.6 备份任务</h3><p>​导致MapReduce操作总时间延长的常见原因之一是“掉队者”:在计算过程中，一台机器花了很长时间才完成最后几个map或reduce任务中的一个。掉队者的出现有很多原因。例如，具有坏磁盘的机器可能会遇到频繁的可纠正错误，从而使其读取性能从30 MB&#x2F;s降低到1 MB&#x2F;s。集群调度系统可能已经调度了机器上的其他任务，由于CPU、内存、本地磁盘或网络带宽的竞争，导致它执行MapReduce代码的速度更慢。我们最近遇到的一个问题是机器初始化代码中的一个错误，它导致处理器缓存被禁用:受影响的机器上的计算速度减慢了一百多倍。</p><p>​我们有一个通用的机制来缓解掉队者的问题。当一个MapReduce操作接近完成时，master调度剩余正在执行的任务执行备份。每当主执行或备份执行完成时，任务就被标记为已完成。我们已经对这种机制进行了调优，使它通常只增加操作所使用的计算资源几个百分点。我们发现这大大减少了完成大型MapReduce操作的时间。例如，当备份任务机制被禁用时，5.3节中描述的排序程序要多花44%的时间来完成。</p><h2 id="4-改进"><a href="#4-改进" class="headerlink" title="4 改进"></a>4 改进</h2><p>​虽然简单编写Map和Reduce函数提供的基本功能足以满足大多数需求，但我们发现一些扩展很有用。本节将介绍这些特性。</p><h3 id="4-1-分区函数"><a href="#4-1-分区函数" class="headerlink" title="4.1 分区函数"></a>4.1 分区函数</h3><p>​MapReduce的用户可以指定他们想要的reduce任务&#x2F;输出文件数量(R)。使用中间键上的分区函数在这些任务之间对数据进行分区。提供了一个默认使用哈希函数进行分区(例如“hash(key) mod R”)，通常会产生相当均衡的分区结果。然而，在某些情况下，根据键值的其他函数对数据进行分区是有用的。例如，当输出键为url时，我们希望将同一主机上所有条目都放置在同一个输出文件中。为了支持这种情况，MapReduce库允许用户提供特殊的分区函数。例如，使用“hash(Hostname(urlkey)) mod R”作为分区函数将导致来自同一主机的所有url最终出现在相同的输出文件中。</p><h3 id="4-2-排序保证"><a href="#4-2-排序保证" class="headerlink" title="4.2 排序保证"></a>4.2 排序保证</h3><p>​保证在给定分区内，中间键&#x2F;值对按键或递增顺序处理。这种排序保证可以很容易地为每个分区生成排序的输出文件，当输出文件格式需要支持有效的按键随机访问查找时，或者输出的用户发现对数据进行排序很方便时，这是很有用的。</p><h3 id="4-3-Combiner"><a href="#4-3-Combiner" class="headerlink" title="4.3 Combiner"></a>4.3 Combiner</h3><p>​在某些情况下，每个map任务产生的中间键存在显著的重复，并且用户指定的Reduce函数是可交换的和关联的。第2.1节中的单词计数就是一个很好的例子。由于词频倾向于遵循Zipf分布，每个地图任务将产生成百上千条形式为&lt;the, 1&gt;的记录。所有这些计数将通过网络发送到一个Reduce任务，然后由Reduce函数将它们加在一起生成一个数字。我们允许用户指定一个可选的Combiner函数，该函数在数据通过网络发送之前对其进行部分合并。</p><p>​Combiner函数在每台执行映射任务的机器上执行。通常使用相同的代码来实现combiner和reduce函数。reduce函数和组合函数之间的唯一区别是MapReduce库如何处理函数的输出。reduce函数的输出被写入最终的输出文件。组合函数的输出被写入中间文件，该中间文件将被发送给reduce任务。</p><p>​部分组合显著加快了某些类型的MapReduce操作。附录A包含一个使用组合器的示例。</p><h3 id="4-4-输入和输出类型"><a href="#4-4-输入和输出类型" class="headerlink" title="4.4 输入和输出类型"></a>4.4 输入和输出类型</h3><p>​MapReduce库支持以几种不同的格式读取输入数据。比如，“text”模式输入将每行视为一个键&#x2F;值对:键是文件中的偏移量，值是该行的内容。另一种常见的支持格式存储按键排序的键&#x2F;值对序列。每个输入类型实现都知道如何将自己分割成有意义的范围，以便作为单独的map任务进行处理(例如，文本模式的范围分割确保范围分割仅在行边界发生)。用户可以通过提供简单阅读器界面的实现来添加对新输入类型的支持，尽管大多数用户只使用少数预定义输入类型中的一种。</p><p>​读取器不一定需要提供从文件读取的数据。例如，很容易定义从数据库或从内存中映射的数据结构中读取记录的读取器。</p><p>​以类似的方式，我们支持一组输出类型来生成不同格式的数据，并且用户代码很容易添加对新输出类型的支持。</p><h3 id="4-5-副作用"><a href="#4-5-副作用" class="headerlink" title="4.5 副作用"></a>4.5 副作用</h3><p>​在某些情况下，MapReduce的用户发现从他们的map和&#x2F;或reduce操作符生成辅助文件作为附加输出是很方便的。我们依靠应用程序编写器使这些副作用原子化和幂等化。通常，应用程序写入临时文件，并在完全生成该文件后自动重命名该文件。</p><p>​我们不支持单个任务生成的多个输出文件的原子两阶段提交。因此，产生具有跨文件一致性要求的多个输出文件的任务应该是确定性的。这种限制在实践中从来没有成为问题。</p><h3 id="4-6-跳过坏记录"><a href="#4-6-跳过坏记录" class="headerlink" title="4.6 跳过坏记录"></a>4.6 跳过坏记录</h3><p>​有时，用户代码中的错误会导致Map或Reduce函数在某些记录上崩溃。这样的bug会导致MapReduce操作无法完成。通常的做法是修复漏洞，但有时这是不可行的;也许这个bug是在一个第三方库中，源代码是不可用的。此外，有时忽略一些记录也是可以接受的，例如在对大型数据集进行统计分析时。我们提供了一种可选的执行模式，其中MapReduce库检测哪些记录导致确定性崩溃，并跳过这些记录，以便向前推进。</p><p>​每个工作进程安装一个信号处理程序，用于捕获分段违反和总线错误。在调用用户Map或Reduce操作之前，mapreduce库将参数的序列号存储在一个全局变量中。如果用户代码生成一个信号，信号处理程序发送一个包含序列号的“最后喘息”UDP数据包到MapReduce主服务器。当主服务器在一个特定的记录上看到多个失败时，它表明在下一次重新执行相应的Map或Reduce任务时应该跳过该记录。</p><h3 id="4-7-本地执行"><a href="#4-7-本地执行" class="headerlink" title="4.7 本地执行"></a>4.7 本地执行</h3><p>​Map或Reduce函数中的调试问题可能很棘手，因为实际的计算发生在分布式系统中，通常在数千台机器上，工作分配决策是由主机动态做出的。为了方便调试、分析和小规模测试，我们开发了MapReduce库的另一种实现，它在本地机器上顺序地执行MapReduce操作的所有工作。控件提供给用户，这样计算就可以限制在特定的地图任务上。用户用一个特殊的标志来调用他们的程序，然后可以很容易地使用他们认为有用的任何调试或测试工具(例如gdb)。</p><h3 id="4-8-状态信息"><a href="#4-8-状态信息" class="headerlink" title="4.8 状态信息"></a>4.8 状态信息</h3><p>​主服务器运行一个内部HTTP服务器，并导出一组状态页供人们使用。状态页显示计算的进度，例如已经完成了多少个任务、正在进行多少个任务、输入字节数、中间数据字节数、输出字节数、处理速率等。这些页面还包含到每个任务生成的标准错误和标准输出文件的链接。用户可以使用这些数据来预测计算需要多长时间，以及是否应该在计算中添加更多的资源。这些页面还可用于确定何时计算比预期慢得多。</p><p>​此外，顶级状态页显示哪些工人失败了，以及他们失败时正在处理哪些映射和减少任务。当试图诊断用户代码中的错误时，此信息非常有用。</p><h3 id="4-9-Counters"><a href="#4-9-Counters" class="headerlink" title="4.9 Counters"></a>4.9 Counters</h3><p>​MapReduce库提供了一个计数器工具来计算各种事件的发生次数。例如，用户代码可能想要计算处理的单词总数或索引的德语文档的数量等。</p><p>​要使用此功能，用户代码创建一个命名计数器对象，然后在Map和&#x2F;或Reduce函数中适当地增加计数器。例如:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs Python">Counter* uppercase; <br>uppercase = GetCounter(<span class="hljs-string">&quot;uppercase&quot;</span>); <br><span class="hljs-built_in">map</span>(String name, String contents): <br><span class="hljs-keyword">for</span> each word w <span class="hljs-keyword">in</span> contents: <br><span class="hljs-keyword">if</span> (IsCapitalized(w)): <br>uppercase-&gt;Increment(); <br>EmitIntermediate(w, <span class="hljs-string">&quot;1&quot;</span>);<br></code></pre></td></tr></table></figure><p>​来自各个工作机器的计数器值定期传播到主机器(在ping响应的基础上)。master从成功的map和reduce任务中聚合计数器值，并在MapReduce操作完成时返回给用户代码。当前计数器的值也显示在主状态页面上，以便人们可以观看实时计算的进度。在聚合计数器值时，主服务器消除了重复执行相同映射或reduce任务的影响，以避免重复计数。(重复执行可能来自我们使用备份任务和由于失败而重新执行任务。</p><p>)</p><p>​一些计数器值由MapReduce库自动维护，例如处理的输入键&#x2F;值对的数量和产生的输出键&#x2F;值对的数量。</p><p>​用户发现计数器功能对于安全检查MapReduce操作的行为很有用。例如，在一些MapReduce操作中，用户代码可能希望确保生成的输出对的数量恰好等于处理的输入对的数量，或者处理的德语文档的比例在处理的文档总数的某个可容忍的比例之内。</p><h2 id="5-Performance"><a href="#5-Performance" class="headerlink" title="5 Performance"></a>5 Performance</h2><p>主要是一些性能的测试，就分析图片吧</p><p>集群配置：所有的程序都在一个由大约1800台机器组成的集群上执行。每台机器都有两个2GHz英特尔至强处理器，支持超线程，4GB内存，两个160GB IDE磁盘和千兆以太网链路。这些机器被安排在一个两级树状交换网络中，根节点的总带宽约为100- 200gbps。所有的机器都在同一个托管设施中，因此任何一对机器之间的往返时间都小于1毫秒。在4GB内存中，大约有1-1.5GB是由集群上运行的其他任务保留的。这些程序是在一个周末的下午执行的，当时cpu、磁盘和网络大多处于空闲状态。</p><p><img src="/../imgs/mapreduce/image-20240314175218619.png" alt="图2:随时间变化的数据传输速率"></p><p>图2显示了计算随时间的进展。y轴表示扫描输入数据的速率。当更多的机器被分配到这个MapReduce计算时，速率逐渐回升，当分配了1764个worker时，速率超过30GB&#x2F;s。当地图任务完成时，速率开始下降，并在计算后80秒左右达到零。整个计算从开始到结束大约需要150秒。这包括大约一分钟的启动开销。开销是由于将程序传播到所有工作机器，以及延迟与GFS交互以打开1000个输入文件集并获得局部性优化所需的信息。</p><p><img src="/../imgs/mapreduce/image-20240314175700641.png" alt="图3:排序程序的不同执行随时间变化的数据传输速率"></p><p>图3 (a)显示了排序程序正常执行的进度。左上角的图表显示了读取输入的速率。速率峰值约为13gb &#x2F;s，并且很快就会消失，因为所有的map任务在200秒内就完成了。注意，输入速率小于grep。这是因为排序映射任务花费大约一半的时间和I&#x2F;O带宽将中间输出写入本地磁盘。grep对应的中间输出的大小可以忽略不计。</p><p>左中图显示了数据通过网络从map任务发送到reduce任务的速率。当第一个map任务完成时，shuffle就开始了。图中的第一个驼峰是第一批大约1700个reduce任务(整个MapReduce被分配了大约1700台机器，每台机器一次最多执行一个reduce任务)。在大约300秒的计算中，第一批reduce任务中的一些完成了，我们开始为剩余的reduce任务转移数据。所有的洗牌在计算后大约600秒完成</p><p>左下角的图表显示了reduce任务将排序后的数据写入最终输出文件的速率。在第一个洗牌周期的结束和写入周期的开始之间有一个延迟，因为机器忙于对中间数据进行排序。继续以大约2-4 GB&#x2F;s的速率写一段时间。所有的写操作在计算完成后大约850秒完成。包括启动开销在内，整个计算耗时891秒。这与目前TeraSort基准测试1057秒的最佳报告结果相似。</p><p>在图3 (b)中，我们展示了禁用备份任务的排序程序的执行。执行流与图3 (a)中所示的类似，除了有一个非常长的尾，几乎没有任何写活动发生。960秒后，除5个reduce任务外，其余的reduce任务都完成了。然而，这些最后几名落伍者直到300秒后才完成比赛。整个计算耗时1283秒，运行时间增加了44%。</p><p>在图3 (c)中，我们展示了排序程序的执行，在计算开始几分钟后，我们故意杀死了1746个工作进程中的200个。底层集群调度器立即重新启动这些机器上的新工作进程(因为只有进程被终止，机器仍然正常运行)。</p><h2 id="6-相关工作"><a href="#6-相关工作" class="headerlink" title="6 相关工作"></a>6 相关工作</h2><p>​许多系统提供了受限的编程模型，并利用这些约束自动并行化计算。例如，可以在N个处理器上使用并行前缀计算，在log N时间内对N个元素数组的所有前缀计算一个关联函数。MapReduce可以被认为是基于我们在现实世界中大量计算的经验对这些模型的简化和提炼。更重要的是，我们提供了可扩展到数千个处理器的容错实现。相比之下，大多数并行处理系统只在较小的规模上实现，并将处理机器故障的细节留给程序员。</p><p>​批量同步编程和一些MPI原语提供了更高级的抽象，使程序员更容易编写并行程序。这些系统和MapReduce之间的一个关键区别是，MapReduce利用一个受限的编程模型来自动并行化用户程序，并提供透明的容错。</p><p>​我们的局部性优化从活动磁盘等技术中获得灵感，其中计算被推进到靠近本地磁盘的处理元素中，以减少通过I&#x2F;O子系统或网络发送的数据量。我们在直接连接少量磁盘的普通处理器上运行，而不是直接在磁盘控制器处理器上运行，但一般方法是相似的。</p><p>​我们的备份任务机制类似于夏洛特系统中采用的急切调度机制。简单的渴望调度的缺点之一是，如果一个给定的任务导致重复的失败，整个计算无法完成。我们用跳过坏记录的机制修复了这个问题的一些实例。</p><p>​MapReduce的实现依赖于内部集群管理系统，该系统负责在大量共享机器上分发和运行用户任务。集群管理系统虽然不是本文的重点，但在精神上与Condor等其他系统相似。</p><p>​排序工具是MapReduce库的一部分，在操作上类似于NOW-Sort。源机器(map worker)对要排序的数据进行分区，并将其发送给R个reduce worker中的一个。每个reduce worker在本地(如果可能的话，在内存中)对其数据进行排序。当然NOW-Sort没有用户自定义的Map和Reduce函数，而这些函数使我们的库具有广泛的适用性。</p><p>​River提供了一种编程模型，其中进程通过在分布式队列上发送数据来相互通信。与MapReduce一样，River系统即使在异构硬件或系统扰动引入的不均匀性存在的情况下，也试图提供良好的平均情况性能。River通过仔细地调度磁盘和网络传输来实现这一点，以实现平衡的完成时间。mapreduce采用了不同的方法。通过限制编程模型，MapReduce框架能够将问题划分为大量细粒度任务。这些任务在可用的worker上动态调度，以便更快的worker处理更多的任务。受限制的编程模型还允许我们在作业结束时安排任务的冗余执行，这大大减少了存在不一致性(例如缓慢或卡住的工人)的完成时间。</p><p>​BAD-FS有一个与MapReduce非常不同的编程模型，而且与MapReduce不同的是，它的目标是在广域网上执行工作。然而，有两个基本的相似之处。(1)两个系统都使用冗余执行来恢复故障造成的数据丢失。(2)两个系统都使用位置感知调度来减少在拥挤的网络链路上发送的数据量。</p><p>​TACC是一种简化高可用性网络业务构建的系统。与MapReduce一样，它依赖于重新执行作为实现容错的机制。</p><h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7 总结"></a>7 总结</h2><p>​MapReduce编程模型已经在Google成功地用于许多不同的目的。我们把这一成功归因于几个原因。首先，该模型易于使用，即使对于没有并行和分布式系统经验的程序员也是如此，因为它隐藏了并行化、容错、局部优化和负载平衡的细节。其次，大量的问题很容易表达为MapReduce计算。例如，MapReduce用于为Google的生产网络搜索服务生成数据，用于排序、数据挖掘、机器学习和许多其他系统。第三，我们已经开发了一个MapReduce的实现，它可以扩展到由数千台机器组成的大型机器集群。该实现有效地利用了这些机器资源，因此适合用于Google遇到的许多大型计算问题。</p><p>​我们从这项工作中学到了一些东西。首先，限制编程模型使其易于并行化和分布计算，并使此类计算具有容错性。第二，网络带宽是一种稀缺资源。因此，我们系统中的许多优化都以减少通过网络发送的数据量为目标:局域优化允许我们从本地磁盘读取数据，并将中间数据的单个副本写入本地磁盘以节省网络带宽。第三，冗余执行可用于减少慢机的影响，并处理机器故障和数据丢失</p><h2 id="A-Word-Frequency"><a href="#A-Word-Frequency" class="headerlink" title="A Word Frequency"></a>A Word Frequency</h2><p>本节包含一个程序，该程序计算在命令行指定的一组输入文件中每个唯一单词的出现次数。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;mapreduce/mapreduce.h&quot;</span> </span><br><span class="hljs-comment">// User’s map function </span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">WordCounter</span> : <span class="hljs-keyword">public</span> Mapper &#123; <br><span class="hljs-keyword">public</span>: <br><span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">Map</span><span class="hljs-params">(<span class="hljs-type">const</span> MapInput&amp; input)</span> </span>&#123; <br><span class="hljs-type">const</span> string&amp; text = input.<span class="hljs-built_in">value</span>(); <br><span class="hljs-type">const</span> <span class="hljs-type">int</span> n = text.<span class="hljs-built_in">size</span>(); <br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; ) &#123; <br><span class="hljs-comment">// Skip past leading whitespace </span><br><span class="hljs-keyword">while</span> ((i &lt; n) &amp;&amp; <span class="hljs-built_in">isspace</span>(text[i])) <br>i++; <br>                <span class="hljs-comment">// Find word end </span><br>                <span class="hljs-type">int</span> start = i; <br>                <span class="hljs-keyword">while</span> ((i &lt; n) &amp;&amp; !<span class="hljs-built_in">isspace</span>(text[i])) <br>                i++; <br>                <span class="hljs-keyword">if</span> (start &lt; i) <br>                <span class="hljs-built_in">Emit</span>(text.<span class="hljs-built_in">substr</span>(start,i-start),<span class="hljs-string">&quot;1&quot;</span>); <br>&#125; <br>&#125; <br>&#125;; <br><span class="hljs-built_in">REGISTER_MAPPER</span>(WordCounter); <br><span class="hljs-comment">// User’s reduce function </span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Adder</span> : <span class="hljs-keyword">public</span> Reducer &#123; <br><span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">Reduce</span><span class="hljs-params">(ReduceInput* input)</span> </span>&#123; <br><span class="hljs-comment">// Iterate over all entries with the </span><br><span class="hljs-comment">// same key and add the values </span><br>int64 value = <span class="hljs-number">0</span>; <br><span class="hljs-keyword">while</span> (!input-&gt;<span class="hljs-built_in">done</span>()) &#123; <br>value += <span class="hljs-built_in">StringToInt</span>(input-&gt;<span class="hljs-built_in">value</span>()); <br>input-&gt;<span class="hljs-built_in">NextValue</span>(); <br>&#125; <br><br><span class="hljs-comment">// Emit sum for input-&gt;key() </span><br><span class="hljs-built_in">Emit</span>(<span class="hljs-built_in">IntToString</span>(value)); <br>&#125; <br>&#125;; <br><span class="hljs-built_in">REGISTER_REDUCER</span>(Adder); <br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-type">int</span> argc, <span class="hljs-type">char</span>** argv)</span> </span>&#123; <br><span class="hljs-built_in">ParseCommandLineFlags</span>(argc, argv); <br><br>MapReduceSpecification spec; <br><span class="hljs-comment">// Store list of input files into &quot;spec&quot; </span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt; argc; i++) &#123; <br>MapReduceInput* input = spec.<span class="hljs-built_in">add_input</span>(); <br>input-&gt;<span class="hljs-built_in">set_format</span>(<span class="hljs-string">&quot;text&quot;</span>); <br>input-&gt;<span class="hljs-built_in">set_filepattern</span>(argv[i]); <br>input-&gt;<span class="hljs-built_in">set_mapper_class</span>(<span class="hljs-string">&quot;WordCounter&quot;</span>); <br>&#125; <br><span class="hljs-comment">// Specify the output files: </span><br><span class="hljs-comment">///gfs/test/freq-00000-of-00100 </span><br><span class="hljs-comment">///gfs/test/freq-00001-of-00100 </span><br><span class="hljs-comment">//... </span><br>MapReduceOutput* out = spec.<span class="hljs-built_in">output</span>(); <br>out-&gt;<span class="hljs-built_in">set_filebase</span>(<span class="hljs-string">&quot;/gfs/test/freq&quot;</span>); <br>out-&gt;<span class="hljs-built_in">set_num_tasks</span>(<span class="hljs-number">100</span>); <br>out-&gt;<span class="hljs-built_in">set_format</span>(<span class="hljs-string">&quot;text&quot;</span>); <br>out-&gt;<span class="hljs-built_in">set_reducer_class</span>(<span class="hljs-string">&quot;Adder&quot;</span>); <br><br><span class="hljs-comment">// Optional: do partial sums within map </span><br><span class="hljs-comment">// tasks to save network bandwidth </span><br>out-&gt;<span class="hljs-built_in">set_combiner_class</span>(<span class="hljs-string">&quot;Adder&quot;</span>); <br><br><span class="hljs-comment">// Tuning parameters: use at most 2000 </span><br><span class="hljs-comment">// machines and 100 MB of memory per task </span><br>spec.<span class="hljs-built_in">set_machines</span>(<span class="hljs-number">2000</span>); <br>spec.<span class="hljs-built_in">set_map_megabytes</span>(<span class="hljs-number">100</span>); <br>spec.<span class="hljs-built_in">set_reduce_megabytes</span>(<span class="hljs-number">100</span>); <br><span class="hljs-comment">// Now run it MapReduceResult result; </span><br><span class="hljs-keyword">if</span> (!<span class="hljs-built_in">MapReduce</span>(spec, &amp;result)) <span class="hljs-built_in">abort</span>(); <br><span class="hljs-comment">// Done: ’result’ structure contains info </span><br><span class="hljs-comment">// about counters, time taken, number of </span><br><span class="hljs-comment">// machines used, etc. </span><br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>; <br>&#125; <br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>mit6.824</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式系统</tag>
      
      <tag>mit6.824</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>14th-March</title>
    <link href="/2024/03/14/14th-March/"/>
    <url>/2024/03/14/14th-March/</url>
    
    <content type="html"><![CDATA[<h1 id="To-do-List"><a href="#To-do-List" class="headerlink" title="To-do List"></a>To-do List</h1><ul><li><p><input checked="" disabled="" type="checkbox"> 算法</p><ul><li><input checked="" disabled="" type="checkbox"> 链表和分治</li></ul></li><li><p><input disabled="" type="checkbox"> 项目</p><ul><li><input checked="" disabled="" type="checkbox"> cmu15445</li><li><input disabled="" type="checkbox"> mit6.824</li><li><input disabled="" type="checkbox"> mit6.081</li></ul></li><li><p><input disabled="" type="checkbox"> 八股</p><ul><li><input checked="" disabled="" type="checkbox"> 操作系统</li><li><input checked="" disabled="" type="checkbox"> 计算机网络</li><li><input disabled="" type="checkbox"> 数据库</li><li><input disabled="" type="checkbox"> redis</li></ul></li><li><p><input checked="" disabled="" type="checkbox"> 日常总结</p></li></ul><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p>今天主要是分治和链表的操作的结合，虽然没有什么很难的知识点，但却是是难了很多</p><h4 id="1-排序链表"><a href="#1-排序链表" class="headerlink" title="1.排序链表"></a>1.<a href="https://leetcode.cn/problems/sort-list/description/?envType=study-plan-v2&envId=top-interview-150">排序链表</a></h4><p>题面：</p><p><img src="/../imgs/14th-March/image-20240314203533498.png" alt="lc排序链表"></p><p>题解：</p><p>​还记得合并两个有序链表，，，所以可以找到链表的中点，将链表拆成两个子链表<font color=red>(!快慢指针找中点)</font>,然后对两个子链表分别排序，最后再合并</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">//分治</span><br><span class="hljs-function">ListNode* <span class="hljs-title">sortList</span><span class="hljs-params">(ListNode* head, ListNode* tail)</span> </span>&#123;<br>       <span class="hljs-keyword">if</span> (head == <span class="hljs-literal">nullptr</span>) &#123;<br>           <span class="hljs-keyword">return</span> head;<br>       &#125;<br>       <span class="hljs-keyword">if</span> (head-&gt;next == tail) &#123;<br>           head-&gt;next = <span class="hljs-literal">nullptr</span>;<br>           <span class="hljs-keyword">return</span> head;<br>       &#125;<br>       ListNode* slow = head, *fast = head;<br>       <span class="hljs-keyword">while</span> (fast != tail) &#123;<br>           slow = slow-&gt;next;<br>           fast = fast-&gt;next;<br>           <span class="hljs-keyword">if</span> (fast != tail) &#123;<br>               fast = fast-&gt;next;<br>           &#125;<br>       &#125;<br>       ListNode* mid = slow;<br>       <span class="hljs-keyword">return</span> <span class="hljs-built_in">merge</span>(<span class="hljs-built_in">sortList</span>(head, mid), <span class="hljs-built_in">sortList</span>(mid, tail));<br>   &#125;<br>   <span class="hljs-comment">//合并两个有序链表</span><br>   <span class="hljs-function">ListNode* <span class="hljs-title">merge</span><span class="hljs-params">(ListNode* head1, ListNode* head2)</span> </span>&#123;<br>       ListNode* dummyHead = <span class="hljs-keyword">new</span> <span class="hljs-built_in">ListNode</span>(<span class="hljs-number">0</span>);<br>       ListNode* temp = dummyHead, *temp1 = head1, *temp2 = head2;<br>       <span class="hljs-keyword">while</span> (temp1 != <span class="hljs-literal">nullptr</span> &amp;&amp; temp2 != <span class="hljs-literal">nullptr</span>) &#123;<br>           <span class="hljs-keyword">if</span> (temp1-&gt;val &lt;= temp2-&gt;val) &#123;<br>               temp-&gt;next = temp1;<br>               temp1 = temp1-&gt;next;<br>           &#125; <span class="hljs-keyword">else</span> &#123;<br>               temp-&gt;next = temp2;<br>               temp2 = temp2-&gt;next;<br>           &#125;<br>           temp = temp-&gt;next;<br>       &#125;<br>       <span class="hljs-keyword">if</span> (temp1 != <span class="hljs-literal">nullptr</span>) &#123;<br>           temp-&gt;next = temp1;<br>       &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (temp2 != <span class="hljs-literal">nullptr</span>) &#123;<br>           temp-&gt;next = temp2;<br>       &#125;<br>       <span class="hljs-keyword">return</span> dummyHead-&gt;next;<br>   &#125;<br></code></pre></td></tr></table></figure><h4 id="2-环形子数组的最大和"><a href="#2-环形子数组的最大和" class="headerlink" title="2.环形子数组的最大和"></a>2.<a href="https://leetcode.cn/problems/maximum-sum-circular-subarray/solutions/2350660/huan-xing-zi-shu-zu-de-zui-da-he-by-leet-elou/?envType=study-plan-v2&envId=top-interview-150">环形子数组的最大和</a></h4><p><img src="/../imgs/14th-March/image-20240314205127381.png" alt="环形子数组的最大和"></p><p>题解：</p><p>​。。。明明说有什么<strong>Kadane</strong>算法，但是确实一点都没看到 还是普通的滑窗感觉（抄的官解，懒得写了主要是）</p><p>​</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">maxSubarraySumCircular</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = nums.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">leftMax</span><span class="hljs-params">(n)</span></span>;<br>        leftMax[<span class="hljs-number">0</span>] = nums[<span class="hljs-number">0</span>];<br>        <span class="hljs-type">int</span> leftSum = nums[<span class="hljs-number">0</span>];<br>        <span class="hljs-type">int</span> pre = nums[<span class="hljs-number">0</span>];<br>        <span class="hljs-type">int</span> res = nums[<span class="hljs-number">0</span>];<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt; n; i++) &#123;<br>            pre = <span class="hljs-built_in">max</span>(pre + nums[i], nums[i]);<br>            res = <span class="hljs-built_in">max</span>(res, pre);<br>            leftSum += nums[i];<br>            leftMax[i] = <span class="hljs-built_in">max</span>(leftMax[i - <span class="hljs-number">1</span>], leftSum);<br>        &#125;<br><br>        <span class="hljs-type">int</span> rightSum = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = n - <span class="hljs-number">1</span>; i &gt; <span class="hljs-number">0</span>; i--) &#123;<br>            rightSum += nums[i];<br>            res = <span class="hljs-built_in">max</span>(res, rightSum + leftMax[i - <span class="hljs-number">1</span>]);<br>        &#125;<br>        <span class="hljs-keyword">return</span> res;<br>    &#125;<br></code></pre></td></tr></table></figure><h2 id="项目"><a href="#项目" class="headerlink" title="项目"></a>项目</h2><p>今天主要是过了一边mapreduce，花了一下午。。。</p><p>中午主要把445的p3 task1解决了</p><p>seqscan insert delete indexscan</p><h2 id="八股"><a href="#八股" class="headerlink" title="八股"></a>八股</h2><h3 id="计算机网络"><a href="#计算机网络" class="headerlink" title="计算机网络"></a>计算机网络</h3><p><strong>DNS解析过程</strong></p><ol><li>先查询浏览器缓存是否有该域名对应的IP地址。</li><li>如果浏览器缓存中没有，会去计算机本地的Host文件中查询是否有对应的缓存。</li><li>如果Host文件中也没有则会向<strong>本地的DNS服务器</strong>发起一个DNS查询请求。</li><li>如果本地DNS解析器有该域名的IP地址，就会直接返回，进入过没有缓存该域名的解析记录，它会向<strong>根DNS服务器</strong>发出查询请求。根DNS服务器并不负责解析域名，但它能告诉本地DNS解析器应该向哪个顶级域名的DNS服务器继续查询。</li><li>本地DNS解析器接着向指定的<strong>顶级域名DNS服务器</strong>发出查询请求。权威DNS服务器是负责存储特定域名和IP地址映射的服务器。当权威DNS服务器收到查询请求时，它会查找”example.com“域名对应的IP地址，并将结果返回给本地DNS解析器。</li><li>本地DNS解析器将收到的IP地址返回给浏览器，并且还会将域名解析结果缓存在本地，以便下次访问时更快地相应。</li><li>浏览器发起连接：本地DNS解析器已经将IP地址返回给您的计算机，您的浏览器可以使用该IP地址与目标服务器建立连接，开始获取网页内容。</li></ol><p><img src="/../imgs/14th-March/image-20240314211600938.png" alt="DNS解析过程（1）"></p><p><img src="/../imgs/14th-March/image-20240314211634503.png" alt="DNS解析过程（2）"></p><p><img src="/../imgs/14th-March/image-20240314211744604.png" alt="DNS解析过程（3）"></p><h4 id="递归查询和迭代查询"><a href="#递归查询和迭代查询" class="headerlink" title="递归查询和迭代查询"></a>递归查询和迭代查询</h4><p>（1）递归查询</p><p>在递归查询中，DNS客户端向上层DNS服务器发起查询请求，并要求这些服务器直接提供完整的解析结果。递归查询的特点是，DNS客户端只需要发送一个查询请求，然后等待完整的解析结果。上层DNS服务器会自行查询下一级的服务器，并将最终结果返回给DNS客户端。</p><p>（2）迭代查询</p><p>在迭代查询中，DNS客户端向上层DNS服务器发起查询请求，但不要求直接提供完整的解析结果。相反，DNS客户端只是询问上层服务器⼀个更⾼级的域名服务器的地址，然后再⾃⾏向那个更⾼级的服务器发起查询请求，以此类推，直到获取完整的解析结果为⽌。</p><p>递归查询适合普通⽤户和客户端，⽽迭代查询适⽤于DNS服务器之间的通信。</p><h3 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h3><h4 id="调度算法"><a href="#调度算法" class="headerlink" title="调度算法"></a>调度算法</h4><p><img src="/../imgs/14th-March/image-20240314212242097.png" alt="调度算法总结"></p><p>（1）先来先服务（<strong>FCFS</strong>）</p><p>每次从就绪队列选择最先进入队列的进程，然后一直运行，知道进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。</p><p>这种算法虽然看上去公平，但是如果有一个长作业需要处理，后面的短作业需要处理很长时间。</p><p>先来先服务的特点是算法简单，对长作业比较有利，对短作业不利，适用于CPU繁忙型的系统，而不适用于I&#x2F;O繁忙型作业的系统。</p><p><img src="/../imgs/14th-March/image-20240314212552297.png" alt="FCFS"></p><p>（2）最短作业优先（SJF）</p><p>最短作业优先调度算法从就绪队列中选择一个估计运行时间最短的作业，将之调入到内存中运行，这有利于提高系统的吞吐量。</p><p>但是这对长作业十分不利，由于调度程序总是优先调度短作业，将会导致长作业长期不被调度，此外该算法也没有考虑到作业的紧迫程度，因此不能保证紧迫性作业会被及时处理。</p><p><img src="/../imgs/14th-March/image-20240314212803783.png" alt="SJF"></p><p>（3）高响应比优先调度算法</p><p>每次进行进程调度时，先计算<strong>响应比优先级</strong>，然后把<strong>响应比优先级</strong>最高的进程投入运行<br>$$<br>\text{优先权} &#x3D; \frac{\text{等待时间} + \text{要求服务时间}}{\text{要求服务时间}}<br>$$<br>根据公式可以知道</p><ul><li>作业的等待时间相同时，如果要求服务时间越短，则响应比更高，有利于短作业执行</li><li>当要求服务时间相同时，响应比由等待时间决定，如果等待时间越长，则响应比越高</li><li>对于长作业，作业的响应比可以随着等待时间的增加而提高</li></ul><p>（4）时间片轮转调度算法</p><p>每个进程被分配⼀个时间段，称为时间⽚（<strong>Quantum</strong>），即允许该进程在该时间段中运⾏。</p><ul><li>如果时间⽚⽤完，进程还在运⾏，那么将会把此进程从 CPU 释放出来，并把 CPU 分配给另外⼀个进程；</li><li>如果该进程在时间⽚结束前阻塞或结束，则 CPU立即进⾏切换；</li></ul><p>另外，时间⽚的⻓度就是⼀个很关键的点：</p><ul><li>如果时间片设的太短会导致过多的进程上下文切换，降低了CPU效率；</li><li>如果设的太长又可能引起对短作业进程的响应时间变长。</li></ul><p>一般来说，时间片设为20~50ms通常是一个比较合理的折中值。</p><p><img src="/../imgs/14th-March/image-20240314213700722.png" alt="时间片轮转"></p><p>（5）最高优先级调度算法</p><p>从就绪队列中选择最高优先级的进程进行运行，但进程的优先级可以分为静态优先级和动态优先级</p><ul><li>静态优先级：优先级在创建进程时已经确定，在进程运行期间保持不变，确定静态优先级的主要依据又进程类型，对资源的要求，用户要求。</li><li>动态优先级：进程运行过程中，根据进程运行时间和等待时间等因素调整进程的优先级</li></ul><p>但这种算法可能会导致低优先级的进程永远不被执行</p><p><img src="/../imgs/14th-March/image-20240314214039380.png" alt="最高优先级调度"></p><p>（6）多级队列调度算法</p><p>上⾯的各种调度算法是固定且单⼀的，⽆法满⾜系统中不同⽤户对进程调度策略的不同要求，多级队列调度算法在系统中设置多个就绪队列，将不同类型或性质的进程固定分配到不同的就绪队列，每个队列可以实施不同的调度算法。</p><p>（7）多级反馈队列调度算法</p><p>多级反馈队列调度算法融合了时间⽚轮转调度算法和优先级调度算法，通过动态调整进程的优先级和时间⽚⼤⼩，多级反馈队列调度算法可以兼顾多⽅⾯的系统⽬标</p><p>多级反馈队列调度算法的实现思想如下：</p><ul><li>设置多个就绪队列，并为每个队列赋予不同的优先级。第1级队列的优先级最⾼，第2级队列的优先级次之，其余队列的优先级逐个降低。</li><li>赋予各个队列的进程运⾏时间⽚的⼤⼩各不相同。在优先级越⾼的队列中，每个进程的时间⽚就越⼩。例如，第 i+1 级队列的时间⽚要⽐第i级队列的时间⽚⻓1倍。</li><li>每个队列都采⽤FCFS算法。当新进程进⼊内存后，⾸先将它放⼊第1级队列的末尾，按FCFS原则等待调度。当轮到该进程执⾏时，如它能在该时间⽚内完成，便可撤离系统。若它在⼀个时间⽚结束时尚未完成，调度程序将其转⼊第2级队列的末尾等待调度：若它在第2级队列中运⾏⼀个时间⽚后仍未完成，再将它放⼊第3级队列…，依此类推。当进程最后被降到第n级队列后，在第n级队列中便采⽤时间⽚轮转⽅式运⾏。</li><li>按队列优先级调度。仅当第1级队列为空时，才调度第2级队列中的进程运⾏；仅当第 1~i-1 级队列均为空时，才会调度第i级队列中的进程运⾏。若处理机正在执⾏第i级队列中的某进程时，⼜有新进程进⼊任⼀优先级较⾼的队列，此时须⽴即把正在运⾏的进程放回到第级队列的末尾，⽽把处理机分配给新到的⾼优先级进程。</li></ul><p>多级反馈队列的优势有以下几点：</p><ul><li>终端型作业用户：短作业优先。</li><li>短批处理作业用户：周转时间较短</li><li>长批处理作业用户：经过前面几个队列得到部分执行，不会长期得不到处理。</li></ul><p><img src="/../imgs/14th-March/image-20240314214242047.png" alt="多级反馈队列调度"></p><h4 id="Golang"><a href="#Golang" class="headerlink" title="Golang"></a>Golang</h4><h4 id="数组与切片有什么异同"><a href="#数组与切片有什么异同" class="headerlink" title="数组与切片有什么异同"></a>数组与切片有什么异同</h4><p>slice的底层数据是数组，slice是对数组的封装，它描述一个数组的片段。两者都可以通过下标来访问单个元素。</p><p>数组是定长的，长度定义好之后，不能再更改。在Go中，数组是不常见的，因为其长度是类型的一部分，限制了它的表达能力，比如[3]int和[4]int就是不同的类型。</p><p>而切片则非常灵活，它可以动态地扩容。切片的类型与长度无关。</p><p>数组就是一片连续的内存，slice实际上是一个结构体，包含三个字段：长度、容量、底层数组。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> slice <span class="hljs-keyword">struct</span> &#123;<br>array unsafe.Pointer <span class="hljs-comment">// 元素指针</span><br><span class="hljs-built_in">len</span>   <span class="hljs-type">int</span> <span class="hljs-comment">// 长度 </span><br><span class="hljs-built_in">cap</span>   <span class="hljs-type">int</span> <span class="hljs-comment">// 容量</span><br>&#125;<br></code></pre></td></tr></table></figure><p>slice的数据结构如下：</p><p><img src="/../imgs/14th-March/0.png" alt="切片数据结构"></p><p>注意，底层数组是可以被多个slice同时指向的，因此对一个slice的元素进行操作是有可能影响到其他slice的。</p><p>【引申1】 [3]int 和 [4]int 是同一个类型吗？</p><p>不是。因为数组的长度是类型的一部分，这是与 slice 不同的一点。</p><p>【引申2】 下面的代码输出是什么？</p><p>说明：例子来自<strong>《Go学习笔记》第四版</strong>，P43页。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> <span class="hljs-string">&quot;fmt&quot;</span><br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>slice := []<span class="hljs-type">int</span>&#123;<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>&#125;<br>s1 := slice[<span class="hljs-number">2</span>:<span class="hljs-number">5</span>]<br>s2 := s1[<span class="hljs-number">2</span>:<span class="hljs-number">6</span>:<span class="hljs-number">7</span>]<br><br>s2 = <span class="hljs-built_in">append</span>(s2, <span class="hljs-number">100</span>)<br>s2 = <span class="hljs-built_in">append</span>(s2, <span class="hljs-number">200</span>)<br><br>s1[<span class="hljs-number">2</span>] = <span class="hljs-number">20</span><br><br>fmt.Println(s1)<br>fmt.Println(s2)<br>fmt.Println(slice)<br>&#125;<br></code></pre></td></tr></table></figure><p>结果：</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs tap">[2<span class="hljs-number"> 3 </span>20]<br>[4<span class="hljs-number"> 5 </span>6<span class="hljs-number"> 7 </span>100 200]<br>[0<span class="hljs-number"> 1 </span>2<span class="hljs-number"> 3 </span>20<span class="hljs-number"> 5 </span>6<span class="hljs-number"> 7 </span>100 9]<br></code></pre></td></tr></table></figure><p><code>s1</code>从slice索引2（闭区间）到索引5（开区间），长度为3，容器默认到数组结尾，为8.<code>s2</code>从<code>s1</code>的索引2闭区间到索引6（开区间），容量到索引7（开区间），为5</p><p><img src="/../imgs/14th-March/1.png" alt="slice origin"></p><p>接着，向 <code>s2</code> 尾部追加一个元素 100：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs go">s2 = <span class="hljs-built_in">append</span>(s2, <span class="hljs-number">100</span>)<br></code></pre></td></tr></table></figure><p><code>s2</code> 容量刚好够，直接追加。不过，这会修改原始数组对应位置的元素。这一改动，数组和 <code>s1</code> 都可以看得到。</p><p><img src="/../imgs/14th-March/2.png" alt="append 100"></p><p>再次向 <code>s2</code> 追加元素200：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs go">s2 = <span class="hljs-built_in">append</span>(s2, <span class="hljs-number">100</span>)<br></code></pre></td></tr></table></figure><p>这时，<code>s2</code> 的容量不够用，该扩容了。于是，<code>s2</code> 另起炉灶，将原来的元素复制新的位置，扩大自己的容量。并且为了应对未来可能的 <code>append</code> 带来的再一次扩容，<code>s2</code> 会在此次扩容的时候多留一些 <code>buffer</code>，将新的容量将扩大为原始容量的2倍，也就是10了。</p><p><img src="/../imgs/14th-March/3.png" alt="append 200"></p><p>最后，修改 <code>s1</code> 索引为2位置的元素：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs go">s1[<span class="hljs-number">2</span>] = <span class="hljs-number">20</span><br></code></pre></td></tr></table></figure><p>这次只会影响原始数组相应位置的元素。它影响不到 <code>s2</code> 了，人家已经远走高飞了。</p><p><img src="/../imgs/14th-March/4.png" alt="s1[2]=20"></p><p>打印 <code>s1</code> 的时候，只会打印出 <code>s1</code> 长度以内的元素。所以，只会打印出3个元素，虽然它的底层数组不止3个元素。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>周六上午十点蚂蚁笔试，下午两点饿了么笔试（不是很匹配其实），周日看能不能面得物</p><p>感觉markdown还是不太熟练 啥时候进修一下子</p>]]></content>
    
    
    <categories>
      
      <category>diary</category>
      
    </categories>
    
    
    <tags>
      
      <tag>diary</tag>
      
      <tag>算法</tag>
      
      <tag>八股</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>13th-March</title>
    <link href="/2024/03/13/13th-March/"/>
    <url>/2024/03/13/13th-March/</url>
    
    <content type="html"><![CDATA[<h2 id="To-do-List"><a href="#To-do-List" class="headerlink" title="To-do List"></a>To-do List</h2><ul><li><p><input checked="" disabled="" type="checkbox"> 算法</p><ul><li><input checked="" disabled="" type="checkbox"> bfs &amp;&amp; trie树</li></ul></li><li><p><input disabled="" type="checkbox"> 项目</p><ul><li><input checked="" disabled="" type="checkbox"> cmu15445</li><li><input disabled="" type="checkbox"> mit6.824</li><li><input disabled="" type="checkbox"> mit6.081</li></ul></li><li><p><input disabled="" type="checkbox"> 八股</p><ul><li><input checked="" disabled="" type="checkbox"> 操作系统</li><li><input checked="" disabled="" type="checkbox"> 计算机网络</li><li><input disabled="" type="checkbox"> 数据库</li><li><input disabled="" type="checkbox"> redis</li></ul></li><li><p><input checked="" disabled="" type="checkbox"> 日常总结</p></li></ul><h3 id="1-算法"><a href="#1-算法" class="headerlink" title="1.算法"></a>1.算法</h3><h4 id="I-bfs"><a href="#I-bfs" class="headerlink" title="I.bfs"></a>I.bfs</h4><p><a href="https://leetcode.cn/problems/word-ladder/description/?envType=study-plan-v2&envId=top-interview-150">单词接龙</a></p><p>题面：<img src="/../imgs/13th-March/image-20240313171436208.png" alt="image-20240313171436208"></p><p>解答：其实都是很经典的队列bfs 和其他同类型的其他两个几乎一样 但是我也不知道为什么他是hard </p><p>用队列存储状态 然后再递归 理解bfs的精髓就好</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">while</span> (!q.<span class="hljs-built_in">empty</span>()) &#123;<br>            <span class="hljs-type">int</span> sz = q.<span class="hljs-built_in">size</span>();<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; sz; i++) &#123;<br>                string curr = q.<span class="hljs-built_in">front</span>();<br>                q.<span class="hljs-built_in">pop</span>();<br>                <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; l; j++) &#123;<br>                    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> k = <span class="hljs-number">0</span>; k &lt; <span class="hljs-number">26</span>; k++) &#123;<br>                        <span class="hljs-keyword">if</span> (<span class="hljs-string">&#x27;a&#x27;</span> + k != curr[j]) &#123;<br>                            string next = curr;<br>                            next[j] = <span class="hljs-string">&#x27;a&#x27;</span> + k;<br>                            <span class="hljs-keyword">if</span> (!visited.<span class="hljs-built_in">count</span>(next) &amp;&amp; cnt.<span class="hljs-built_in">count</span>(next)) &#123;<br>                                <span class="hljs-keyword">if</span> (next == end) &#123;<br>                                    <span class="hljs-keyword">return</span> step;<br>                                &#125;<br>                                q.<span class="hljs-built_in">emplace</span>(next);<br>                                visited.<span class="hljs-built_in">emplace</span>(next);<br>                            &#125;<br>                        &#125;<br>                    &#125;<br>                &#125;<br>            &#125;<br>            step++;<br>        &#125;<br></code></pre></td></tr></table></figure><h4 id="II-Trie树"><a href="#II-Trie树" class="headerlink" title="II.Trie树"></a>II.Trie树</h4><p><a href="https://leetcode.cn/problems/word-search-ii/description/?envType=study-plan-v2&envId=top-interview-150">单词搜索II</a></p><p>题面：</p><p><img src="/../imgs/13th-March/image-20240313171824850.png" alt="image-20240313171824850"></p><p>题解：就不放经典的Trie了，这个才是真正的应用，将每个单词insert，再遍历整个二维数组用dfs，能访问到的就加入答案</p><p>Trie模板：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">TrieNode</span> &#123;<br>    string word;<br>    unordered_map&lt;<span class="hljs-type">char</span>,TrieNode *&gt; children; <span class="hljs-comment">//还有就是可以用vector存 size26</span><br>    <span class="hljs-built_in">TrieNode</span>() &#123;<br>        <span class="hljs-keyword">this</span>-&gt;word = <span class="hljs-string">&quot;&quot;</span>;<br>    &#125;<br>&#125;;<br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">insert</span><span class="hljs-params">(TrieNode *root,<span class="hljs-type">const</span> string &amp; word)</span> </span>&#123;<br>    TrieNode *node = root;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> c : word) &#123;<br>        <span class="hljs-keyword">if</span> (!node-&gt;children.<span class="hljs-built_in">count</span>(c)) &#123;<br>            node-&gt;children[c] = <span class="hljs-keyword">new</span> <span class="hljs-built_in">TrieNode</span>();<br>        &#125;<br>        node = node-&gt;children[c];<br>    &#125;<br>    node-&gt;word = word;<br>&#125;<br></code></pre></td></tr></table></figure><p>dfs代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">dfs</span><span class="hljs-params">(vector&lt;vector&lt;<span class="hljs-type">char</span>&gt;&gt;&amp; board, <span class="hljs-type">int</span> x, <span class="hljs-type">int</span> y, TrieNode * root, set&lt;string&gt; &amp; res)</span> </span>&#123;<br>        <span class="hljs-type">char</span> ch = board[x][y];        <br>        <span class="hljs-keyword">if</span> (!root-&gt;children.<span class="hljs-built_in">count</span>(ch)) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>        &#125;<br>        root = root-&gt;children[ch];<br>        <span class="hljs-keyword">if</span> (root-&gt;word.<span class="hljs-built_in">size</span>() &gt; <span class="hljs-number">0</span>) &#123;<br>            res.<span class="hljs-built_in">insert</span>(root-&gt;word);<br>        &#125;<br><br>        board[x][y] = <span class="hljs-string">&#x27;#&#x27;</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">4</span>; ++i) &#123;<br>            <span class="hljs-type">int</span> nx = x + dirs[i][<span class="hljs-number">0</span>];<br>            <span class="hljs-type">int</span> ny = y + dirs[i][<span class="hljs-number">1</span>];<br>            <span class="hljs-keyword">if</span> (nx &gt;= <span class="hljs-number">0</span> &amp;&amp; nx &lt; board.<span class="hljs-built_in">size</span>() &amp;&amp; ny &gt;= <span class="hljs-number">0</span> &amp;&amp; ny &lt; board[<span class="hljs-number">0</span>].<span class="hljs-built_in">size</span>()) &#123;<br>                <span class="hljs-keyword">if</span> (board[nx][ny] != <span class="hljs-string">&#x27;#&#x27;</span>) &#123;<br>                    <span class="hljs-built_in">dfs</span>(board, nx, ny, root,res);<br>                &#125;<br>            &#125;<br>        &#125;<br>        board[x][y] = ch;<br><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;      <br>    &#125;<br></code></pre></td></tr></table></figure><h3 id="2-项目"><a href="#2-项目" class="headerlink" title="2.项目"></a>2.项目</h3><h4 id="cmu15445"><a href="#cmu15445" class="headerlink" title="cmu15445"></a>cmu15445</h4><p>进度：p3task1 大概看了一下 主要是query plan？ 到时候再看怎么看看代码</p><h3 id="3-八股"><a href="#3-八股" class="headerlink" title="3.八股"></a>3.八股</h3><h4 id="计算机网络"><a href="#计算机网络" class="headerlink" title="计算机网络"></a>计算机网络</h4><p>（1）在浏览器中输入URL并按下回车之后会发生什么</p><p>第一步：输入URL并解析</p><p>对URL进行解析，获得协议、主机、端口、路径等信息，并构造一个HTTP请求（强制缓存 or 协商缓存）</p><p>第二步：DNS域名解析</p><p>将域名解析为对应的IP地址</p><p>第三步：建立TCP三次握手链接</p><p>Q：为什么是三次，不是两次、四次？握手丢失会发生什么，过程中可以携带数据吗</p><p>第四步：浏览器发送HTTP&#x2F;HTTPS请求到web服务器</p><p>Q：HTTP&#x2F;HTTPS的区别，请求状态码1xx-5xx</p><p>第五步：服务器处理HTTP请求并返回HTTP报文</p><p>服务器接收请求并将其传递给请求处理程序并发送HTTP响应，内容：请求的网页以及状态码、压缩类型、如何缓存的页面、设置的cookie；</p><p>第六步：浏览器渲染页面</p><p>第七步：断开连接TCP4次握手</p><p><img src="/../imgs/13th-March/image-20240313182738368.png" alt="image-20240313182738368"></p><h4 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h4><h5 id="进程和线程"><a href="#进程和线程" class="headerlink" title="进程和线程"></a>进程和线程</h5><h6 id="1-进程基础"><a href="#1-进程基础" class="headerlink" title="1.进程基础"></a>1.进程基础</h6><p>(1)进程的概念</p><p>我们编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当我们运行这个可执行文件后，它就会被装载到内存中，接着CPU会执行程序中的每一条指令，那么这个运行中的程序，就被称为 <strong>[进程]（process)</strong></p><p>所以说，进程是具有独立功能的程序在一个数据集合上运行的过程，是系统进行资源分配和调度的一个独立单位。</p><p>（2）进程控制块（PCB）</p><p>系统通过<strong>PCB</strong>来描述进程的基本情况和运行状态，进而控制和管理进程，它是进程存在的唯一标识，包括：进程描述信息、进程控制和管理信息、进程资源分配清单、CPU相关信息</p><p><strong>PCB</strong>通常是通过链表的方式进行组织，把具有相同状态的进程链在一起，组成各种队列。</p><p>（3）并发与并行</p><p>单个处理核在很短时间内分别执行多个进程，成为并发</p><p>多个处理核同时执行多个进程称为并行</p><p>对于并发来说，CPU需要从一个进程切换到另一个进程，在切换前必须要记录当前进程中运行的状态信息，以备下次切换回来的时候可以恢复执行</p><p><img src="/../imgs/13th-March/image-20240313193807222.png" alt="image-20240313193807222"></p><p>（4）进程的状态切换</p><p>我们知道了并发会执行进程的切换，这就需要进程有运行状态和停止状态，实际上某个进程在某个时刻所处的态分为一下三种：</p><ul><li><p><strong>运行态</strong>：该时刻进程占用CPU</p></li><li><p><strong>就绪态</strong>：可运行，由于其他进程处于运行状态而暂停运行</p></li><li><p><strong>阻塞态</strong>：该进程正在等待某一事件的发生（如IO操作）而暂时停止运行</p><p><img src="/../imgs/13th-March/image-20240313194129133.png" alt="image-20240313194129133"></p></li></ul><p>如果有大量处于阻塞状态的进程，进程可能会占用着物理内存空间，所以系统通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存，那么就需要一个新的状态，来描述进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态。这跟阻塞状态是不一样的，阻塞是等待某个时间的返回。</p><p>分为阻塞挂起和阻塞就绪状态</p><p>（5）进程的上下文切换</p><p>一个进程切换到另一个进程运行，称为进程的上下文切换，<strong>进程的上下文切换</strong>不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括内核堆栈、寄存器等内核空间的资源。</p><p>（6）进程的创建</p><p>一个进程可以创建另一个进程，此时创建者为父进程，被创建的进程为子进程，操作系统创建一个新进程的过程如下：</p><ul><li>为新进程分配一个独特的进程控制块（PCB）</li><li>为新进程分配所需要的资源，如内存、CPU时间等</li><li>初始化进程控制块（PCB）的各种字段，包括状态、优先级、寄存器初始值等。</li><li>将其状态设置为就绪状态，使其能够被调度执行。进程进入就绪队列，等待分配处理器时间。</li></ul><p>（7）进程的终止</p><ul><li>根据标识符，查找需要终止的进程的PCB</li><li>如果进程处于执行状态，则立即终止该进程的执行，然后将处理器资源分配给其他进程</li><li>如果还有子进程，则将其子进程交给1号进程接管</li><li>将该进程所拥有的全部资源都归还给操作系统</li><li>将其从PCB所在队列中删除</li></ul><p>（8）进程的阻塞</p><ul><li>找到被阻塞进程的标识符对应的PCB</li><li>如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行</li><li>将该PCB插入到等待队列中，将处理机资源调度给其他就绪进程</li></ul><p>（9）进程的唤醒</p><ul><li>在该事件的阻塞队列中找到相应进程的PCB</li><li>将其从阻塞队列中移出，并置为就绪状态</li><li>将PCB插入到就绪队列中，等待调度程序调度</li></ul><h6 id="2-线程基础"><a href="#2-线程基础" class="headerlink" title="2.线程基础"></a>2.线程基础</h6><p>（1）什么是线程？</p><p>线程是“轻量级线程”，是进程中的一个实体，是程序执行的最小单位，也是被系统独立调度和分配的基本单位。</p><p>线程是进程当中的一条执行流程，同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程各自都有一套独立的寄存器和栈，这样可以确保线程的控制流是相互独立的。</p><p>（2）线程的特点</p><ul><li>线程是一个“轻量级线程”，一个进程中可以有多个线程，线程不拥有系统资源，但是也有PCB，创建线程使用的底层函数和进程一样，都是clone</li><li>各个线程之间可以并发执行</li><li>同一个进程中的各个线程共享该进程所拥有的资源</li><li>进程可以蜕变成线程</li></ul><p>实际上，无论是创建进程的fork，还是创建线程的pthread_create，底层实现都是调用同一个内核函数clone</p><p>linux内核是不区分线程和进程的，只在用户层面上进行区分。所以，线程所有操作函数pthread_*是库函数，而非系统调用</p><p>（3）进程和线程的比较</p><p>​<strong>进程是资源（包括内存、打开的文件等）分配的单位，线程是CPU调度的单位</strong></p><hr><ul><li>资源：进程是系统中拥有资源的基本单位，而线程不拥有系统资源（只有寄存器和栈），但线程可以访问隶属进程的系统资源</li><li>调度：线程切换的代价远低于进程，在同一个进程中，线程的切换不会引起进程切换，而从一个进程中的线程切换到另一个进程的线程中，会引起进程切换</li><li>并发：进程可以并发执行，而一个进程中的多个线程之间也能并发执行，甚至不同进程中的线程也能并发执行，从而是的操作系统拥有更好的并发性，提高了系统资源的利用率和系统的吞吐量</li><li>独立性：每个进程都拥有独⽴的地址空间和资源、除了共享全局变量，不允许其他进程访问。某进程中的线程对其他进程都不可⻅，同⼀进程中的不同线程是为了提⾼并发性以及进⾏相互之间的合作⽽创建的，它们共享进程的地址空间和资源。</li><li>系统开销：线程所需要的开销比进程小</li></ul><p>（4）线程的状态：</p><ul><li>执行状态</li><li>就绪状态</li><li>阻塞状态</li></ul><p>（5）线程的实现</p><ol><li>用户线程：用户空间实现的线程，操作系统不直接参与</li><li>内核线程：操作系统管理、调度，PCB存放在内核中</li><li>轻量级线程：内核支持的用户线程</li></ol><p>（6）线程共享资源</p><ul><li>文件描述符表</li><li>每种信号的处理方式</li><li>当前工作目录</li><li>用户ID和组ID</li></ul><p>（7）线程非共享资源</p><ul><li>线程id</li><li>处理器现场和栈指针</li><li>独立的栈空间</li><li>errno变量（？这是什么）</li><li>信号屏蔽字</li><li>调度优先级</li></ul><p>（8）线程的优缺点</p><p><strong>优点:</strong></p><ul><li>提高程序并发性</li><li>开销小</li><li>数据通信、共享数据方便</li></ul><p><strong>缺点:</strong></p><ul><li>库函数，不稳定</li><li>调试、编写困难、gdb不支持</li><li>对信号支持不好</li></ul><p>（9）线程如何减少开销</p><ol><li>线程创建快、进程创建需要资源管理信息，比如内存管理信息和文件管理信息，而线程创建后是共享其所属进程的资源管理信息</li><li>线程终止时间快，需回收的仅有少量寄存器和私有的栈区</li><li>线程切换快，因为线程切换仅涉及到少量寄存器和栈区，而进程上下文切换有CPU寄存器和程序寄存器、虚拟内存空间、页表切换等</li><li>线程因为创建时共享了其所属进程绝大多数资源，因此天生具有很好的线程间通信交互效率</li></ol><h3 id="4-总结"><a href="#4-总结" class="headerlink" title="4.总结"></a>4.总结</h3><p>投递进度</p><table><thead><tr><th>公司</th><th>进度</th><th>备注</th></tr></thead><tbody><tr><td>字节</td><td>简历评估</td><td></td></tr><tr><td>快手</td><td>系统研发存储 已投</td><td></td></tr><tr><td>携程</td><td>已投</td><td></td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>diary</category>
      
    </categories>
    
    
    <tags>
      
      <tag>diary</tag>
      
      <tag>算法</tag>
      
      <tag>八股</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>12th-March</title>
    <link href="/2024/03/12/12th-March/"/>
    <url>/2024/03/12/12th-March/</url>
    
    <content type="html"><![CDATA[<h2 id="To-do-List"><a href="#To-do-List" class="headerlink" title="To-do List"></a>To-do List</h2><ul><li><p><input checked="" disabled="" type="checkbox"> 算法</p><ul><li><input checked="" disabled="" type="checkbox"> graph</li></ul></li><li><p><input disabled="" type="checkbox"> 项目</p><ul><li><input checked="" disabled="" type="checkbox"> cmu15445</li><li><input disabled="" type="checkbox"> mit6.824</li><li><input disabled="" type="checkbox"> mit6.081</li></ul></li><li><p><input disabled="" type="checkbox"> 八股</p><ul><li><input disabled="" type="checkbox"> 操作系统</li><li><input disabled="" type="checkbox"> 计算机网络</li><li><input disabled="" type="checkbox"> 数据库</li><li><input disabled="" type="checkbox"> redis</li></ul></li><li><p><input disabled="" type="checkbox"> 日常总结</p></li></ul><h3 id="1-算法"><a href="#1-算法" class="headerlink" title="1.算法"></a>1.算法</h3><h4 id="图论"><a href="#图论" class="headerlink" title="图论"></a>图论</h4><p>(1)<a href="https://leetcode.cn/problems/surrounded-regions/description/?envType=study-plan-v2&envId=top-interview-150">leetcode被围绕的区域</a></p><p>题面：<img src="/../imgs/12th-March/image-20240312215015214.png" alt="image-20240312215015214"></p><p>解答：从边缘的点开始dfs，先标记为’A’,再重新遍历修改</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">dfs</span><span class="hljs-params">(vector&lt;vector&lt;<span class="hljs-type">char</span>&gt;&gt; &amp;board, <span class="hljs-type">int</span> i, <span class="hljs-type">int</span> j)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (i &lt; <span class="hljs-number">0</span> || i &gt;= n || j &lt; <span class="hljs-number">0</span> || j &gt;= m || board[i][j] != <span class="hljs-string">&#x27;O&#x27;</span>) &#123;<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        board[i][j] = <span class="hljs-string">&#x27;A&#x27;</span>;<br>        <span class="hljs-keyword">if</span> (i - <span class="hljs-number">1</span> &gt;= <span class="hljs-number">0</span> &amp;&amp; board[i<span class="hljs-number">-1</span>][j] == <span class="hljs-string">&#x27;O&#x27;</span>) <span class="hljs-built_in">dfs</span>(board, i - <span class="hljs-number">1</span>, j);<br>        <span class="hljs-keyword">if</span> (j - <span class="hljs-number">1</span> &gt;= <span class="hljs-number">0</span> &amp;&amp; board[i][j<span class="hljs-number">-1</span>] == <span class="hljs-string">&#x27;O&#x27;</span>) <span class="hljs-built_in">dfs</span>(board, i, j - <span class="hljs-number">1</span>);<br>        <span class="hljs-keyword">if</span> (i + <span class="hljs-number">1</span> &lt; n &amp;&amp; board[i+<span class="hljs-number">1</span>][j] == <span class="hljs-string">&#x27;O&#x27;</span>) <span class="hljs-built_in">dfs</span>(board, i + <span class="hljs-number">1</span>, j);<br>        <span class="hljs-keyword">if</span> (j + <span class="hljs-number">1</span> &lt; m &amp;&amp; board[i][j+<span class="hljs-number">1</span>] == <span class="hljs-string">&#x27;O&#x27;</span>) <span class="hljs-built_in">dfs</span>(board, i, j + <span class="hljs-number">1</span>);<br>    &#125;<br></code></pre></td></tr></table></figure><p>(2)<a href="https://leetcode.cn/problems/course-schedule/description/?envType=study-plan-v2&envId=top-interview-150">leetcode课程表</a></p><p>题面：</p><p><img src="/../imgs/12th-March/image-20240312215238605.png" alt="image-20240312215238605"></p><p>题解：主要是拓扑排序，要是自己写可能就记录每个点的入度？然后从0开始，再一个一个遍历。但是其他题解是dfs，仔细想了想确实精妙。从一个点开始dfs，遍历他所有的节点，然后记录状态，最后记录当前节点，并放入答案中。</p><p>dfs重要代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">dfs</span><span class="hljs-params">(<span class="hljs-type">int</span> u)</span> </span>&#123;<br>        visited[u] = <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> v: edges[u]) &#123;<br>            <span class="hljs-keyword">if</span> (visited[v] == <span class="hljs-number">0</span>) &#123;<br>                <span class="hljs-built_in">dfs</span>(v);<br>                <span class="hljs-keyword">if</span> (!valid) &#123;<br>                    <span class="hljs-keyword">return</span>;<br>                &#125;<br>            &#125;<br>            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (visited[v] == <span class="hljs-number">1</span>) &#123;<br>                valid = <span class="hljs-literal">false</span>;<br>                <span class="hljs-keyword">return</span>;<br>            &#125;<br>        &#125;<br>        visited[u] = <span class="hljs-number">2</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="2-项目"><a href="#2-项目" class="headerlink" title="2.项目"></a>2.项目</h3><h4 id="cmu15445"><a href="#cmu15445" class="headerlink" title="cmu15445"></a>cmu15445</h4><p>Query Planning</p><p>emmm懒得总结了 大概就是说logical优化和physical优化</p><h3 id="3-八股"><a href="#3-八股" class="headerlink" title="3.八股"></a>3.八股</h3><p>今天没看。。。下次再说</p><h3 id="4-总结"><a href="#4-总结" class="headerlink" title="4.总结"></a>4.总结</h3><p>今天搞的有点少。。主要是晚上全在鼓捣这玩意，先好好准备一下周末的蚂蚁笔试，饿了么也可以</p><p>投递进度</p><table><thead><tr><th>公司</th><th>进度</th><th>备注</th></tr></thead><tbody><tr><td>腾讯</td><td>已投递</td><td>等捞？</td></tr><tr><td>字节</td><td>已投递</td><td></td></tr><tr><td>百度</td><td>无消息 已投递</td><td></td></tr><tr><td>蚂蚁</td><td>3.16笔试</td><td></td></tr><tr><td>美团</td><td>笔试完</td><td></td></tr><tr><td>阿里云</td><td>已投递</td><td></td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>diary</category>
      
    </categories>
    
    
    <tags>
      
      <tag>diary</tag>
      
      <tag>算法</tag>
      
      <tag>八股</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
