<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>20th-March</title>
    <link href="/2024/03/20/20th-March/"/>
    <url>/2024/03/20/20th-March/</url>
    
    <content type="html"><![CDATA[<h1 id="每日八股"><a href="#每日八股" class="headerlink" title="每日八股"></a>每日八股</h1><h2 id="计网"><a href="#计网" class="headerlink" title="计网"></a>计网</h2><h3 id="HTTP-1-1、HTTP-2、HTTP-3演变"><a href="#HTTP-1-1、HTTP-2、HTTP-3演变" class="headerlink" title="HTTP&#x2F;1.1、HTTP&#x2F;2、HTTP&#x2F;3演变"></a>HTTP&#x2F;1.1、HTTP&#x2F;2、HTTP&#x2F;3演变</h3><h4 id="HTTP-1-1-相比-HTTP-1-0提高了什么性能？"><a href="#HTTP-1-1-相比-HTTP-1-0提高了什么性能？" class="headerlink" title="HTTP&#x2F;1.1 相比 HTTP&#x2F;1.0提高了什么性能？"></a>HTTP&#x2F;1.1 相比 HTTP&#x2F;1.0提高了什么性能？</h4><ul><li>使用长连接的方式改善了HTTP&#x2F;1.0短连接造成的性能开销</li><li>支持管道网络运输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。</li></ul><p>但HTTP&#x2F;1.1还是有性能瓶颈：</p><ul><li>请求&#x2F;响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩<code>Body</code>的部分</li><li>发送冗长的首部。每次互相发送相同的首部造成的浪费较多</li><li>服务器是按请求的顺序响应的，如果服务器响应慢，会导致客户端一直请求不到数据，也就是队头阻塞</li><li>没有请求优先级控制</li><li>请求只能从客户端开始，服务器只能被动响应</li></ul><h4 id="HTTP-2做了什么优化？"><a href="#HTTP-2做了什么优化？" class="headerlink" title="HTTP&#x2F;2做了什么优化？"></a>HTTP&#x2F;2做了什么优化？</h4><p>HTTP&#x2F;2协议是基于HTTPS的，所以HTTP&#x2F;2的安全性也是有保障的。</p><ul><li>头部压缩</li><li>二进制格式</li><li>并发传输</li><li>服务器主动推送资源</li></ul><p>1.头部压缩</p><p>HTTP&#x2F;2会压缩头，如果你同时发出多个请求，他们的头是一样的或是相似，那么，协议会帮你消除重复的部分。</p><p>这就是所谓的HPACK算法:在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送重复的字段了，只发送索引号，这样就提高速度了。</p><p>2.二进制格式</p><p>HTTP&#x2F;2不再像HTTP&#x2F;1.1里的纯文本形式的文本，而是全面采用了二进制格式，头信息和数据体都是二进制，并且统称为帧：头信息帧和数据帧</p><p>这样虽然对人不友好，但是对计算机非常友好，因为计算机只懂二进制，那么收到报文后，无需再将明文的报文转成二进制，而是直接解析二进制报文，这<strong>增加了数据传输的效率</strong>。</p><p>比如状态码 200 ，在 HTTP&#x2F;1.1 是用 ‘2’’0’’0’ 三个字符来表示（二进制：00110010 00110000 00110000），共用了 3 个字节，在 HTTP&#x2F;2 对于状态码 200 的二进制编码是 10001000，只用了 1 字节就能表示，相比于 HTTP&#x2F;1.1 节省了 2 个字节，</p><p>3.并发传输</p><p>我们都知道HTTP&#x2F;1.1的实现是基于请求-响应模型的。同一个连接中，HTTP完成一个事务（请求与响应），才能处理下一个事务，也就是说在发出请求等待响应的过程中，是没办法做其他事情的，如果响应迟迟不来，那么后续的请求是无法发送的，也造成了对头阻塞的问题</p><p>而HTTP&#x2F;2就引出了Stream概念，多个Stream复用在一条TCP连接</p><p><img src="/../imgs/20th-March/stream.png" alt="Stream"></p><p>从上图可以看到，1个TCP连接包含多个Stream，Stream里可以包含1个或多个Message，Message对应HTTP&#x2F;1中的请求或响应，由HTTP头部和Body构成。Message里包含一条或者多个Frame，Frame是HTTP&#x2F;2最小单位，以二进制压缩格式存放HTTP&#x2F;1中的内容。</p><p>针对不同的HTTP请求用独一无二的Stream ID来区分，接收端可以通过Stream ID有序组装成HTTP消息，不同Stream的帧是可以乱序发送的，因此可以并发不同的Stream，也就是HTTP&#x2F;2可以并行交错地发送请求和响应。</p><p>4.服务器推送</p><p>HTTP&#x2F;2还在一定程度上改善了传统的请求-应答工作模式，服务端不再是被动地响应，可以主动向客户端发送信息。</p><p>客户端和服务器<strong>双方都可以建立 Stream</strong>， Stream ID 也是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。</p><h4 id="HTTP-2有什么缺陷？"><a href="#HTTP-2有什么缺陷？" class="headerlink" title="HTTP&#x2F;2有什么缺陷？"></a>HTTP&#x2F;2有什么缺陷？</h4><p>HTTP&#x2F;2通过Stream的并发能力，解决了HTTP1&#x2F;1队头阻塞的问题，看似很完美了，但是HTTP&#x2F;2还是存在“队头阻塞”的问题，不过是在TCP这一层。</p><p><strong>HTTP&#x2F;2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP&#x2F;2 应用层才能从内核中拿到数据，这就是 HTTP&#x2F;2 队头阻塞问题。</strong></p><p><img src="/../imgs/20th-March/tcp%E9%98%9F%E5%A4%B4%E9%98%BB%E5%A1%9E.gif" alt="TCP队头阻塞"></p><p>图中发送方发送了很多个 packet，每个 packet 都有自己的序号，你可以认为是 TCP 的序列号，其中 packet 3 在网络中丢失了，即使 packet 4-6 被接收方收到后，由于内核中的 TCP 数据不是连续的，于是接收方的应用层就无法从内核中读取到，只有等到 packet 3 重传后，接收方的应用层才可以从内核中读取到数据，这就是 HTTP&#x2F;2 的队头阻塞问题，是在 TCP 层面发生的。</p><p>所以，一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的<strong>所有的 HTTP 请求都必须等待这个丢了的包被重传回来</strong>。</p><h4 id="HTTP-3-做了哪些优化？"><a href="#HTTP-3-做了哪些优化？" class="headerlink" title="HTTP&#x2F;3 做了哪些优化？"></a>HTTP&#x2F;3 做了哪些优化？</h4><p>从TCP改成了UDP</p><p>UDP 发送是不管顺序，也不管丢包的，所以不会出现像 HTTP&#x2F;2 队头阻塞的问题。大家都知道 UDP 是不可靠传输的，但基于 UDP 的 <strong>QUIC 协议</strong> 可以实现类似 TCP 的可靠性传输。</p><ul><li>无队头阻塞</li><li>更快的连接建立</li><li>连接迁移</li></ul><p>1.无队头阻塞</p><p>QUIC协议也有类似HTTP&#x2F;2 Stream与多路复用的概念，也是可以在同一条连接上并发传输多个Stream，Stream可以认为就是一条HTTP请求。</p><p>QUIC有自己的一套机制可以保证传输的可靠性的。当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题。这与HTTP&#x2F;2不同，HTTP&#x2F;2只要某个流中的数据包丢失了，其他流也会因此受影响。</p><p>所以，QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不受影响。</p><p><img src="/../imgs/20th-March/quic%E6%97%A0%E9%98%BB%E5%A1%9E.jpeg" alt="QUIC多路复用"></p><p><img src="/../imgs/20th-March/http2%E9%98%BB%E5%A1%9E.jpeg" alt="TCP队头阻塞"></p><p>2.更快的连接建立</p><p>对于HTTP&#x2F;1和HTTP&#x2F;2协议，TCP和TLS是分层的，分别属于内核实现的传输层，openssl层库实现的表示层，因此它们难以合并在一起，需要分批次来我收，先TCP握手再TLS握手。</p><p>HTTP&#x2F;3再传输数据前虽然需要QUIC协议握手，但是这个握手过程只需要1RTT，握手的目的是为确认双方的连接ID，连接迁移就是基于连接ID实现的。</p><p>但是HTTP&#x2F;3的QUIC协议并不是与TLS分层，而是QUIC内部包含了TLS，它再自己的帧会携带TLS里的“记录”，再加上QUIC使用的是TLS&#x2F;1.3，因此只需要1个RTT就可以同时完成建立连接与密钥协商</p><p><img src="/../imgs/20th-March/28-HTTP3%E4%BA%A4%E4%BA%92%E6%AC%A1%E6%95%B0.jpeg" alt="TCP HTTPS（TLS/1.3） 和 QUIC HTTPS "></p><p>3.连接迁移</p><p>基于TCP传输协议的HTTP协议，由于是通过四元组确定一条TCP连接。</p><p><img src="/../imgs/20th-March/format,png-20230309231026577.png" alt="TCP 四元组"></p><p>那么当移动设备的网络从4G切换到WIFI时，意味着IP地址变化了，那么久必须要断开连接，然后重新建立连接。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。</p><p>而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过<strong>连接 ID</strong> 来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了<strong>连接迁移</strong>的功能。</p><p>所以， QUIC 是一个在 UDP 之上的<strong>伪</strong> TCP + TLS + HTTP&#x2F;2 的多路复用的协议。</p><p>QUIC 是新协议，对于很多网络设备，根本不知道什么是 QUIC，只会当做 UDP，这样会出现新的问题，因为有的网络设备是会丢掉 UDP 包的，而 QUIC 是基于 UDP 实现的，那么如果网络设备无法识别这个是 QUIC 包，那么就会当作 UDP包，然后被丢弃。</p><h3 id="什么是TCP？"><a href="#什么是TCP？" class="headerlink" title="什么是TCP？"></a>什么是TCP？</h3><p>TCP是面向连接的、可靠的、基于字节流的传输层通信协议</p><ul><li>面向连接：一定是一对一才能连接，不能像UDP协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的</li><li>可靠的：无论网络链路中出现了怎样的链路变化，TCP都可以保证一个报文一定能够到达接收端</li><li>字节流：用户消息通过 TCP 协议传输时，消息可能会被操作系统「分组」成多个的 TCP 报文，如果接收方的程序如果不知道「消息的边界」，是无法读出一个有效的用户消息的。并且 TCP 报文是「有序的」，当「前一个」TCP 报文没有收到的时候，即使它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理，同时对「重复」的 TCP 报文会自动丢弃。</li></ul><h3 id="UDP和TCP有什么区别呢？分别的应用场景是？"><a href="#UDP和TCP有什么区别呢？分别的应用场景是？" class="headerlink" title="UDP和TCP有什么区别呢？分别的应用场景是？"></a>UDP和TCP有什么区别呢？分别的应用场景是？</h3><p>UDP不提供复杂的控制机制，利用IP提供面向无连接的通信服务。</p><ul><li>目标和源端口：主要是告诉UDP协议应该把报文发给哪个进程。</li><li>包长度：该字段保存了UDP首部的长度跟数据的长度之和</li><li>校验和：校验和是为了提供可靠的UDP首部和数据而设计，防止收到再网络传输中受损的UDP包</li></ul><p><img src="/../imgs/20th-March/format,png-20230309230439961.png" alt="UDP 头部格式"></p><p><img src="/../imgs/20th-March/format,png-20230309230534096.png" alt="TCP 头格式"></p><p>区别：</p><p>1.连接</p><ul><li>TCP是面向连接的传输层协议，传输数据前先要建立连接</li><li>UDP是不需要连接，即刻传输数据。</li></ul><p>2.服务对象</p><ul><li>TCP是一对一的两点服务，即一条连接只有两个端点</li><li>UDP支持一对一、一对多、多对多的交互通信</li></ul><p>3.可靠性</p><ul><li>TCP是可靠交付数据的，数据可以无差错、不丢失、不重复、按序到达。</li><li>UDP是尽最大努力交付，不保证可靠交付数据，但是可以基于UDP传输协议实现一个可靠的传输协议，比如QUIC协议</li></ul><p>4.拥塞控制，流量控制</p><ul><li>TCP由拥塞控制和流量控制机制，保证数据传输的安全性</li><li>UDP则没有，即使网络非常拥堵了，也不会影响UDP的发送速率。</li></ul><p>5.首部开销</p><ul><li>TCP首部长度较长，会有一定的开销，首部在没有使用选项时是20个字节，如果使用了选项字段则会变长的。</li><li>UDP首部只有8个字节，并且是固定不变的，开销较小</li></ul><ol start="6"><li>传输方式</li></ol><ul><li>TCP 是流式传输，没有边界，但保证顺序和可靠。</li><li>UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。</li></ul><p>7.分片不同</p><ul><li>TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。</li><li>UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。</li></ul><p><strong>TCP 和 UDP 应用场景：</strong></p><p>由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：</p><ul><li><code>FTP</code> 文件传输；</li><li>HTTP &#x2F; HTTPS；</li></ul><p>由于 UDP 面向无连接，它可以随时发送数据，再加上 UDP 本身的处理既简单又高效，因此经常用于：</p><ul><li>包总量较少的通信，如 <code>DNS</code> 、<code>SNMP</code> 等；</li><li>视频、音频等多媒体通信；</li><li>广播通信；</li></ul><h3 id="TCP重传、流量控制、拥塞控制"><a href="#TCP重传、流量控制、拥塞控制" class="headerlink" title="TCP重传、流量控制、拥塞控制"></a>TCP重传、流量控制、拥塞控制</h3><p>TCP 实现可靠传输的方式之一，是通过序列号与确认应答。</p><p>在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个确认应答消息，表示已收到消息。</p><p>但在错综复杂的网络，并不一定能如上图那么顺利能正常的数据传输，万一数据在传输过程中丢失了呢？</p><p>所以 TCP 针对数据包丢失的情况，会用<strong>重传机制</strong>解决。</p><p>接下来说说常见的重传机制：</p><ul><li>超时重传</li><li>快速重传</li><li>SACK</li><li>D-SACK</li></ul><h3 id="超时重传"><a href="#超时重传" class="headerlink" title="超时重传"></a>超时重传</h3><p>重传机制的其中一个方式，就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 <code>ACK</code> 确认应答报文，就会重发该数据，也就是我们常说的<strong>超时重传</strong>。</p><p>TCP 会在以下两种情况发生超时重传：</p><ul><li>数据包丢失</li><li>确认应答丢失</li></ul><p><img src="/../imgs/20th-March/5.jpg" alt="超时重传的两种情况"></p><p>超时触发重传存在的问题是，超时周期可能相对较长。那是不是可以有更快的方式呢？</p><p>于是就可以用「快速重传」机制来解决超时重发的时间等待。</p><h3 id="快速重传"><a href="#快速重传" class="headerlink" title="#快速重传"></a><a href="https://xiaolincoding.com/network/3_tcp/tcp_feature.html#%E5%BF%AB%E9%80%9F%E9%87%8D%E4%BC%A0">#</a>快速重传</h3><p>TCP 还有另外一种<strong>快速重传（Fast Retransmit）机制</strong>，它<strong>不以时间为驱动，而是以数据驱动重传</strong>。</p><p>快速重传机制，是如何工作的呢？其实很简单，一图胜千言。</p><p><img src="/../imgs/20th-March/10.jpg" alt="快速重传机制"></p><p>在上图，发送方发出了 1，2，3，4，5 份数据：</p><ul><li>第一份 Seq1 先送到了，于是就 Ack 回 2；</li><li>结果 Seq2 因为某些原因没收到，Seq3 到达了，于是还是 Ack 回 2；</li><li>后面的 Seq4 和 Seq5 都到了，但还是 Ack 回 2，因为 Seq2 还是没有收到；</li><li><strong>发送端收到了三个 Ack &#x3D; 2 的确认，知道了 Seq2 还没有收到，就会在定时器过期之前，重传丢失的 Seq2。</strong></li><li>最后，收到了 Seq2，此时因为 Seq3，Seq4，Seq5 都收到了，于是 Ack 回 6 。</li></ul><p>所以，快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。</p><p>快速重传机制只解决了一个问题，就是超时时间的问题，但是它依然面临着另外一个问题。就是<strong>重传的时候，是重传一个，还是重传所有的问题。</strong></p><p>举个例子，假设发送方发了 6 个数据，编号的顺序是 Seq1 ~ Seq6 ，但是 Seq2、Seq3 都丢失了，那么接收方在收到 Seq4、Seq5、Seq6 时，都是回复 ACK2 给发送方，但是发送方并不清楚这连续的 ACK2 是接收方收到哪个报文而回复的， 那是选择重传 Seq2 一个报文，还是重传 Seq2 之后已发送的所有报文呢（Seq2、Seq3、 Seq4、Seq5、 Seq6） 呢？</p><ul><li>如果只选择重传 Seq2 一个报文，那么重传的效率很低。因为对于丢失的 Seq3 报文，还得在后续收到三个重复的 ACK3 才能触发重传。</li><li>如果选择重传 Seq2 之后已发送的所有报文，虽然能同时重传已丢失的 Seq2 和 Seq3 报文，但是 Seq4、Seq5、Seq6 的报文是已经被接收过了，对于重传 Seq4 ～Seq6 折部分数据相当于做了一次无用功，浪费资源。</li></ul><p>可以看到，不管是重传一个报文，还是重传已发送的报文，都存在问题。</p><p>为了解决不知道该重传哪些 TCP 报文，于是就有 <code>SACK</code> 方法。</p><h3 id="SACK-方法"><a href="#SACK-方法" class="headerlink" title="SACK 方法"></a>SACK 方法</h3><p>还有一种实现重传机制的方式叫：<code>SACK</code>（ Selective Acknowledgment）， <strong>选择性确认</strong>。</p><p>这种方式需要在 TCP 头部「选项」字段里加一个 <code>SACK</code> 的东西，它<strong>可以将已收到的数据的信息发送给「发送方」</strong>，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以<strong>只重传丢失的数据</strong>。</p><p>如下图，发送方收到了三次同样的 ACK 确认报文，于是就会触发快速重发机制，通过 <code>SACK</code> 信息发现只有 <code>200~299</code> 这段数据丢失，则重发时，就只选择了这个 TCP 段进行重复。</p><p><img src="/../imgs/20th-March/11.jpg" alt="选择性确认"></p><h3 id="Duplicate-SACK"><a href="#Duplicate-SACK" class="headerlink" title="Duplicate SACK"></a>Duplicate SACK</h3><p>Duplicate SACK 又称 <code>D-SACK</code>，其主要<strong>使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。</strong></p><p>下面举例两个栗子，来说明 <code>D-SACK</code> 的作用。</p><p><img src="/../imgs/20th-March/12.jpg" alt="ACK 丢包"></p><ul><li>「接收方」发给「发送方」的两个 ACK 确认应答都丢失了，所以发送方超时后，重传第一个数据包（3000 ~ 3499）</li><li><strong>于是「接收方」发现数据是重复收到的，于是回了一个 SACK &#x3D; 3000~3500</strong>，告诉「发送方」 3000~3500 的数据早已被接收了，因为 ACK 都到了 4000 了，已经意味着 4000 之前的所有数据都已收到，所以这个 SACK 就代表着 <code>D-SACK</code>。</li><li>这样「发送方」就知道了，数据没有丢，是「接收方」的 ACK 确认报文丢了。</li></ul><p><img src="/../imgs/20th-March/13.jpg" alt="网络延时"></p><ul><li>数据包（1000~1499） 被网络延迟了，导致「发送方」没有收到 Ack 1500 的确认报文。</li><li>而后面报文到达的三个相同的 ACK 确认报文，就触发了快速重传机制，但是在重传后，被延迟的数据包（1000~1499）又到了「接收方」；</li><li><strong>所以「接收方」回了一个 SACK&#x3D;1000~1500，因为 ACK 已经到了 3000，所以这个 SACK 是 D-SACK，表示收到了重复的包。</strong></li><li>这样发送方就知道快速重传触发的原因不是发出去的包丢了，也不是因为回应的 ACK 包丢了，而是因为网络延迟了。</li></ul><p>可见，<code>D-SACK</code> 有这么几个好处：</p><ol><li>可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;</li><li>可以知道是不是「发送方」的数据包被网络延迟了;</li><li>可以知道网络中是不是把「发送方」的数据包给复制了;</li></ol><h2 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h2><p>发送方不能无脑的发数据给接收方，要考虑接收方处理能力。</p><p>如果一直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。</p><p>为了解决这种现象发生，<strong>TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。</strong></p><p>下面举个栗子，为了简单起见，假设以下场景：</p><ul><li>客户端是接收方，服务端是发送方</li><li>假设接收窗口和发送窗口相同，都为 <code>200</code></li><li>假设两个设备在整个传输过程中都保持相同的窗口大小，不受外界影响</li></ul><h2 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h2><blockquote><p>为什么要有拥塞控制呀，不是有流量控制了吗？</p></blockquote><p>前面的流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么。</p><p>一般来说，计算机网络都处在一个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。</p><p><strong>在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大….</strong></p><p>所以，TCP 不能忽略网络上发生的事，它被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量。</p><p>于是，就有了<strong>拥塞控制</strong>，控制的目的就是<strong>避免「发送方」的数据填满整个网络。</strong></p><p>为了在「发送方」调节所要发送数据的量，定义了一个叫做「<strong>拥塞窗口</strong>」的概念。</p><blockquote><p>什么是拥塞窗口？和发送窗口有什么关系呢？</p></blockquote><p><strong>拥塞窗口 cwnd</strong>是发送方维护的一个的状态变量，它会根据<strong>网络的拥塞程度动态变化的</strong>。</p><p>我们在前面提到过发送窗口 <code>swnd</code> 和接收窗口 <code>rwnd</code> 是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是swnd &#x3D; min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。</p><p>拥塞窗口 <code>cwnd</code> 变化的规则：</p><ul><li>只要网络中没有出现拥塞，<code>cwnd</code> 就会增大；</li><li>但网络中出现了拥塞，<code>cwnd</code> 就减少；</li></ul><blockquote><p>那么怎么知道当前网络是否出现了拥塞呢？</p></blockquote><p>其实只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是<strong>发生了超时重传，就会认为网络出现了拥塞。</strong></p><blockquote><p>拥塞控制有哪些控制算法？</p></blockquote><p>拥塞控制主要是四个算法：</p><ul><li>慢启动</li><li>拥塞避免</li><li>拥塞发生</li><li>快速恢复</li></ul><h4 id="慢启动"><a href="#慢启动" class="headerlink" title="慢启动"></a>慢启动</h4><p>TCP在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量如果一上来就发大量的数据，就是再给网络添堵。</p><p><strong>当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。</strong></p><ul><li>连接建立完成后，一开始初始化 <code>cwnd = 1</code>，表示可以传一个 <code>MSS</code> 大小的数据。</li><li>当收到一个 ACK 确认应答后，cwnd 增加 1，于是一次能够发送 2 个</li><li>当收到 2 个的 ACK 确认应答后， cwnd 增加 2，于是就可以比之前多发2 个，所以这一次能够发送 4 个</li><li>当这 4 个的 ACK 确认到来的时候，每个确认 cwnd 增加 1， 4 个确认 cwnd 增加 4，于是就可以比之前多发 4 个，所以这一次能够发送 8 个。</li></ul><p>可以看出慢启动算法，发包的个数是<strong>指数性的增长</strong>。</p><blockquote><p>那慢启动涨到什么时候是个头呢？</p></blockquote><p>有一个叫慢启动门限 <code>ssthresh</code> （slow start threshold）状态变量。</p><ul><li>当 <code>cwnd</code> &lt; <code>ssthresh</code> 时，使用慢启动算法。</li><li>当 <code>cwnd</code> &gt;&#x3D; <code>ssthresh</code> 时，就会使用「拥塞避免算法」。</li></ul><h4 id="拥塞避免算法"><a href="#拥塞避免算法" class="headerlink" title="拥塞避免算法"></a>拥塞避免算法</h4><p>前面说道，当拥塞窗口 <code>cwnd</code> 「超过」慢启动门限 <code>ssthresh</code> 就会进入拥塞避免算法。</p><p>一般来说 <code>ssthresh</code> 的大小是 <code>65535</code> 字节。</p><p>那么进入拥塞避免算法后，它的规则是：<strong>每当收到一个 ACK 时，cwnd 增加 1&#x2F;cwnd。</strong></p><p>接上前面的慢启动的栗子，现假定 <code>ssthresh</code> 为 <code>8</code>：</p><ul><li>当 8 个 ACK 应答确认到来时，每个确认增加 1&#x2F;8，8 个 ACK 确认 cwnd 一共增加 1，于是这一次能够发送 9 个 <code>MSS</code> 大小的数据，变成了<strong>线性增长。</strong></li></ul><p>所以，我们可以发现，拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长，还是增长阶段，但是增长速度缓慢了一些。</p><p>就这么一直增长着后，网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传。</p><p>当触发了重传机制，也就进入了「拥塞发生算法」。</p><h3 id="拥塞发生"><a href="#拥塞发生" class="headerlink" title="#拥塞发生"></a><a href="https://xiaolincoding.com/network/3_tcp/tcp_feature.html#%E6%8B%A5%E5%A1%9E%E5%8F%91%E7%94%9F">#</a>拥塞发生</h3><p>当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：</p><ul><li>超时重传</li><li>快速重传</li></ul><p>这两种使用的拥塞发送算法是不同的，接下来分别来说说。</p><blockquote><p>发生超时重传的拥塞发生算法</p></blockquote><p>当发生了「超时重传」，则就会使用拥塞发生算法。</p><p>这个时候，ssthresh 和 cwnd 的值会发生变化：</p><ul><li><code>ssthresh</code> 设为 <code>cwnd/2</code>，</li><li><code>cwnd</code> 重置为 <code>1</code> （是恢复为 cwnd 初始化值，我这里假定 cwnd 初始化值 1）</li></ul><p><img src="/../imgs/20th-March/29.jpg" alt="拥塞发送 —— 超时重传"></p><p>接着，就重新开始慢启动，慢启动是会突然减少数据流的。这真是一旦「超时重传」，马上回到解放前。但是这种方式太激进了，反应也很强烈，会造成网络卡顿。</p><p>就好像本来在秋名山高速漂移着，突然来个紧急刹车，轮胎受得了吗。。。</p><blockquote><p>发生快速重传的拥塞发生算法</p></blockquote><p>还有更好的方式，前面我们讲过「快速重传算法」。当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。</p><p>TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 <code>ssthresh</code> 和 <code>cwnd</code> 变化如下：</p><ul><li><code>cwnd = cwnd/2</code> ，也就是设置为原来的一半;</li><li><code>ssthresh = cwnd</code>;</li><li>进入快速恢复算法</li></ul><h3 id="快速恢复"><a href="#快速恢复" class="headerlink" title="快速恢复"></a>快速恢复</h3><p>快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 <code>RTO</code> 超时那么强烈。</p><p>正如前面所说，进入快速恢复之前，<code>cwnd</code> 和 <code>ssthresh</code> 已被更新了：</p><ul><li><code>cwnd = cwnd/2</code> ，也就是设置为原来的一半;</li><li><code>ssthresh = cwnd</code>;</li></ul><p>然后，进入快速恢复算法如下：</p><ul><li>拥塞窗口 <code>cwnd = ssthresh + 3</code> （ 3 的意思是确认有 3 个数据包被收到了）；</li><li>重传丢失的数据包；</li><li>如果再收到重复的 ACK，那么 cwnd 增加 1；</li><li>如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态；</li></ul><p>快速恢复算法的变化过程如下图：</p><p><img src="/../imgs/20th-March/%E6%8B%A5%E5%A1%9E%E5%8F%91%E7%94%9F-%E5%BF%AB%E9%80%9F%E9%87%8D%E4%BC%A0.drawio.png" alt="快速重传和快速恢复"></p><h2 id="Mysql"><a href="#Mysql" class="headerlink" title="Mysql"></a>Mysql</h2><h3 id="事务有哪些特性？"><a href="#事务有哪些特性？" class="headerlink" title="事务有哪些特性？"></a>事务有哪些特性？</h3><p>事务是由MySQL的引擎来实现的，我们常见的InnoDB引擎它是支持事务的。</p><p>不过并不是所有的引擎都能支持事务，比如 MySQL 原生的 MyISAM 引擎就不支持事务，也正是这样，所以大多数 MySQL 的引擎都是用 InnoDB。</p><p>事务看起来感觉简单，但是要实现事务必须要遵守 4 个特性，分别如下：</p><ul><li><strong>原子性（Atomicity）：</strong>一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间的某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态。</li><li><strong>一致性（Consistency）：</strong>是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态。比如，用户 A 和用户 B 在银行分别有 800 元和 600 元，总共 1400 元，用户 A 给用户 B 转账 200 元，分为两个步骤，从 A 的账户扣除 200 元和对 B 的账户增加 200 元。一致性就是要求上述步骤操作后，最后的结果是用户 A 还有 600 元，用户 B 有 800 元，总共 1400 元，而不会出现用户 A 扣除了 200 元，但用户 B 未增加的情况（该情况，用户 A 和 B 均为 600 元，总共 1200 元）。</li><li><strong>隔离性（Isolation）</strong>：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致，因为多个事务同时使用相同的数据时，不会相互干扰，每个事务都有一个完整的数据空间，对其他并发事务是隔离的。也就是说，消费者购买商品这个事务，是不影响其他消费者购买的。</li><li><strong>持久性（Durability）</strong>：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。</li></ul><p>InnoDB 引擎通过什么技术来保证事务的这四个特性的呢？</p><ul><li>持久性是通过 redo log （重做日志）来保证的；</li><li>原子性是通过 undo log（回滚日志） 来保证的；</li><li>隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的；</li><li>一致性则是通过持久性+原子性+隔离性来保证；</li></ul><h2 id="并行事务会引发什么问题？"><a href="#并行事务会引发什么问题？" class="headerlink" title="并行事务会引发什么问题？"></a>并行事务会引发什么问题？</h2><p>MySQL 服务端是允许多个客户端连接的，这意味着 MySQL 会出现同时处理多个事务的情况。</p><p>那么<strong>在同时处理多个事务的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题</strong>。</p><p>接下来，通过举例子给大家说明，这些问题是如何发生的。</p><h3 id="脏读"><a href="#脏读" class="headerlink" title="#脏读"></a><a href="https://xiaolincoding.com/mysql/transaction/mvcc.html#%E8%84%8F%E8%AF%BB">#</a>脏读</h3><p><strong>如果一个事务「读到」了另一个「未提交事务修改过的数据」，就意味着发生了「脏读」现象。</strong></p><p>假设有 A 和 B 这两个事务同时在处理，事务 A 先开始从数据库中读取小林的余额数据，然后再执行更新操作，如果此时事务 A 还没有提交事务，而此时正好事务 B 也从数据库中读取小林的余额数据，那么事务 B 读取到的余额数据是刚才事务 A 更新后的数据，即使没有提交事务。</p><p>因为事务 A 是还没提交事务的，也就是它随时可能发生回滚操作，<strong>如果在上面这种情况事务 A 发生了回滚，那么事务 B 刚才得到的数据就是过期的数据，这种现象就被称为脏读。</strong></p><h3 id="不可重复读"><a href="#不可重复读" class="headerlink" title="不可重复读"></a>不可重复读</h3><p><strong>在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了「不可重复读」现象。</strong></p><p>假设有 A 和 B 这两个事务同时在处理，事务 A 先开始从数据库中读取小林的余额数据，然后继续执行代码逻辑处理，<strong>在这过程中如果事务 B 更新了这条数据，并提交了事务，那么当事务 A 再次读取该数据时，就会发现前后两次读到的数据是不一致的，这种现象就被称为不可重复读。</strong></p><h3 id="幻读"><a href="#幻读" class="headerlink" title="幻读"></a>幻读</h3><p>在一个事务内多次查询某个符合查询条件的记录数量，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了幻读现象。</p><p>假设有 A 和 B 这两个事务同时在处理，事务 A 先开始从数据库查询账户余额大于 100 万的记录，发现共有 5 条，然后事务 B 也按相同的搜索条件也是查询出了 5 条记录。</p><p>接下来，事务 A 插入了一条余额超过 100 万的账号，并提交了事务，此时数据库超过 100 万余额的账号个数就变为 6。</p><p>然后事务 B 再次查询账户余额大于 100 万的记录，此时查询到的记录数量有 6 条，<strong>发现和前一次读到的记录数量不一样了，就感觉发生了幻觉一样，这种现象就被称为幻读。</strong></p><h2 id="事务的隔离级别有哪些？"><a href="#事务的隔离级别有哪些？" class="headerlink" title="事务的隔离级别有哪些？"></a>事务的隔离级别有哪些？</h2><p>前面我们提到，当多个事务并发执行时可能会遇到「脏读、不可重复读、幻读」的现象，这些现象会对事务的一致性产生不同程序的影响。</p><ul><li>脏读：读到其他事务未提交的数据；</li><li>不可重复读：前后读取的数据不一致；</li><li>幻读：前后读取的记录数量不一致。</li></ul><p>SQL 标准提出了四种隔离级别来规避这些现象，隔离级别越高，性能效率就越低，这四个隔离级别如下：</p><ul><li><strong>读未提交（*read uncommitted*）</strong>，指一个事务还没提交时，它做的变更就能被其他事务看到；</li><li><strong>读提交（*read committed*）</strong>，指一个事务提交之后，它做的变更才能被其他事务看到；</li><li><strong>可重复读（*repeatable read*）</strong>，指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，<strong>MySQL InnoDB 引擎的默认隔离级别</strong>；</li><li><strong>串行化（*serializable* ）</strong>；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；</li></ul><p>针对不同的隔离级别，并发事务时可能发生的现象也会不同。</p><ul><li>在「读未提交」隔离级别下，可能发生脏读、不可重复读和幻读现象；</li><li>在「读提交」隔离级别下，可能发生不可重复读和幻读现象，但是不可能发生脏读现象；</li><li>在「可重复读」隔离级别下，可能发生幻读现象，但是不可能脏读和不可重复读现象；</li><li>在「串行化」隔离级别下，脏读、不可重复读和幻读现象都不可能会发生。</li></ul><p>MySQL InnoDB 引擎的默认隔离级别虽然是「可重复读」，但是它很大程度上避免幻读现象（并不是完全解决了）解决的方案有两种：</p><ul><li>针对<strong>快照读</strong>（普通 select 语句），是<strong>通过 MVCC 方式解决了幻读</strong>，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。</li><li>针对<strong>当前读</strong>（select … for update 等语句），是<strong>通过 next-key lock（记录锁+间隙锁）方式解决了幻读</strong>，因为当执行 select … for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。</li></ul><h2 id="Read-View-在-MVCC-里如何工作的？"><a href="#Read-View-在-MVCC-里如何工作的？" class="headerlink" title="Read View 在 MVCC 里如何工作的？"></a>Read View 在 MVCC 里如何工作的？</h2><p>我们需要了解两个知识：</p><ul><li>Read View 中四个字段作用；</li><li>聚簇索引记录中两个跟事务有关的隐藏列；</li></ul><p>那 Read View 到底是个什么东西？</p><p><img src="/../imgs/20th-March/readview%E7%BB%93%E6%9E%84.drawio.png" alt="mvcc"></p><p>Read View 有四个重要的字段：</p><ul><li>m_ids ：指的是在创建 Read View 时，当前数据库中「活跃事务」的<strong>事务 id 列表</strong>，注意是一个列表，<strong>“活跃事务”指的就是，启动了但还没提交的事务</strong>。</li><li>min_trx_id ：指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 <strong>id 最小的事务</strong>，也就是 m_ids 的最小值。</li><li>max_trx_id ：这个并不是 m_ids 的最大值，而是<strong>创建 Read View 时当前数据库中应该给下一个事务的 id 值</strong>，也就是全局事务中最大的事务 id 值 + 1；</li><li>creator_trx_id ：指的是<strong>创建该 Read View 的事务的事务 id</strong>。</li></ul><p>知道了 Read View 的字段，我们还需要了解聚簇索引记录中的两个隐藏列。</p><p><img src="/../imgs/20th-March/f595d13450878acd04affa82731f76c5.png" alt="隐藏列"></p><p>对于使用 InnoDB 存储引擎的数据库表，它的聚簇索引记录中都包含下面两个隐藏列：</p><ul><li>trx_id，当一个事务对某条聚簇索引记录进行改动时，就会<strong>把该事务的事务 id 记录在 trx_id 隐藏列里</strong>；</li><li>roll_pointer，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后<strong>这个隐藏列是个指针，指向每一个旧版本记录</strong>，于是就可以通过它找到修改前的记录。</li></ul><p>在创建 Read View 后，我们可以将记录中的 trx_id 划分这三种情况：</p><p><img src="/../imgs/20th-March/ReadView.drawio.png" alt="trx_id"></p><p>一个事务去访问记录的时候，除了自己的更新记录总是可见之外，还有这几种情况：</p><ul><li>如果记录的 trx_id 值小于 Read View 中的 <code>min_trx_id</code> 值，表示这个版本的记录是在创建 Read View <strong>前</strong>已经提交的事务生成的，所以该版本的记录对当前事务<strong>可见</strong>。</li><li>如果记录的 trx_id 值大于等于 Read View 中的 <code>max_trx_id</code> 值，表示这个版本的记录是在创建 Read View <strong>后</strong>才启动的事务生成的，所以该版本的记录对当前事务<strong>不可见</strong>。</li><li>如果记录的 trx_id 值在 Read View 的<code>min_trx_id</code>和<code>max_trx_id</code>之间，需要判断 <code>trx_id</code> 是否在 m_ids 列表中：<ul><li>如果记录的 trx_id <strong>在</strong> <code>m_ids</code> 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务<strong>不可见</strong>。</li><li>如果记录的 trx_id <strong>不在</strong> <code>m_ids</code>列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务<strong>可见</strong>。</li></ul></li></ul><p><strong>这种通过「版本链」来控制并发事务访问同一个记录时的行为就叫 MVCC（多版本并发控制）。</strong></p><h2 id="可重复读是如何工作的？"><a href="#可重复读是如何工作的？" class="headerlink" title="可重复读是如何工作的？"></a>可重复读是如何工作的？</h2><p><strong>可重复读隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View</strong>。</p><p>假设事务 A （事务 id 为51）启动后，紧接着事务 B （事务 id 为52）也启动了，那这两个事务创建的 Read View 如下：</p><p><img src="/../imgs/20th-March/%E4%BA%8B%E5%8A%A1ab%E7%9A%84%E8%A7%86%E5%9B%BE-new.png" alt="可重复读ReadView"></p><p>事务 A 和 事务 B 的 Read View 具体内容如下：</p><ul><li>在事务 A 的 Read View 中，它的事务 id 是 51，由于它是第一个启动的事务，所以此时活跃事务的事务 id 列表就只有 51，活跃事务的事务 id 列表中最小的事务 id 是事务 A 本身，下一个事务 id 则是 52。</li><li>在事务 B 的 Read View 中，它的事务 id 是 52，由于事务 A 是活跃的，所以此时活跃事务的事务 id 列表是 51 和 52，<strong>活跃的事务 id 中最小的事务 id 是事务 A</strong>，下一个事务 id 应该是 53。</li></ul><p>接着，在可重复读隔离级别下，事务 A 和事务 B 按顺序执行了以下操作：</p><ul><li>事务 B 读取小林的账户余额记录，读到余额是 100 万；</li><li>事务 A 将小林的账户余额记录修改成 200 万，并没有提交事务；</li><li>事务 B 读取小林的账户余额记录，读到余额还是 100 万；</li><li>事务 A 提交事务；</li><li>事务 B 读取小林的账户余额记录，读到余额依然还是 100 万；</li></ul><p>事务 B 第一次读小林的账户余额记录，在找到记录后，它会先看这条记录的 trx_id，此时<strong>发现 trx_id 为 50，比事务 B 的 Read View 中的 min_trx_id 值（51）还小，这意味着修改这条记录的事务早就在事务 B 启动前提交过了，所以该版本的记录对事务 B 可见的</strong>，也就是事务 B 可以获取到这条记录。</p><p>接着，事务 A 通过 update 语句将这条记录修改了（还未提交事务），将小林的余额改成 200 万，这时 MySQL 会记录相应的 undo log，并以链表的方式串联起来，形成<strong>版本链</strong>，如下图：</p><p><img src="/../imgs/20th-March/%E4%BA%8B%E5%8A%A1ab%E7%9A%84%E8%A7%86%E5%9B%BE2.png" alt="版本链"></p><p>你可以在上图的「记录的字段」看到，由于事务 A 修改了该记录，以前的记录就变成旧版本记录了，于是最新记录和旧版本记录通过链表的方式串起来，而且最新记录的 trx_id 是事务 A 的事务 id（trx_id &#x3D; 51）。</p><p>然后事务 B 第二次去读取该记录，<strong>发现这条记录的 trx_id 值为 51，在事务 B 的 Read View 的 min_trx_id 和 max_trx_id 之间，则需要判断 trx_id 值是否在 m_ids 范围内，判断的结果是在的，那么说明这条记录是被还未提交的事务修改的，这时事务 B 并不会读取这个版本的记录。而是沿着 undo log 链条往下找旧版本的记录，直到找到 trx_id 「小于」事务 B 的 Read View 中的 min_trx_id 值的第一条记录</strong>，所以事务 B 能读取到的是 trx_id 为 50 的记录，也就是小林余额是 100 万的这条记录。</p><p>最后，当事物 A 提交事务后，<strong>由于隔离级别时「可重复读」，所以事务 B 再次读取记录时，还是基于启动事务时创建的 Read View 来判断当前版本的记录是否可见。所以，即使事物 A 将小林余额修改为 200 万并提交了事务， 事务 B 第三次读取记录时，读到的记录都是小林余额是 100 万的这条记录</strong>。</p><h2 id="读提交是如何工作的？"><a href="#读提交是如何工作的？" class="headerlink" title="读提交是如何工作的？"></a>读提交是如何工作的？</h2><p><strong>读提交隔离级别是在每次读取数据时，都会生成一个新的 Read View</strong>。</p><p>也意味着，事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致，因为可能这期间另外一个事务修改了该记录，并提交了事务。</p><p>那读提交隔离级别是怎么工作呢？我们还是以前面的例子来聊聊。</p><p>假设事务 A （事务 id 为51）启动后，紧接着事务 B （事务 id 为52）也启动了，接着按顺序执行了以下操作：</p><ul><li>事务 B 读取数据（创建 Read View），小林的账户余额为 100 万；</li><li>事务 A 修改数据（还没提交事务），将小林的账户余额从 100 万修改成了 200 万；</li><li>事务 B 读取数据（创建 Read View），小林的账户余额为 100 万；</li><li>事务 A 提交事务；</li><li>事务 B 读取数据（创建 Read View），小林的账户余额为 200 万；</li></ul><h2 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h2><h2 id="quicklist"><a href="#quicklist" class="headerlink" title="quicklist"></a>quicklist</h2><p>在 Redis 3.0 之前，List 对象的底层数据结构是双向链表或者压缩列表。然后在 Redis 3.2 的时候，List 对象的底层改由 quicklist 数据结构实现。</p><p>其实 quicklist 就是「双向链表 + 压缩列表」组合，因为一个 quicklist 就是一个链表，而链表中的每个元素又是一个压缩列表。</p><p>在前面讲压缩列表的时候，我也提到了压缩列表的不足，虽然压缩列表是通过紧凑型的内存布局节省了内存开销，但是因为它的结构设计，如果保存的元素数量增加，或者元素变大了，压缩列表会有「连锁更新」的风险，一旦发生，会造成性能下降。</p><p>quicklist 解决办法，<strong>通过控制每个链表节点中的压缩列表的大小或者元素个数，来规避连锁更新的问题。因为压缩列表元素越少或越小，连锁更新带来的影响就越小，从而提供了更好的访问性能。</strong></p><h3 id="quicklist-结构设计"><a href="#quicklist-结构设计" class="headerlink" title="#quicklist 结构设计"></a><a href="https://xiaolincoding.com/redis/data_struct/data_struct.html#quicklist-%E7%BB%93%E6%9E%84%E8%AE%BE%E8%AE%A1">#</a>quicklist 结构设计</h3><p>quicklist 的结构体跟链表的结构体类似，都包含了表头和表尾，区别在于 quicklist 的节点是 quicklistNode。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">quicklist</span> &#123;</span><br>    <span class="hljs-comment">//quicklist的链表头</span><br>    quicklistNode *head;      <span class="hljs-comment">//quicklist的链表头</span><br>    <span class="hljs-comment">//quicklist的链表尾</span><br>    quicklistNode *tail; <br>    <span class="hljs-comment">//所有压缩列表中的总元素个数</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> count;<br>    <span class="hljs-comment">//quicklistNodes的个数</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> len;       <br>    ...<br>&#125; quicklist;<br></code></pre></td></tr></table></figure><p>接下来看看，quicklistNode 的结构定义：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">quicklistNode</span> &#123;</span><br>    <span class="hljs-comment">//前一个quicklistNode</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">quicklistNode</span> *<span class="hljs-title">prev</span>;</span>     <span class="hljs-comment">//前一个quicklistNode</span><br>    <span class="hljs-comment">//下一个quicklistNode</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">quicklistNode</span> *<span class="hljs-title">next</span>;</span>     <span class="hljs-comment">//后一个quicklistNode</span><br>    <span class="hljs-comment">//quicklistNode指向的压缩列表</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> *zl;              <br>    <span class="hljs-comment">//压缩列表的的字节大小</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> sz;                <br>    <span class="hljs-comment">//压缩列表的元素个数</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> count : <span class="hljs-number">16</span>;        <span class="hljs-comment">//ziplist中的元素个数 </span><br>    ....<br>&#125; quicklistNode;<br></code></pre></td></tr></table></figure><p>可以看到，quicklistNode 结构体里包含了前一个节点和下一个节点指针，这样每个 quicklistNode 形成了一个双向链表。但是链表节点的元素不再是单纯保存元素值，而是保存了一个压缩列表，所以 quicklistNode 结构体里有个指向压缩列表的指针 *zl。</p><p><img src="/../imgs/20th-March/f46cbe347f65ded522f1cc3fd8dba549.png" alt="quicklist"></p><p>在向 quicklist 添加一个元素的时候，不会像普通的链表那样，直接新建一个链表节点。而是会检查插入位置的压缩列表是否能容纳该元素，如果能容纳就直接保存到 quicklistNode 结构里的压缩列表，如果不能容纳，才会新建一个新的 quicklistNode 结构。</p><p>quicklist 会控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来规避潜在的连锁更新的风险，但是这并没有完全解决连锁更新的问题。</p><h2 id="listpack"><a href="#listpack" class="headerlink" title="listpack"></a>listpack</h2><p>quicklist 虽然通过控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来减少连锁更新带来的性能影响，但是并没有完全解决连锁更新的问题。</p><p>因为 quicklistNode 还是用了压缩列表来保存元素，压缩列表连锁更新的问题，来源于它的结构设计，所以要想彻底解决这个问题，需要设计一个新的数据结构。</p><p>于是，Redis 在 5.0 新设计一个数据结构叫 listpack，目的是替代压缩列表，它最大特点是 listpack 中每个节点不再包含前一个节点的长度了，压缩列表每个节点正因为需要保存前一个节点的长度字段，就会有连锁更新的隐患。</p><p><strong>我看了 Redis 的 Github，在最新 6.2 发行版本中，Redis Hash 对象、ZSet 对象的底层数据结构的压缩列表还未被替换成 listpack，而 Redis 的最新代码（还未发布版本）已经将所有用到压缩列表底层数据结构的 Redis 对象替换成 listpack 数据结构来实现，估计不久将来，Redis 就会发布一个将压缩列表为 listpack 的发行版本</strong>。</p><h3 id="listpack-结构设计"><a href="#listpack-结构设计" class="headerlink" title="#listpack 结构设计"></a><a href="https://xiaolincoding.com/redis/data_struct/data_struct.html#listpack-%E7%BB%93%E6%9E%84%E8%AE%BE%E8%AE%A1">#</a>listpack 结构设计</h3><p>listpack 采用了压缩列表的很多优秀的设计，比如还是用一块连续的内存空间来紧凑地保存数据，并且为了节省内存的开销，listpack 节点会采用不同的编码方式保存不同大小的数据。</p><p>我们先看看 listpack 结构：</p><p><img src="/../imgs/20th-March/4d2dc376b5fd68dae70d9284ae82b73a.png" alt="listpack结构"></p><p>listpack 头包含两个属性，分别记录了 listpack 总字节数和元素数量，然后 listpack 末尾也有个结尾标识。图中的 listpack entry 就是 listpack 的节点了。</p><p>每个 listpack 节点结构如下：</p><p><img src="/../imgs/20th-March/c5fb0a602d4caaca37ff0357f05b0abf.png" alt="listpack entry"></p><p>主要包含三个方面内容：</p><ul><li>encoding，定义该元素的编码类型，会对不同长度的整数和字符串进行编码；</li><li>data，实际存放的数据；</li><li>len，encoding+data的总长度；</li></ul><p>可以看到，<strong>listpack 没有压缩列表中记录前一个节点长度的字段了，listpack 只记录当前节点的长度，当我们向 listpack 加入一个新元素的时候，不会影响其他节点的长度字段的变化，从而避免了压缩列表的连锁更新问题</strong>。</p><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p><a href="https://www.nowcoder.com/practice/886370fe658f41b498d40fb34ae76ff9?tpId=295&tqId=1377477&ru=/exam/company&qru=/ta/format-top101/question-ranking&sourceUrl=/exam/company"><strong>链表中倒数最后k个结点</strong></a></p><p><img src="/../imgs/20th-March/image-20240320214547723.png" alt="链表中倒数最后k个节点"></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs C++"><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">ListNode</span> &#123;<br> *<span class="hljs-type">int</span> val;<br> *<span class="hljs-keyword">struct</span> <span class="hljs-title class_">ListNode</span> *next;<br> *<span class="hljs-built_in">ListNode</span>(<span class="hljs-type">int</span> x) : <span class="hljs-built_in">val</span>(x), <span class="hljs-built_in">next</span>(<span class="hljs-literal">nullptr</span>) &#123;&#125;<br>&#125;;<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 代码中的类名、方法名、参数名已经指定，请勿修改，直接返回方法规定的值即可</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * </span><br><span class="hljs-comment">     * @param pHead ListNode类 </span><br><span class="hljs-comment">     * @param k int整型 </span><br><span class="hljs-comment">     * @return ListNode类</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-function">ListNode* <span class="hljs-title">FindKthToTail</span><span class="hljs-params">(ListNode* pHead, <span class="hljs-type">int</span> k)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span>(pHead == <span class="hljs-literal">nullptr</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">nullptr</span>;<br>        ListNode* fast = pHead,*slow = pHead;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; k; i++) &#123;<br>            fast = fast-&gt;next;<br>            <span class="hljs-keyword">if</span>(fast == <span class="hljs-literal">nullptr</span>&amp;&amp;i!=k<span class="hljs-number">-1</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">nullptr</span>;<br>        &#125;<br>        <span class="hljs-keyword">while</span>(fast) &#123;<br>            fast = fast-&gt;next;<br>            slow = slow-&gt;next;<br>        &#125;<br>        <span class="hljs-keyword">return</span> slow;<br>    &#125;<br>&#125;;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-type">int</span> n;<br>    cin&gt;&gt;n;<br>    ListNode* dummyhead = <span class="hljs-keyword">new</span> <span class="hljs-built_in">ListNode</span>(<span class="hljs-number">-1</span>);<br>    ListNode* curr = dummyhead;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i++) &#123;<br>        <span class="hljs-type">int</span> x;<br>        cin&gt;&gt;x;<br>        curr-&gt;next = <span class="hljs-keyword">new</span> <span class="hljs-built_in">ListNode</span>(x);<br>      curr = curr-&gt;next;<br>    &#125;<br>    Solution sol1;<br>    <span class="hljs-type">int</span> k;<br>    cin&gt;&gt;k;<br>    ListNode* ans = sol.<span class="hljs-built_in">FindKthToTail</span>(dummyhead-&gt;next,k);<br>    <span class="hljs-keyword">while</span>(ans) &#123;<br>        cout&lt;&lt;ans-&gt;val&lt;&lt;<span class="hljs-string">&quot; &quot;</span>;<br>      ans = ans-&gt;next;<br>    &#125;<br>    cout&lt;&lt;<span class="hljs-string">&#x27;\n&#x27;</span>;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>今天感觉体验还不错 但是不知道过没过 不过过了也得考虑去不去吧</p><p>周五字节 先抠八股和算法 周一美团 重点sql和算法 周二快手 重点看看824</p>]]></content>
    
    
    <categories>
      
      <category>八股</category>
      
    </categories>
    
    
    <tags>
      
      <tag>diary</tag>
      
      <tag>八股</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>19th-March</title>
    <link href="/2024/03/19/19th-March/"/>
    <url>/2024/03/19/19th-March/</url>
    
    <content type="html"><![CDATA[<h1 id="面经"><a href="#面经" class="headerlink" title="面经"></a>面经</h1><p>刚好都是字节国际电商？ 估计问的就差不多，所以偷一下看看</p><h2 id="OS"><a href="#OS" class="headerlink" title="OS"></a>OS</h2><h3 id="虚拟内存相关"><a href="#虚拟内存相关" class="headerlink" title="虚拟内存相关"></a>虚拟内存相关</h3><h4 id="内存虚拟化是什么，有什么目的？"><a href="#内存虚拟化是什么，有什么目的？" class="headerlink" title="内存虚拟化是什么，有什么目的？"></a>内存虚拟化是什么，有什么目的？</h4><p>内存虚拟化是一种将物理内存资源抽象、管理和分配的技术。它允许将计算机的物理内存划分为独立的、隔离的虚拟内存块，每个虚拟内存块都有操作系统或虚拟机管理。内存虚拟化可以在多个层次实现，如硬件层、操作系统层或应用程序层。</p><p>目的：</p><ul><li><strong>资源隔离与共享：</strong>内存虚拟化可以在不同的进程、应用程序或虚拟机之间隔离内存资源，从而提高系统的稳定性和安全性。同时，内存虚拟化还支持灵活地共享内存资源，以实现负载均衡和资源利用率最大化。</li><li><strong>易用性：</strong>内存虚拟化简化了内存管理，使得程序员无需关注物理内存的具体细节。程序员可以专注于编写代码，而操作系统和硬件负责处理内存分配、回收等问题。</li><li><strong>容错和回复：</strong>内存虚拟化有助于实现容错和故障恢复。当系统发生故障时，可以将虚拟内存的状态保存到磁盘上，然后再另一台计算机上恢复虚拟内存状态，以实现快速恢复（没太懂？）</li><li><strong>内存优化：</strong>内存虚拟化支持一些内存优化技术，如按需分配、内存去重和内存压缩。这些技术可以提高内存资源的利用率，降低内存成本。</li><li><strong>进程保护：</strong>每个进程都有自己的虚拟地址空间，这样就能防止一个进程意外或恶意的访问另一个进程的内存。提高系统的稳定性和安全性。</li></ul><h4 id="物理内存与虚拟内存的映射机制"><a href="#物理内存与虚拟内存的映射机制" class="headerlink" title="物理内存与虚拟内存的映射机制"></a>物理内存与虚拟内存的映射机制</h4><p>物理内存和虚拟内存的映射机制是计算机系统中实现内存虚拟化的关键技术。虚拟内存到物理内存的映射方式一般有分段和分页两种，由于分段机制内存碎片较多，常用的是分页机制。映射过程有内存管理单元（MMU）和操作系统共同完成。</p><ul><li><p><strong>分页机制：</strong>在分页系统中，虚拟内存和物理内存都被划分为固定大小的单元，称为页。虚拟页的大小和物理页相同，通常为4KB或更大。分页系统的主要目的是将虚拟内存中的页映射到物理内存中的页。</p></li><li><p><strong>页表：</strong>页表是一种数据结构，用于存储虚拟页到物理页的映射关系。每个进程都有自己的页表，由操作系统管理。页表中的每个条目包含一个虚拟页号和对应的物理页号。当CPU访问虚拟内存时，MMU会使用页表将虚拟地址转换为物理地址。</p></li><li><p><strong>地址转换：</strong>虚拟地址通常由两部分组成：虚拟页号（VPN）和页内偏移（offset）。虚拟页号用于查找页表中相应的物理页号，而页内偏移表示在物理页中的具体位置。地址抓换过程如下：</p><ol><li>CPU生成一个虚拟地址</li><li>MMU从虚拟地址中提取虚拟页号和页内偏移</li><li>MMU使用VPN在页表中查找对应的物理页号（PPN）</li><li>MMU将物理页号与页内偏移组合成物理地址</li><li>CPU使用物理地址访问物理内存</li></ol></li><li><p>页面置换和缺页中断：当虚拟页尚未加载到物理内存时，发生页面缺失（page fault）。在这种情况下，操作系统需要从磁盘或其他存储设备中加载所需的虚拟页，并将其映射到物理内存。为了腾出空间，操作系统可能需要选择一个已加载的页面，将其换出到磁盘。页面置换算法用于决定哪个页面应该被换出</p></li><li><p>多级页表：多级页表使一种用于减少页表大小的技术。在具有大量虚拟地址空间的系统中，使用单级页表可能导致浪费大量内存。多级页表通过将虚拟地址空间划分为多个层次来减小页表的大小。每个层次都有自己的页表，只有在需要时才会分配。这样可以大大减小内存开销。</p></li><li><p>快表（TLB）：快表，也称为转换后援缓冲（Translation Lookaside Buffer），是一种硬件缓存，用于加速虚拟地址到物理地址的转换过程。TLB将最近使用过的虚拟地址到物理地址的映射存储在高速缓存中，以便快速查找。当MMU需要转换一个虚拟地址时，它首先检查TLB是否包含所需的映射。如何TLB中存在映射，MMU可以避免访问内存中的页表，从而加速地址转换过程。</p></li><li><p>内存分配策略：操作系统使用不同的内存分配策略来管理虚拟内存和物理内存之间的映射。按需分配是一种常用的策略，它旨在进程实际访问虚拟内存时才将虚拟页加载到物理内存。预取是另一种策略，它根据进程的访问模式提前加载可能需要的虚拟页，以减少页面缺失的开销。</p></li><li><p>内存共享：内存共享是一种允许多个进程访问相同物理内存区域的技术。通过将不同 进程的虚拟地址映射到同一物理页，操作系统可以实现内存共享。这种技术在共享库、进程间通信和内存去重等场景中非常有用。</p></li></ul><p>物理内存和虚拟内存的映射机制通过分页、页表、地址转换、多级页表、TLB、内存分配策略等技术实现。这种映射提供了内存虚拟化、进程隔离和内存优化等关键功能。</p><h3 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h3><h4 id="进程、线程、协程区别与联系"><a href="#进程、线程、协程区别与联系" class="headerlink" title="进程、线程、协程区别与联系"></a>进程、线程、协程区别与联系</h4><p>进程、线程和协程是计算机程序执行的三个不同层次</p><p><strong>进程：</strong>进程是操作系统进行资源分配和调度的基本单位，是一个独立运行的程序实体。每个进程拥有独立的内存空间、文件描述符、寄存器状态等资源。进程之间的资源是相互隔离的，因此进程间通信需要通过操作系统提供的特定机制（如管道、消息队列、共享内存等）进行。由于进程拥有独立的资源，所以进程间的切换调度开销较大</p><p><strong>线程：</strong>线程是操作系统调度执行的最小单位，是进程内的一个执行流。一个进程可以拥有多个线程，这些线程共享进程的资源（如内存空间、文件描述符等）。由于线程共享相同的资源，线程间通信相对简单，可以直接通过共享变量、锁等方式进行。线程相较于进程，上下文切换和调度开销较小。但多个线程并行执行时，需要处理好同步和互斥问题，以避免数据不一致或竞争条件。</p><p><strong>协程：</strong>协程是一种用户态的轻量级线程，它的调度和切换完全由程序控制，不依赖于操作系统的调度。协程之间共享线程的资源，因此协程间通信也可以通过共享变量、锁等方式进行。协程的优势在于可以轻松地实现高并发，因此协程切换和调度的开销非常小。协程适用于I&#x2F;O密集型任务，通过异步I&#x2F;O可以有效地提高程序的性能。</p><p><strong>联系</strong></p><ul><li>线程属于进程，多个线程共享进程的资源，一个进程可以包含多个线程，这些线程共同完成任务，提高程序的并发性。</li><li>协程属于线程，多个协程共享线程的资源。一个线程可以包含多个协程，这些协程共同完成任务，提高程序的并发性。</li><li>进程、线程和协程在执行程序时，都需要面对异步、互斥和通信等问题。在实际应用中，可以根据需求和场景选择合适的执行实体来实现最优的性能和资源利用。</li></ul><h2 id="计网"><a href="#计网" class="headerlink" title="计网"></a>计网</h2><h3 id="TCP的确认机制"><a href="#TCP的确认机制" class="headerlink" title="TCP的确认机制"></a>TCP的确认机制</h3><p>1.确认的作用</p><p>TCP的确认机制用于确保数据的可靠传输。当接收端成功接收到一个数据包时，它会返回一个确认信号（ACK）给发送端。这个确认信号包含了接收端期望接受的下一个数据包的序号。发送端收到确认信号后，就知道之前发送的数据包已经被成功接收，并可以继续发送后续的数据包。</p><p>2.确认的实现方式</p><p>确认信号是通过TCP数据包中的ACK标志位来实现。当ACK标志位被设置为1时，表示该数据包时一个确认信号。确认信号中还包含一个32位的确认号字段，用于指示接收端期望接受的下一个数据包的序号。</p><h3 id="TCP流量控制"><a href="#TCP流量控制" class="headerlink" title="TCP流量控制"></a>TCP流量控制</h3><p>发送方不能无脑的发数据给接收方，要考虑接收方处理能力。</p><p>如果一直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。</p><p>为了解决这种现象发生，TCP提供了一种机制可以让发送放根据接收方的实际接受能力控制发送的数据量，这就是所谓的流量控制。</p><p><img src="/../imgs/19th-March/21.png" alt="流量控制"></p><ol><li>客户端向服务端发送请求数据报文。</li><li>服务端收到请求报文后，发送确认报文和80字节的数据，于是可用窗口 <code>Usable</code> 减少为 120 字节，同时<code>SND.NXT</code>指针页向右偏移80字节，这意味着下次发送数据的时候，序列号时321.</li><li>客户端收到80字节数据后，于是接收窗口往右移动80字节，<code>RCV.NXT</code>也就指向321，这意味着客户端期望的下一个报文的序列号时321，接着发送确认报文给服务端。</li><li>服务端再次发送了120字节数据，于是可用窗口耗尽为0，服务端无法再继续发送数据。</li><li>客户端收到120字节的数据后，于是接收窗口往右移动 120 字节，<code>RCV.NXT</code> 也就指向 441，接着发送确认报文给服务端。</li><li>服务端收到对 80 字节数据的确认报文后，<code>SND.UNA</code> 指针往右偏移后指向 321，于是可用窗口 <code>Usable</code> 增大到 80。</li><li>服务端收到对 120 字节数据的确认报文后，<code>SND.UNA</code> 指针往右偏移后指向 441，于是可用窗口 <code>Usable</code> 增大到 200。</li><li>服务端可以继续发送了，于是发送了 160 字节的数据后，<code>SND.NXT</code> 指向 601，于是可用窗口 <code>Usable</code> 减少到 40。</li><li>客户端收到 160 字节后，接收窗口往右移动了 160 字节，<code>RCV.NXT</code> 也就是指向了 601，接着发送确认报文给服务端。</li><li>服务端收到对 160 字节数据的确认报文后，发送窗口往右移动了 160 字节，于是 <code>SND.UNA</code> 指针偏移了 160 后指向 601，可用窗口 <code>Usable</code> 也就增大至了 200。</li></ol><h3 id="HTTPS是如何建立连接的？"><a href="#HTTPS是如何建立连接的？" class="headerlink" title="HTTPS是如何建立连接的？"></a>HTTPS是如何建立连接的？</h3><p>1.ClientHello</p><p>首先由客户端向服务器发起加密通信请求，也就是CLientHello请求。</p><p>在这一步，客户端主要向服务器发送以下信息：</p><ul><li>客户端支持的TLS协议版本</li><li>客户端产生的随机数，后面用于生成会话密钥条件之一</li><li>客户端支持的密码套件列表</li></ul><p>2。ServerHello</p><p>服务器收到客户端请求后，向客户端发出相应，主要内容</p><ul><li>确认TLS协议版本，如果浏览器不支持，则关闭加密通信</li><li>服务器生产的随机数，也就是后面用于生成会话密钥的条件之一</li><li>确认的密码套件列表</li><li>服务器的数字证书</li></ul><p>3.客户端回应</p><p>客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的CA公钥，确认服务器的数字证书的真实性。</p><p>如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使用它加密报文，向服务器发送如下信息：</p><ul><li>一个随机数，会被服务器公钥加密</li><li>加密通信算法改变通知，表示随后信息都将用会话密钥加密通信</li><li>客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。</li></ul><p>上面第一项的随机数是整个握手阶段的第三个随机数，会发给服务端，所以这个随机数客户端和服务端都是一样的。</p><p>服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」。</p><p>4.服务器的最后回应</p><p>服务器收到客户端的第三个随机数（<code>pre-master key</code>）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。</p><p>然后，向客户端发送最后的信息：</p><p>（1）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。</p><p>（2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。</p><p>至此，整个 TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。</p><h2 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h2><h3 id="zset底层原理"><a href="#zset底层原理" class="headerlink" title="zset底层原理"></a>zset底层原理</h3><p>Zset 类型的底层数据结构是由<strong>压缩列表或跳表</strong>实现的：</p><ul><li>如果有序集合的元素个数小于 <code>128</code> 个，并且每个元素的值小于 <code>64</code> 字节时，Redis 会使用<strong>压缩列表</strong>作为 Zset 类型的底层数据结构；</li><li>如果有序集合的元素不满足上面的条件，Redis 会使用<strong>跳表</strong>作为 Zset 类型的底层数据结构；</li></ul><p><strong>在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。</strong></p><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p><a href="https://leetcode.cn/problems/copy-list-with-random-pointer/">138. 随机链表的复制</a></p><p><img src="/../imgs/19th-March/image-20240320000304343.png" alt="随机链表的复制"></p><p>哈希表实现：</p><p>用哈希表存储每个链表节点 然后再串联next和random</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">/*</span><br><span class="hljs-comment">// Definition for a Node.</span><br><span class="hljs-comment">class Node &#123;</span><br><span class="hljs-comment">public:</span><br><span class="hljs-comment">    int val;</span><br><span class="hljs-comment">    Node* next;</span><br><span class="hljs-comment">    Node* random;</span><br><span class="hljs-comment">    </span><br><span class="hljs-comment">    Node(int _val) &#123;</span><br><span class="hljs-comment">        val = _val;</span><br><span class="hljs-comment">        next = NULL;</span><br><span class="hljs-comment">        random = NULL;</span><br><span class="hljs-comment">    &#125;</span><br><span class="hljs-comment">&#125;;</span><br><span class="hljs-comment">*/</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">Node* <span class="hljs-title">copyRandomList</span><span class="hljs-params">(Node* head)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span>(head == <span class="hljs-literal">nullptr</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">nullptr</span>;<br>        Node* cur = head;<br>        unordered_map&lt;Node*,Node*&gt; map;<br>        <span class="hljs-keyword">while</span>(cur != <span class="hljs-literal">nullptr</span>)&#123;<br>            map[cur] = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Node</span>(cur-&gt;val);<br>            cur = cur-&gt;next;<br>        &#125;<br>        cur = head;<br>        <span class="hljs-keyword">while</span>(cur != <span class="hljs-literal">nullptr</span>)&#123;<br>            map[cur]-&gt;next = map[cur-&gt;next];<br>            map[cur]-&gt;random = map[cur-&gt;random];<br>            cur = cur-&gt;next;<br>        &#125;<br>        <span class="hljs-keyword">return</span> map[head];<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><p>明天实现一下在节点后面添加新的节点再脱离一下</p>]]></content>
    
    
    <categories>
      
      <category>diary</category>
      
    </categories>
    
    
    <tags>
      
      <tag>diary</tag>
      
      <tag>八股</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>18th-March</title>
    <link href="/2024/03/18/18th-March/"/>
    <url>/2024/03/18/18th-March/</url>
    
    <content type="html"><![CDATA[<h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1 简介"></a>1 简介</h1><p>晚上收到字节周五约面，所以专心准备项目八股和算法，今天先抠一下项目的细节，从6.824开始</p><h1 id="2-6-824"><a href="#2-6-824" class="headerlink" title="2 6.824"></a>2 6.824</h1><h2 id="可能会问的问题"><a href="#可能会问的问题" class="headerlink" title="可能会问的问题"></a>可能会问的问题</h2><h3 id="mapreduce-Q-A"><a href="#mapreduce-Q-A" class="headerlink" title="mapreduce Q&amp;A"></a>mapreduce Q&amp;A</h3><p><font color='red'>1.简单介绍一下mapreduce（开始乱吹）</font></p><p>在二十年以前，分布式系统和分布式计算并不普及，很多公司只是用一台计算机进行操作，但是随着互联网的飞速发展，一台机器的算力已经不足以支撑起快速的计算了，所以就有了分布式这个概念，多台电脑一起完成一个工作。谷歌作为一个国际大公司也是对这方面有着很深刻的研究，他们也会经常要使用并行的计算，而计算必须分布在数百台或者上千台机器，以便在合理的时间内完成，如何并行化计算、分布数据和处理故障等问题，使得单机变成多机的问题十分的复杂。所以就这样，他们受到了map和reduce原语的启发，也就有了mapreduce这么一个简单但强大的支持大规模计算的自动并行化和分布的接口</p><p><font color = 'red'>2.mapreduce是怎么操作的</font></p><p>首先mapreduce库将输入文件分成m个16-64mb的小文件 然后再一个机器集群上启动该程序的副本</p><p>这些副本中有一份是特别的就是master，其余的就是master分配工作的worker。</p><p>被分配map任务的worker线程读取相应输入分割的内容。它们从输入数据中解析键值对，并将每对传递给用户定义的map函数，map产生中间键值对再内存中进行缓冲</p><p>周期性地将缓冲对写入本地磁盘，并通过分区函数划分R个区域。这些缓冲对再本地磁盘上的位置被传递回主服务器，然后再将位置转发给reduce worker</p><p>它使用远程过程调用从map worker的本地磁盘读取缓冲数据。当reduce工作程序读取了所有中间数据后，它按中间键对数据进行排序，以便将所有出现的相同键分组在一起。排序是必要的，因为通常有许多不同的键映射到相同的reduce任务。如果中间数据量太大，内存无法容纳，则使用外部排序。</p><p>reduce worker遍历已排序的中间数据，对于遇到的每个唯一的中间键，它将键和相应的中间值集传递给用户的reduce函数。Reduce函数的输出被附加到这个Reduce分区的最终输出文件中。</p><p>当所有map任务和reduce任务完成后，主程序唤醒用户程序。此时，用户程序中的MapReduce调用返回到用户代码。</p><p><font color = 'red'>3.mapreduce的优化点？</font></p><p>combiner </p><p>状态信息</p><p>我们从这项工作中学到了一些东西。首先，限制编程模型使其易于并行化和分布计算，并使此类计算具有容错性。第二，网络带宽是一种稀缺资源。因此，我们系统中的许多优化都以减少通过网络发送的数据量为目标:局域优化允许我们从本地磁盘读取数据，并将中间数据的单个副本写入本地磁盘以节省网络带宽。第三，冗余执行可用于减少慢机的影响，并处理机器故障和数据丢失</p><h3 id="Raft-Q-A"><a href="#Raft-Q-A" class="headerlink" title="Raft Q&amp;A"></a>Raft Q&amp;A</h3><p><font color='red'>简单讲讲Raft？</font></p><p>他是从多副本状态机的角度提出来的，用于管理多副本状态机的日志复制，分为多个子问题：Leader选举，日志同步，安全性，日志压缩，成员变更等</p><p>raft将系统中的角色分为leader，follower，和candidate</p><p>leader：接受客户端请求，并向Follower同步请求日志，当日志同步到大多数节点上后告诉Follower提交日志</p><p>Follower：接受并持久化Leader同步的日志，再Leader告知日志可以提交之后便提交</p><p>Candidate：Leader选举过程中的临时角色</p><p><font color = 'red'>Raft选举过程 日志复制？</font></p><p>Raft 使用心跳（heartbeat）触发Leader选举。当服务器启动时，初始化为Follower。Leader向所有Followers周期性发送heartbeat。如果Follower在选举超时时间内没有收到Leader的heartbeat，就会等待一段随机的时间后发起一次Leader选举。</p><p>Follower将其当前term加一然后转换为Candidate。它首先给自己投票并且给集群中的其他服务器发送 RequestVote RPC （RPC细节参见八、Raft算法总结）。结果有以下三种情况：</p><ul><li>赢得了多数的选票，成功选举为Leader；</li><li>收到了Leader的消息，表示有其它服务器已经抢先当选了Leader；</li><li>没有服务器赢得多数的选票，Leader选举失败，等待选举时间超时后发起下一次选举。</li></ul><p>Leader选出后，就开始接收客户端的请求。Leader把请求作为日志条目（Log entries）加入到它的日志中，然后并行的向其他服务器发起 AppendEntries RPC 复制日志条目。当这条日志被复制到大多数服务器上，Leader将这条日志应用到它的状态机并向客户端返回执行结果。</p><p>快照 持久化 快速恢复</p><p>可以让Follower在回复Leader的AppendEntries消息中，携带3个额外的信息，来加速日志的恢复。这里的回复是指，Follower因为Log信息不匹配，拒绝了Leader的AppendEntries之后的回复。这里的三个信息是指：</p><ul><li>XTerm：这个是Follower中与Leader冲突的Log对应的任期号。在之前（7.1）有介绍Leader会在prevLogTerm中带上本地Log记录中，前一条Log的任期号。如果Follower在对应位置的任期号不匹配，它会拒绝Leader的AppendEntries消息，并将自己的任期号放在XTerm中。如果Follower在对应位置没有Log，那么这里会返回 -1。</li><li>XIndex：这个是Follower中，对应任期号为XTerm的第一条Log条目的槽位号。</li><li>XLen：如果Follower在对应位置没有Log，那么XTerm会返回-1，XLen表示空白的Log槽位数。</li></ul><p>线性一致</p><p>目前看完2B 看明天怎么看一下2C和2D 争取把这个干完有时间再看其他两个</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>算法 八股 项目 都得看看 </p><p>算法把那几个dp干完看csview上的 但是记得字节应该是得自己new样例的</p><p>八股 先小林 然后再看其他的怎么说</p><p>今天就先这样吧</p>]]></content>
    
    
    <categories>
      
      <category>diary</category>
      
    </categories>
    
    
    <tags>
      
      <tag>diary</tag>
      
      <tag>6.824</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>15th-March</title>
    <link href="/2024/03/15/15th-March/"/>
    <url>/2024/03/15/15th-March/</url>
    
    <content type="html"><![CDATA[<h1 id="To-do-List"><a href="#To-do-List" class="headerlink" title="To-do List"></a>To-do List</h1><ul><li><p><input checked="" disabled="" type="checkbox"> 算法</p><ul><li><input disabled="" type="checkbox"> </li></ul></li><li><p><input disabled="" type="checkbox"> 项目</p><ul><li><input disabled="" type="checkbox"> cmu15445</li><li><input checked="" disabled="" type="checkbox"> mit6.824</li><li><input disabled="" type="checkbox"> mit6.081</li></ul></li><li><p><input disabled="" type="checkbox"> 八股</p><ul><li><input disabled="" type="checkbox"> 操作系统</li><li><input disabled="" type="checkbox"> 计算机网络</li><li><input disabled="" type="checkbox"> 数据库</li><li><input disabled="" type="checkbox"> redis</li></ul></li><li><p><input checked="" disabled="" type="checkbox"> 日常总结</p></li></ul><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p>今天没写。。。 心态有点小崩 等会随便找个题练个手吧</p><h2 id="项目"><a href="#项目" class="headerlink" title="项目"></a>项目</h2><h3 id="6-824"><a href="#6-824" class="headerlink" title="6.824"></a>6.824</h3><p>完成了mapreduce</p><p>主要是coordinator mapworker和reduceworker的协调，感觉还是表达能力差了点</p><p>放点主要代码吧</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">DoMap</span><span class="hljs-params">(mapf <span class="hljs-keyword">func</span>(<span class="hljs-type">string</span>, <span class="hljs-type">string</span>)</span></span> []KeyValue, task *Task) &#123;<br><span class="hljs-comment">//读入每个输入文件，将其传给map，累积中间Map输出。</span><br>fmt.Println(<span class="hljs-string">&quot;Begin map function,task information(TaskType Filename NReduce TaskId Finished Start):&quot;</span>, task)<br>intermediate := []KeyValue&#123;&#125;<br>filename := task.Filename<br>file, err := os.Open(filename)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>log.Fatalf(<span class="hljs-string">&quot;cannot open %v&quot;</span>, filename)<br>&#125;<br>content, err := ioutil.ReadAll(file)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>log.Fatalf(<span class="hljs-string">&quot;cannot read %v&quot;</span>, filename)<br>&#125;<br>file.Close()<br>kva := mapf(filename, <span class="hljs-type">string</span>(content))<br><span class="hljs-comment">//中间key</span><br>intermediate = <span class="hljs-built_in">append</span>(intermediate, kva...)<br>fmt.Println(<span class="hljs-string">&quot;map生成的中间key:&quot;</span>, intermediate)<br>intermediateMap := <span class="hljs-built_in">make</span>([][]KeyValue, task.NReduce)<br><span class="hljs-keyword">for</span> _, tmp := <span class="hljs-keyword">range</span> intermediate &#123;<br>intermediateMap[ihash(tmp.Key)%task.NReduce] = <span class="hljs-built_in">append</span>(intermediateMap[ihash(tmp.Key)%task.NReduce], tmp)<br>&#125;<br>sort.Sort(ByKey(intermediate))<br>i := <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> i &lt; task.NReduce &#123;<br>oname := <span class="hljs-string">&quot;mr-&quot;</span> + strconv.Itoa(task.TaskId) + <span class="hljs-string">&quot;-&quot;</span> + strconv.Itoa(i)<br>ofile, _ := os.Create(oname)<br>enc := json.NewEncoder(ofile)<br><span class="hljs-keyword">for</span> _, kv := <span class="hljs-keyword">range</span> intermediateMap[i] &#123;<br>enc.Encode(&amp;kv)<br>&#125;<br>i++<br>ofile.Close()<br>&#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">DoReduce</span><span class="hljs-params">(reducef <span class="hljs-keyword">func</span>(<span class="hljs-type">string</span>, []<span class="hljs-type">string</span>)</span></span> <span class="hljs-type">string</span>, task *Task) &#123;<br>i := <span class="hljs-number">0</span><br>intermediate := []KeyValue&#123;&#125;<br><span class="hljs-keyword">for</span> i &lt; task.NReduce &#123;<br>filepath := task.Filename + strconv.Itoa(i) + <span class="hljs-string">&quot;-&quot;</span> + strconv.Itoa(task.TaskId)<br>fmt.Println(<span class="hljs-string">&quot;Begin map function,task information(TaskType Filename NReduce TaskId Finished Start):&quot;</span>, task, <span class="hljs-string">&quot;\nfilepath:&quot;</span>, filepath)<br>file, _ := os.Open(filepath)<br>dec := json.NewDecoder(file)<br><span class="hljs-comment">//解码</span><br><span class="hljs-keyword">for</span> &#123;<br><span class="hljs-keyword">var</span> kv KeyValue<br><span class="hljs-keyword">if</span> err := dec.Decode(&amp;kv); err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">break</span><br>&#125;<br>intermediate = <span class="hljs-built_in">append</span>(intermediate, kv)<br>&#125;<br>file.Close()<br>i++<br>&#125;<br>sort.Sort(ByKey(intermediate))<br>i = <span class="hljs-number">0</span><br>oname := <span class="hljs-string">&quot;mr-out-&quot;</span> + strconv.Itoa(task.TaskId)<br>ofile, _ := os.Create(oname)<br><br><span class="hljs-keyword">for</span> i &lt; <span class="hljs-built_in">len</span>(intermediate) &#123;<br>j := i + <span class="hljs-number">1</span><br><span class="hljs-keyword">for</span> j &lt; <span class="hljs-built_in">len</span>(intermediate) &amp;&amp; intermediate[j].Key == intermediate[i].Key &#123;<br>j++<br>&#125;<br>values := []<span class="hljs-type">string</span>&#123;&#125;<br><span class="hljs-comment">//将相同的Key收集到一起</span><br><span class="hljs-keyword">for</span> k := i; k &lt; j; k++ &#123;<br>values = <span class="hljs-built_in">append</span>(values, intermediate[k].Value)<br>&#125;<br>output := reducef(intermediate[i].Key, values)<br>fmt.Fprintf(ofile, <span class="hljs-string">&quot;%v %v\n&quot;</span>, intermediate[i].Key, output)<br>i = j<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="八股"><a href="#八股" class="headerlink" title="八股"></a>八股</h2><h3 id="Golang-切片的容量是怎样增长的"><a href="#Golang-切片的容量是怎样增长的" class="headerlink" title="Golang-切片的容量是怎样增长的"></a>Golang-切片的容量是怎样增长的</h3><p>一般都是在向slice追加了元素之后，才会引起扩容，追加元素调用的是append函数</p><p>先来看看append函数的原型：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">append</span><span class="hljs-params">(slice []Type, elems ...Type)</span></span> []Type<br></code></pre></td></tr></table></figure><p>append函数的参数长度可变，因此可以追加多个值到slice中，还可以用…传入slice，直接追加一个切片</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs go">slice = <span class="hljs-built_in">append</span>(slice, elem1, elem2)<br>slice = <span class="hljs-built_in">append</span>(slice, anotherSlice...)<br></code></pre></td></tr></table></figure><p>append函数返回值是一个新的slice，Go编译器不允许调用了append函数后不使用返回值。</p><p>使用 append 可以向 slice 追加元素，实际上是往底层数组添加元素。但是底层数组的长度是固定的，如果索引 <code>len-1</code> 所指向的元素已经是底层数组的最后一个元素，就没法再添加了。</p><p>这时，slice 会迁移到新的内存位置，新底层数组的长度也会增加，这样就可以放置新增的元素。同时，为了应对未来可能再次发生的 append 操作，新的底层数组的长度，也就是新 <code>slice</code> 的容量是留了一定的 <code>buffer</code> 的。否则，每次添加元素的时候，都会发生迁移，成本太高。</p><p>新 slice 预留的 <code>buffer</code> 大小是有一定规律的。在golang1.18版本更新之前网上大多数的文章都是这样描述slice的扩容策略的：</p><blockquote><p>当原 slice 容量小于 <code>1024</code> 的时候，新 slice 容量变成原来的 <code>2</code> 倍；原 slice 容量超过 <code>1024</code>，新 slice 容量变成原来的<code>1.25</code>倍。</p></blockquote><p>在1.18版本更新之后，slice的扩容策略变为了：</p><blockquote><p>当原slice容量(oldcap)小于256的时候，新slice(newcap)容量为原来的2倍；原slice容量超过256，新slice容量newcap &#x3D; oldcap+(oldcap+3*256)&#x2F;4</p></blockquote><p>举例：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> <span class="hljs-string">&quot;fmt&quot;</span><br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>s := <span class="hljs-built_in">make</span>([]<span class="hljs-type">int</span>, <span class="hljs-number">0</span>)<br><br>oldCap := <span class="hljs-built_in">cap</span>(s)<br><br><span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">2048</span>; i++ &#123;<br>s = <span class="hljs-built_in">append</span>(s, i)<br><br>newCap := <span class="hljs-built_in">cap</span>(s)<br><br><span class="hljs-keyword">if</span> newCap != oldCap &#123;<br>fmt.Printf(<span class="hljs-string">&quot;[%d -&gt; %4d] cap = %-4d  |  after append %-4d  cap = %-4d\n&quot;</span>, <span class="hljs-number">0</span>, i<span class="hljs-number">-1</span>, oldCap, i, newCap)<br>oldCap = newCap<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>我先创建了一个空的 <code>slice</code>，然后，在一个循环里不断往里面 <code>append</code> 新的元素。然后记录容量的变化，并且每当容量发生变化的时候，记录下老的容量，以及添加完元素之后的容量，同时记下此时 <code>slice</code> 里的元素。这样，我就可以观察，新老 <code>slice</code> 的容量变化情况，从而找出规律。</p><p>运行结果(1.18版本之前)：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-section">[0 -&gt;   -1]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">0</span>     |  after append <span class="hljs-number">0</span>     cap = <span class="hljs-number">1</span>   <br><span class="hljs-section">[0 -&gt;    0]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">1</span>     |  after append <span class="hljs-number">1</span>     cap = <span class="hljs-number">2</span>   <br><span class="hljs-section">[0 -&gt;    1]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">2</span>     |  after append <span class="hljs-number">2</span>     cap = <span class="hljs-number">4</span>   <br><span class="hljs-section">[0 -&gt;    3]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">4</span>     |  after append <span class="hljs-number">4</span>     cap = <span class="hljs-number">8</span>   <br><span class="hljs-section">[0 -&gt;    7]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">8</span>     |  after append <span class="hljs-number">8</span>     cap = <span class="hljs-number">16</span>  <br><span class="hljs-section">[0 -&gt;   15]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">16</span>    |  after append <span class="hljs-number">16</span>    cap = <span class="hljs-number">32</span>  <br><span class="hljs-section">[0 -&gt;   31]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">32</span>    |  after append <span class="hljs-number">32</span>    cap = <span class="hljs-number">64</span>  <br><span class="hljs-section">[0 -&gt;   63]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">64</span>    |  after append <span class="hljs-number">64</span>    cap = <span class="hljs-number">128</span> <br><span class="hljs-section">[0 -&gt;  127]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">128</span>   |  after append <span class="hljs-number">128</span>   cap = <span class="hljs-number">256</span> <br><span class="hljs-section">[0 -&gt;  255]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">256</span>   |  after append <span class="hljs-number">256</span>   cap = <span class="hljs-number">512</span> <br><span class="hljs-section">[0 -&gt;  511]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">512</span>   |  after append <span class="hljs-number">512</span>   cap = <span class="hljs-number">1024</span><br><span class="hljs-section">[0 -&gt; 1023]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">1024</span>  |  after append <span class="hljs-number">1024</span>  cap = <span class="hljs-number">1280</span><br><span class="hljs-section">[0 -&gt; 1279]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">1280</span>  |  after append <span class="hljs-number">1280</span>  cap = <span class="hljs-number">1696</span><br><span class="hljs-section">[0 -&gt; 1695]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">1696</span>  |  after append <span class="hljs-number">1696</span>  cap = <span class="hljs-number">2304</span><br></code></pre></td></tr></table></figure><p>运行结果(1.18版本)：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-section">[0 -&gt;   -1]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">0</span>     |  after append <span class="hljs-number">0</span>     cap = <span class="hljs-number">1</span><br><span class="hljs-section">[0 -&gt;    0]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">1</span>     |  after append <span class="hljs-number">1</span>     cap = <span class="hljs-number">2</span>   <br><span class="hljs-section">[0 -&gt;    1]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">2</span>     |  after append <span class="hljs-number">2</span>     cap = <span class="hljs-number">4</span>   <br><span class="hljs-section">[0 -&gt;    3]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">4</span>     |  after append <span class="hljs-number">4</span>     cap = <span class="hljs-number">8</span>   <br><span class="hljs-section">[0 -&gt;    7]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">8</span>     |  after append <span class="hljs-number">8</span>     cap = <span class="hljs-number">16</span>  <br><span class="hljs-section">[0 -&gt;   15]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">16</span>    |  after append <span class="hljs-number">16</span>    cap = <span class="hljs-number">32</span>  <br><span class="hljs-section">[0 -&gt;   31]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">32</span>    |  after append <span class="hljs-number">32</span>    cap = <span class="hljs-number">64</span>  <br><span class="hljs-section">[0 -&gt;   63]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">64</span>    |  after append <span class="hljs-number">64</span>    cap = <span class="hljs-number">128</span> <br><span class="hljs-section">[0 -&gt;  127]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">128</span>   |  after append <span class="hljs-number">128</span>   cap = <span class="hljs-number">256</span> <br><span class="hljs-section">[0 -&gt;  255]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">256</span>   |  after append <span class="hljs-number">256</span>   cap = <span class="hljs-number">512</span> <br><span class="hljs-section">[0 -&gt;  511]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">512</span>   |  after append <span class="hljs-number">512</span>   cap = <span class="hljs-number">848</span> <br><span class="hljs-section">[0 -&gt;  847]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">848</span>   |  after append <span class="hljs-number">848</span>   cap = <span class="hljs-number">1280</span><br><span class="hljs-section">[0 -&gt; 1279]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">1280</span>  |  after append <span class="hljs-number">1280</span>  cap = <span class="hljs-number">1792</span><br><span class="hljs-section">[0 -&gt; 1791]</span> <span class="hljs-attr">cap</span> = <span class="hljs-number">1792</span>  |  after append <span class="hljs-number">1792</span>  cap = <span class="hljs-number">2560</span><br></code></pre></td></tr></table></figure><p>根据上面的结果我们可以看出在<code>1.18</code>版本之前：</p><p>在原来的slice容量<code>oldcap</code>小于1024的时候，新 slice 的容量<code>newcap</code>的确是<code>oldcap</code>的2倍。</p><p>但是，当<code>oldcap</code>大于等于 <code>1024</code> 的时候，情况就有变化了。当向 slice 中添加元素 <code>1280</code> 的时候，原来的slice 的容量为 <code>1280</code>，之后<code>newcap</code>变成了 <code>1696</code>，两者并不是 <code>1.25</code> 倍的关系（1696&#x2F;1280&#x3D;1.325）。添加完 <code>1696</code> 后，新的容量 <code>2304</code> 当然也不是 <code>1696</code> 的 <code>1.25</code> 倍。</p><p>在<code>1.18</code>版本之后：</p><p>在原来的slice 容量<code>oldcap</code>小于256的时候，新 slice 的容量<code>newcap</code>的确是<code>oldcap</code> 的2倍。</p><p>但是，当<code>oldcap</code>容量大于等于 <code>256</code> 的时候，情况就有变化了。当向 slice 中添加元素 <code>512</code> 的时候，老 slice 的容量为 <code>512</code>，之后变成了 <code>8</code>48，两者并没有符合<code>newcap = oldcap+(oldcap+3*256)/4</code> 的策略（512+（512+3*256）&#x2F;4）&#x3D;832。添加完 <code>848</code> 后，新的容量 <code>1280</code> 当然也不是 按照之前策略所计算出的的1252。</p><p>难道现在网上各种文章中的扩容策略并不是正确的吗。我们直接搬出源码：源码面前，了无秘密。</p><p>从前面汇编代码我们也看到了，向 slice 追加元素的时候，若容量不够，会调用 <code>growslice</code> 函数，所以我们直接看它的代码。</p><p><strong>golang版本1.9.5</strong></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// go 1.9.5 src/runtime/slice.go:82</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">growslice</span><span class="hljs-params">(et *_type, old slice, <span class="hljs-built_in">cap</span> <span class="hljs-type">int</span>)</span></span> slice &#123;<br>    <span class="hljs-comment">// ……</span><br>    newcap := old.<span class="hljs-built_in">cap</span><br>doublecap := newcap + newcap<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">cap</span> &gt; doublecap &#123;<br>newcap = <span class="hljs-built_in">cap</span><br>&#125; <span class="hljs-keyword">else</span> &#123;<br><span class="hljs-keyword">if</span> old.<span class="hljs-built_in">len</span> &lt; <span class="hljs-number">1024</span> &#123;<br>newcap = doublecap<br>&#125; <span class="hljs-keyword">else</span> &#123;<br><span class="hljs-keyword">for</span> newcap &lt; <span class="hljs-built_in">cap</span> &#123;<br>newcap += newcap / <span class="hljs-number">4</span><br>&#125;<br>&#125;<br>&#125;<br><span class="hljs-comment">// ……</span><br><br>capmem = roundupsize(<span class="hljs-type">uintptr</span>(newcap) * ptrSize)<br>newcap = <span class="hljs-type">int</span>(capmem / ptrSize)<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>golang版本1.18</strong></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// go 1.18 src/runtime/slice.go:178</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">growslice</span><span class="hljs-params">(et *_type, old slice, <span class="hljs-built_in">cap</span> <span class="hljs-type">int</span>)</span></span> slice &#123;<br>    <span class="hljs-comment">// ……</span><br>    newcap := old.<span class="hljs-built_in">cap</span><br>doublecap := newcap + newcap<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">cap</span> &gt; doublecap &#123;<br>newcap = <span class="hljs-built_in">cap</span><br>&#125; <span class="hljs-keyword">else</span> &#123;<br><span class="hljs-keyword">const</span> threshold = <span class="hljs-number">256</span><br><span class="hljs-keyword">if</span> old.<span class="hljs-built_in">cap</span> &lt; threshold &#123;<br>newcap = doublecap<br>&#125; <span class="hljs-keyword">else</span> &#123;<br><span class="hljs-keyword">for</span> <span class="hljs-number">0</span> &lt; newcap &amp;&amp; newcap &lt; <span class="hljs-built_in">cap</span> &#123;<br>                <span class="hljs-comment">// Transition from growing 2x for small slices</span><br><span class="hljs-comment">// to growing 1.25x for large slices. This formula</span><br><span class="hljs-comment">// gives a smooth-ish transition between the two.</span><br>newcap += (newcap + <span class="hljs-number">3</span>*threshold) / <span class="hljs-number">4</span><br>&#125;<br><span class="hljs-keyword">if</span> newcap &lt;= <span class="hljs-number">0</span> &#123;<br>newcap = <span class="hljs-built_in">cap</span><br>&#125;<br>&#125;<br>&#125;<br><span class="hljs-comment">// ……</span><br>    <br>capmem = roundupsize(<span class="hljs-type">uintptr</span>(newcap) * ptrSize)<br>newcap = <span class="hljs-type">int</span>(capmem / ptrSize)<br>&#125;<br></code></pre></td></tr></table></figure><p>如果只看前半部分，现在网上各种文章里说的 <code>newcap</code> 的规律是对的。现实是，后半部分还对 <code>newcap</code> 作了一个<code>内存对齐</code>，这个和内存分配策略相关。进行内存对齐之后，新 slice 的容量是要 <code>大于等于</code> 按照前半部分生成的<code>newcap</code>。</p><p>之后，向 Go 内存管理器申请内存，将老 slice 中的数据复制过去，并且将 append 的元素添加到新的底层数组中。</p><p>最后，向 <code>growslice</code> 函数调用者返回一个新的 slice，这个 slice 的长度并没有变化，而容量却增大了。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>。。。失败 但是差不多能知道哪里不足了 可以尝试一下 明天笔试加油</p>]]></content>
    
    
    <categories>
      
      <category>diary</category>
      
    </categories>
    
    
    <tags>
      
      <tag>diary</tag>
      
      <tag>八股</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>raft</title>
    <link href="/2024/03/15/raft-1/"/>
    <url>/2024/03/15/raft-1/</url>
    
    <content type="html"><![CDATA[<h1 id="一种可理解的共识算法的寻找-扩展版"><a href="#一种可理解的共识算法的寻找-扩展版" class="headerlink" title="一种可理解的共识算法的寻找(扩展版)"></a>一种可理解的共识算法的寻找(扩展版)</h1><h2 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h2><p>​<strong>Raft</strong>是用于管理复制日志的共识算法。它产生的结果相当于(多)Paxos，效率和Paxos一样，但结构与Paxos不同;这使得Raft比Paxos更容易理解，也为构建实用系统提供了更好的基础。为了增强可理解性，Raft分离了共识的关键元素，如leader选举、日志复制和安全性，并且它强制执行更强的一致性，以减少必须考虑的状态的数量。用户研究的结果表明，对于学生来说，Raft比Paxos更容易学习。Raft还包含了一个改变集群成员的新机制，它使用重叠大多数来保证安全。</p><h2 id="I-介绍"><a href="#I-介绍" class="headerlink" title="I.介绍"></a>I.介绍</h2><p>​共识算法允许一组机器作为一个连贯的群体工作，可以在其中一些成员出现故障时幸存下来。正因为如此，它们在构建可靠的大型软件系统中起着关键作用。Paxos[15,16]在过去十年中主导了共识算法的讨论:大多数共识的实现都基于Paxos或受其影响，Paxos已成为教授学生共识的主要工具。</p><p>​不幸的是，Paxos很难理解，尽管有许多尝试使它更容易理解。此外，它的体系结构需要进行复杂的更改以支持实际系统。因此，系统构建者和学生使用Paxos都很困难。</p><p>​在与Paxos斗争之后，我们开始寻找一种新的共识算法，可以为系统构建和教育提供更好的基础。我们的方法是不同寻常的，因为我们的主要目标是可理解性:我们能否为实际系统定义一个共识算法，并以一种比Paxos更容易学习的方式来描述它?此外，我们希望算法能够促进对系统构建者至关重要的直觉的发展。重要的不仅是算法能起作用，还在于它为什么能起作用。</p><p>​这项工作的结果是一个被称为Raft的共识算法。在设计Raft时，我们应用了特定的技术来提高可理解性，包括分解(Raft将领导者选举、日志复制和安全性分开)和状态空间缩减(相对于Paxos, Raft降低了不确定性的程度和服务器之间可能不一致的方式)。一项针对两所大学43名学生的用户研究表明，Raft比Paxos更容易理解:在学习了这两种算法后，其中33名学生能够更好地回答关于Raft的问题，而不是关于Paxos的问题。</p><p>​Raft在许多方面与现有的共识算法相似(最值得注意的是Oki和Liskov的Viewstamped Replication)，但它有几个新特性:</p><ul><li><strong>强大的leader</strong>:Raft使用比其他共识算法更强大的领导形式。例如，日志条目只从leader流向其他服务器。这简化了复制日志的管理，使Raft更容易理解。</li><li><strong>leader选举</strong>:Raft使用随机计时器来选举首领。这只给任何共识算法已经需要的心跳增加了少量的机制，同时简单快速地解决冲突。</li><li><strong>成员变更</strong>:Raft用于更改集群中服务器集的机制使用了一种新的联合共识方法，在这种方法中，两种不同配置的大多数在转换期间重叠。这允许集群在配置更改期间继续正常运行。</li></ul><p>​我们相信Raft优于Paxos和其他共识算法，无论是出于教育目的还是作为实现的基础。它比其他算法更简单，更容易理解;它的描述足够完整，足以满足实际系统的需要;它有几个开源实现，并被几家公司使用;其安全性能已经过正式规定和证明;其效率与其他算法相当。</p><p>​本文的其余部分介绍了复制状态机问题(第2节)，讨论了Paxos的优缺点(第3节)，描述了我们实现可理解性的一般方法(第4节)，介绍了Raft共识算法(第5-8节)，评估了Raft(第9节)，并讨论了相关工作(第10节)。</p><h2 id="II-复制状态机"><a href="#II-复制状态机" class="headerlink" title="II.复制状态机"></a>II.复制状态机</h2><p><img src="/../imgs/raft-1/image-20240315211045665.png" alt="图1:复制状态机架构。一致性算法管理包含来自客户机的状态机命令的复制日志。状态机处理来自日志的相同命令序列，因此它们产生相同的输出。"></p><p>​共识算法通常出现在复制状态机的环境中。在这种方法中，一组服务器上的状态机计算相同状态的相同副本，并且即使某些服务器关闭也可以继续运行。复制状态机用于解决分布式系统中的各种容错问题。例如，具有单个集群领导者的大型系统，如GFS， HDFS和RAMCloud，通常使用单独的复制状态机来管理领导者选举和存储必须在领导者崩溃时存活的配置信息。复制状态机的例子包括Chubby和ZooKeeper。</p><p>​复制状态机通常使用复制日志来实现，如图1所示。每个服务器存储包含一系列命令的日志，其状态机按顺序执行这些命令。每个日志以相同的顺序包含相同的命令，因此每个状态机处理相同的命令序列。由于状态机是确定性的，因此每个状态机都计算相同的状态和相同的输出序列。</p><p>​保持复制日志的一致性是一致性算法的工作。服务器上的consensus模块接收来自客户端的命令并将其添加到日志中。它与其他服务器上的共识模块通信，以确保每个日志最终以相同的顺序包含相同的请求，即使某些服务器失败。一旦正确地复制了命令，每个服务器的状态机将按日志顺序处理它们，并将输出返回给客户机。因此，这些服务器似乎形成了一个单一的、高度可靠的状态机。</p><p>​实际系统的共识算法通常具有以下性质:</p><ul><li>它们确保在所有非拜占庭条件下的安全性(永远不会返回错误的结果)，包括网络延迟、分区、数据包丢失、重复和重新排序。</li><li>只要任何大多数服务器都是可操作的，并且可以相互通信并与客户端通信，它们就具有完整的功能(可用)。因此，典型的五台服务器集群可以容忍任意两台服务器的故障。通过停止假定服务器失败;它们可能稍后从稳定存储上的状态恢复并重新加入集群。</li><li>它们不依赖于定时来确保日志的一致性:错误的时钟和极端的消息延迟在最坏的情况下会导致可用性问题。</li><li>在通常情况下，只要集群的大多数响应了一轮远程过程调用，命令就可以完成;少数慢速服务器不需要影响整体系统性能。</li></ul><h2 id="III-What’s-wrong-with-Paxos"><a href="#III-What’s-wrong-with-Paxos" class="headerlink" title="III.What’s wrong with Paxos???"></a>III.What’s wrong with Paxos???</h2><p>​在过去的十年里，Leslie Lamport的Paxos协议几乎已经成为共识的代名词:它是课程中最常教授的协议，大多数共识的实现都将其作为起点。Paxos首先定义了一个能够就单个决策达成一致的协议，比如单个复制的日志条目。我们将这个子集称为单命令Paxos。然后，Paxos结合该协议的多个实例来促进一系列决策，例如日志(多Paxos)。Paxos确保了安全性和活动性，并且支持更改集群成员。该方法的正确性得到了验证，在一般情况下是有效的。</p><p>​不幸的是，Paxos有两个明显的缺点。第一个缺点是Paxos非常难以理解。完整的解释[15]是出了名的不透明;只有付出巨大努力的人才能理解它。因此，已经有人尝试用更简单的术语来解释Paxos。这些解释集中于单一法令子集，但它们仍然具有挑战性。在对2012年NSDI与会者的非正式调查中，我们发现很少有人对Paxos感到满意，即使是经验丰富的研究人员。我们自己也在努力开发Paxos;直到阅读了几个简化的解释并设计了我们自己的替代协议之后，我们才能够理解完整的协议，这个过程花了将近一年的时间。</p><p>​我们假设Paxos的不透明性源于它选择单一法令子集作为其基础。单一法令的Paxos是密集而微妙的:它分为两个阶段，没有简单的直观解释，无法独立理解。正因为如此，很难对单一法令协议的工作原理做出直观的解释。多paxos的组合规则增加了额外的复杂性和微妙性。我们相信，在多个决策上达成共识的整体问题(即，一个日志而不是单个条目)可以用其他更直接和明显的方式分解。</p><p>​Paxos的第二个问题是，它没有为构建实际实现提供良好的基础。其中一个原因是，对于多paxos，还没有得到广泛认可的算法。兰波特的描述主要是关于单一法令的Paxos;他概述了实现多paxos的可能方法，但缺少许多细节。已经有几次尝试充实和优化Paxos，但这些彼此不同，也不同于Lamport的草图。像Chubby这样的系统已经实现了类似paxos的算法，但在大多数情况下，它们的细节还没有公布。</p><p>​此外，Paxos架构对于构建实际系统来说是一个糟糕的架构;这是单一法令分解的另一个后果。例如，独立地选择一组日志条目，然后将它们合并到一个顺序日志中，这几乎没有什么好处;这只会增加复杂性。围绕日志设计系统更简单、更有效，在日志中，新条目以受限的顺序依次挂起。另一个问题是Paxos在其核心使用了对称的点对点方法(尽管它最终提出了一种弱形式的领导作为性能优化)。这在只需要做出一个决策的简化世界中是有意义的，但是很少有实际的系统使用这种方法。如果必须做出一系列决策，那么首先选举一个领导者，然后让领导者协调决策是更简单和更快的方法。</p><p>​因此，实际系统与Paxos几乎没有相似之处。每个实现都从Paxos开始，发现实现它的困难，然后开发一个截然不同的体系结构。这既耗时又容易出错，而且理解Paxos的困难加剧了这个问题。Paxos的公式对于证明其正确性的定理可能是一个很好的公式，但是实际实现与Paxos如此不同，以至于证明几乎没有价值。以下是Chubby实现者的典型评论:</p><p>​<font color = 'red'><strong>在Paxos算法的描述和真实系统的需求之间有很大的差距…最终的系统将基于一个未经验证的协议</strong></font></p><p>​由于这些问题，我们得出结论，Paxos不能为系统构建或教育提供良好的基础。考虑到共识在大型软件系统中的重要性，我们决定看看是否可以设计一个具有比Paxos更好属性的替代共识算法。Raft就是那次实验的结果。</p><h2 id="IV-为可理解性而设计"><a href="#IV-为可理解性而设计" class="headerlink" title="IV.为可理解性而设计"></a>IV.为可理解性而设计</h2><p>​我们在设计Raft时有几个目标:它必须为系统构建提供一个完整和实用的基础，这样它就可以显著减少开发人员所需的设计工作量;它必须在所有条件下都是安全的，并在典型的操作条件下可用;对于一般的操作，它必须是有效的。但我们最重要的目标——也是最困难的挑战——是可理解性。它必须能够让大量的观众轻松地理解算法。此外，必须能够开发关于算法的直觉，以便系统构建者可以进行在实际实现中不可避免的扩展。</p><p>​在Raft的设计过程中，我们需要在不同的方法中做出选择。在这些情况下，我们根据可理解性来评估备选方案:解释每个备选方案有多难(例如，其状态空间有多复杂，它是否有微妙的含义?)，读者完全理解该方法及其含义有多容易?</p><p>​我们认识到，在这种分析中有高度的主观性;尽管如此，我们还是使用了两种普遍适用的技术。第一种技术是众所周知的问题分解方法:只要有可能，我们就把问题分成可以相对独立地解决、解释和理解的独立部分。例如，在Raft中，我们分离了leader选举、日志复制、安全性和成员变更。</p><p>​我们的第二种方法是通过减少要考虑的状态数量来简化状态空间，使系统更加连贯，并在可能的情况下消除不确定性。具体来说，原木不允许有孔，Raft限制了原木相互不一致的方式。尽管在大多数情况下我们试图消除非确定性，但在某些情况下，非确定性实际上提高了可理解性。特别是，随机方法引入了不确定性，但它们倾向于通过以类似的方式处理所有可能的选择(“随便选没关系”)。我们使用随机化来简化Raft leader的选举算法。</p><h2 id="V-Raft共识算法"><a href="#V-Raft共识算法" class="headerlink" title="V.Raft共识算法"></a>V.Raft共识算法</h2><p><img src="/../imgs/raft-1/image-20240315213252013.png" alt="图2:Raft共识算法的简明摘要(不包括成员变更和日志压缩)。左上角框中的服务器行为被描述为一组独立且重复触发的规则。章节编号，如§5.2表示讨论特定特征的地方。正式规范更精确地描述了该算法。"></p><p>​Raft是一种算法，用于管理第2节中描述的形式的复制日志。图2对算法进行了简明总结，以供参考，图3列出了算法的关键属性;这些数字的元素将在本节的其余部分逐条讨论。</p><p>​Raft通过首先选举一个杰出的领导者来实现共识，然后让领导者完全负责管理复制的日志。leader接受来自客户机的日志条目，在其他服务器上复制它们，并告诉服务器何时可以安全地将日志条目应用到它们的状态机。拥有一个leader可以简化对复制日志的管理。例如，leader可以在不咨询其他服务器的情况下决定在日志中放置新条目的位置，并且数据以一种简单的方式从leader流向其他服务器。leader可能会失败或与其他服务器断开连接，在这种情况下，会选举一个新的leader。</p><p>​在leader方法下，Raft将共识问题分解为三个相对独立的子问题，并在以下小节中进行讨论:</p><ul><li>领导人选举:当现有领导人失败时，必须选择新的领导人(第5.2节)。</li><li>日志复制:leader必须接受来自客户端的日志条目，并在整个集群中复制它们，迫使其他日志与自己的日志一致(第5.3节)。</li><li>安全性:Raft的关键安全属性是图3中的状态机安全属性:如果任何服务器将特定的日志条目应用到其状态机，那么其他服务器就不能对相同的日志索引应用不同的命令。第5.4节描述了Raft如何确保此属性;该解决方案涉及对第5.2节中描述的选举机制的额外限制。</li></ul><p><img src="/../imgs/raft-1/image-20240315213333387.png" alt="图3:Raft保证这些属性在任何时候都是正确的。节号表示讨论每个属性的位置。"></p><p>​在介绍了共识算法之后，本节将讨论可用性问题和定时在系统中的作用。</p><h3 id="V-1-Raft基础"><a href="#V-1-Raft基础" class="headerlink" title="V.1 Raft基础"></a>V.1 Raft基础</h3><p>​Raft集群包含多个服务器;5是一个典型的数字，它允许系统容忍两次故障。在任何给定时间，每个服务器都处于以下三种状态之一:领导者、追随者或候选人。在正常操作中，只有一个领导者，所有其他服务器都是追随者。追随者是被动的:他们自己不发出任何要求，只是对领导和候选人的要求做出回应。leader处理所有客户端请求(如果客户端联系了follower, follower会将其重定向到leader)。第三个状态，candidate，用于选举新的领导人，如第5.2节所述。图4显示了状态及其转换;下面将讨论这些转换。</p><p><img src="/../imgs/raft-1/image-20240315213542054.png" alt="图4:服务器状态。追随者只响应来自其他服务器的请求。如果追随者没有收到任何通信，它就成为候选人并发起选举。获得整个集群大多数选票的候选人成为新的领导者。领导者通常会一直工作到失败。"></p><p><img src="/../imgs/raft-1/image-20240315213607650.png" alt="图5:时间分为任期，每任期以选举开始。在一次成功的选举之后，一个单一的领导者管理集群直到任期结束。有些选举失败，在这种情况下，任期结束时没有选出领导人。在不同的服务器上，可以在不同的时间观察到术语之间的转换。"></p><p>​Raft将时间划分为任意长度，如图5所示。任期用连续整数编号。每个任期以选举开始，其中一个或多个候选人试图成为第5.2节所述的领导人。如果一位候选人赢得选举，那么他将在剩下的任期内担任领导人。在某些情况下，选举会导致票数不一致。在这种情况下，任期结束时将没有领导人;新任期(有新的选举)即将开始。Raft保证在给定的任期内最多有一个leader。</p><p>​不同的服务器可能会在不同的时间观察任期之间的过渡，在某些情况下，服务器可能不会观察选举甚至整个任期。术语在Raft中充当逻辑时钟，它们允许服务器检测过时的信息，如过时的leader。每个服务器存储一个当前术语号，该术语号随时间单调增加。每当服务器通信时，都会交换当前条款;如果一台服务器的当前项小于另一台服务器的，则将其当前项更新为较大的值。如果候选人或领导人发现自己的任期已经过期，</p><p>​Raft服务器使用远程过程调用(rpc)进行通信，基本的一致性算法只需要两种类型的rpc。RequestVote rpc是由候选人在选举期间发起的(第5.2节)，而追加条目rpc是由领导者发起的，用于复制日志条目并提供心跳形式(第5.3节)。第7节添加了第三个RPC，用于在服务器之间传输快照。如果服务器没有及时收到响应，它们会重试rpc，并并行地发出rpc以获得最佳性能。</p><h3 id="V-2-领导选举"><a href="#V-2-领导选举" class="headerlink" title="V.2 领导选举"></a>V.2 领导选举</h3><p>​Raft使用心跳机制来触发领导人选举。当服务器启动时，它们从追随者开始。只要从leader或candidate接收到有效的rpc，服务器就保持follower状态。领导者定期向所有追随者发送心跳(AppendEntries rpc，不携带日志条目)，以维护他们的权威。如果一个follower在一段称为选举超时的时间内没有收到任何通信，那么它假设没有可见的leader，并开始选举以选择一个新的leader。</p><p>​要开始选举，追随者增加其当前任期并过渡到候选人状态。然后，它为自己投票，并并行地向集群中的每个其他服务器发出RequestVote rpc。候选人一直处于这种状态，直到发生以下三种情况之一:(A)它赢得了选举，(b)另一个服务器确立了自己的领导地位，或者(c)一段时间过去了，没有赢家。这些结果将在下文各段分别讨论。</p><p>​如果候选人在同一任期内获得整个集群中大多数服务器的投票，则该候选人赢得选举。在给定的任期内，每个服务器将以先到先得的方式投票给最多一个候选人(注意:第5.4节增加了对投票的额外限制)。多数决定原则确保最多有一名候选人能够赢得特定任期的选举(图3中的选举安全属性)。一旦候选人赢得选举，它就成为领导者。然后，它向所有其他服务器发送心跳消息，以建立其权威并防止新的选举。</p><p>​在等待投票期间，候选人可能会从另一个声称是领导者的服务器接收AppendEntries RPC。如果领导者的任期(包含在其RPC中)至少与候选人的当前任期一样长，则候选人将承认领导者是合法的，并返回到追随者状态。如果RPC中的术语小于候选者的当前术语，则候选者拒绝RPC并继续处于候选者状态。</p><p>​第三种可能的结果是候选人既不赢也不输:如果许多追随者同时成为候选人，选票可能会被分割，因此没有候选人获得多数。当这种情况发生时，每个候选人将超时并通过增加其任期并启动另一轮请求-投票rpc来开始新的选举。然而，如果不采取额外措施，分裂投票可能会无限期地重复。</p><p>​Raft使用随机选举超时来确保分裂投票很少，并且可以快速解决。为了首先防止分裂投票，选举超时从固定间隔(例如150-300ms)中随机选择。这将分散服务器，因此在大多数情况下，只有一个服务器会超时;它赢得了选举，并在任何其他服务器超时之前发送心跳。同样的机制也用于处理分裂投票。每个候选人在选举开始时重新启动其随机选举超时，并等待该超时结束后再开始下一次选举;这降低了在新选举中再次出现分裂投票的可能性。9.3节表明，这种方法可以快速地选出领导者。</p><p><img src="/../imgs/raft-1/image-20240315214258232.png" alt="图6:日志由条目组成，条目按顺序编号。每个条目包含创建它时使用的术语(每个框中的数字)和用于状态机的命令。如果将一个条目应用于状态机是安全的，则认为该条目已提交。"></p><p>​选举是一个例子，说明可理解性如何指导我们在设计方案之间做出选择。最初我们计划使用一个排名系统:每个候选人被分配一个唯一的排名，用于在竞争候选人之间进行选择。如果一个候选人发现了另一个排名更高的候选人，它就会回到追随者状态，这样排名更高的候选人就更容易赢得下一次选举。我们发现这种方法在可用性方面产生了微妙的问题(如果排名较高的服务器失败，排名较低的服务器可能需要超时并再次成为候选服务器，但如果它这样做得太快，它可能会重置选举领导者的进度)。我们对算法进行了几次调整，但每次调整后都会出现新的拐角案例。最终我们得出结论，随机重试方法更明显，更容易理解。</p><h3 id="V-3-日志复制"><a href="#V-3-日志复制" class="headerlink" title="V.3 日志复制"></a>V.3 日志复制</h3><p>​一旦选出领导者，它就开始服务客户端请求。每个客户端请求都包含一个要由复制状态机执行的命令。leader将该命令作为一个新条目追加到它的日志中，然后将AppendEntries rpc与其他每个服务器并行，以复制该条目。当条目被安全复制后(如下所述)，leader将该条目应用于其状态机，并将执行的结果返回给客户机。如果follower崩溃或运行缓慢，或者如果网络数据包丢失，leader会无限期地重试追加条目rpc(即使在它已经响应客户端之后)，直到所有follower最终存储所有日志条目。</p><p>​日志组织如图6所示。每个日志记录存储一个状态机命令以及leader接收到该条目时的术语号。日志条目中的术语编号用于检测日志之间的不一致性，并确保图3中的一些属性。每个日志条目还有一个整数索引，用于标识其在日志中的位置。</p><p>​领导者决定何时对状态机应用日志记录是安全的;这样的条目称为committed。Raft保证提交的条目是持久的，并且最终将由所有可用的状态机执行。一旦创建条目的leader在大多数服务器上复制了该条目(例如，图6中的条目7)，日志条目就会被提交。这也会提交leader日志中所有之前的条目，包括之前的leader创建的条目。第5.4节讨论了在领导者更换后应用此规则时的一些微妙之处，并表明此承诺定义是安全的。leader跟踪它知道要提交的最高索引，并将该索引包含在未来的AppendEntries rpc中(包括心跳)，以便其他服务器最终发现。一旦追随者了解到日志条目已提交，它将该条目应用于其本地状态机(按日志顺序)。</p><p>​我们设计Raft日志机制是为了在不同服务器上的日志之间保持高度的一致性。这不仅简化了系统的行为，使其更可预测，而且是确保安全的重要组成部分。Raft维护以下属性，它们共同构成了图3中的日志匹配属性:</p><ul><li>如果不同日志中的两个条目具有相同的索引和期限，则它们存储相同的命令。</li><li>如果不同日志中的两个条目具有相同的索引和期限，则前面所有条目的日志都相同。</li></ul><p>​第一个属性源于这样一个事实，即leader在给定的期限内最多创建一个具有给定日志索引的条目，并且日志条目永远不会改变其在日志中的位置。第二个属性由AppendEntries执行的简单一致性检查保证。当发送AppendEntries RPC时，leader在其日志中包含条目的索引和期限，该条目立即位于新条目之前。如果跟随者在其日志中没有找到具有相同索引和期限的条目，则拒绝新条目。一致性检查作为一个归纳步骤:日志的初始空状态满足日志匹配属性，无论何时扩展日志，一致性检查都保持日志匹配属性。因此，每当AppendEntries成功返回时，leader就知道follower的日志与它自己的日志通过新条目相同。</p><p>​正常运行时，leader和follower的日志是一致的，所以AppendEntries一致性检查不会失败。但是，leader崩溃可能导致日志不一致(旧leader可能没有完全复制其日志中的所有条目)。这些不一致可能会在一系列领导者和追随者的崩溃中加剧。图7说明了追随者的日志可能与新领导者的不同之处。follower可能缺少leader上存在的条目，也可能有leader上没有的额外条目，或者两者兼而有之。日志中缺少的和无关的条目可能跨越多个术语。</p><p>​在Raft中，领导者通过强迫追随者的日志复制自己的日志来处理不一致。这意味着跟随者日志中的冲突条目将被来自领导者日志的条目覆盖。第5.4节将说明，如果加上另外一个限制，这样做是安全的。</p><p>​为了使追随者的日志与自己的日志保持一致，领导者必须找到两个日志一致的最新日志条目，删除追随者日志中在该点之后的任何条目，并将领导者在该点之后的所有条目发送给追随者。所有这些操作都是对AppendEntries rpc执行的一致性检查的响应。leader为每个follower维护一个nextindex，这是leader将发送给该follower的下一个日志条目的索引。当leader首次掌权时，它将所有nextIndex值初始化为日志中最后一个值之后的索引(图7中的11)。如果follower的日志与leader的日志不一致，AppendEntries一致性检查将在下一个AppendEntries RPC中失败。拒绝后，leader减少nextIndex并重试AppendEntries RPC。最终nextIndex将达到领导者和追随者日志匹配的点。当这种情况发生时，AppendEntries将成功，它将删除follower日志中的任何冲突条目，并从leader日志中添加条目(如果有的话)。一旦AppendEntries成功，跟随者的日志与领导者的日志一致，并且在任期的剩余时间内保持这种状态。</p><p>​如果需要，可以优化协议以减少被拒绝的AppendEntries rpc的数量。例如，在拒绝AppendEntries请求时，follower可以包含冲突条目的项和它为该项存储的第一个索引。有了这些信息，leader就可以对nextIndex进行减量以绕过该项中所有冲突的表项;每个有冲突条目的术语需要一个AppendEntries RPC，而不是每个条目一个RPC。在实践中，我们怀疑这种优化是否必要，因为故障很少发生，而且不太可能有许多不一致的条目。</p><p>​有了这种机制，当涉及到权力时，领导者不需要采取任何特殊操作来恢复日志一致性。它只是开始正常操作，并且日志会自动收敛，以响应追加条目一致性检查失败。leader永远不会覆盖或删除自己日志中的条目(图3中的leader追加属性)。</p><p>​这种日志复制机制展示了第2节中描述的理想的共识属性:只要大多数服务器正常运行，Raft就可以接受、复制和应用新的日志条目;在正常情况下，一个新条目可以通过一轮rpc复制到集群的大多数;一个缓慢的追随者不会影响你的表现。</p><h3 id="V-4-安全"><a href="#V-4-安全" class="headerlink" title="V.4 安全"></a>V.4 安全</h3><p>​前面的小节描述了Raft如何选择leader和复制日志条目。然而，到目前为止所描述的机制还不足以确保每个状态机以相同的顺序执行完全相同的命令。例如，当leader提交多个日志条目时，follower可能不可用，那么它可以被选为leader并用新的条目覆盖这些条目;因此，不同的状态机可能执行不同的命令序列。</p><p>​本节通过添加服务器可以被选为领导者的限制来完成Raft算法。该限制确保任何给定任期的leader包含在前一任期中提交的所有条目(图3中的leader完整性属性)。考虑到选举限制，我们将使提交规则更加精确。最后，我们给出了Leader完备性的证明草图，并展示了它如何导致复制状态机的正确行为。</p><h4 id="V-4-1-选举限制"><a href="#V-4-1-选举限制" class="headerlink" title="V.4.1 选举限制"></a>V.4.1 选举限制</h4><p>​在任何基于领导者的共识算法中，领导者最终必须存储所有已提交的日志条目。在一些共识算法中，如Viewstamped replication，即使leader最初没有包含所有提交的条目，也可以被选举出来。这些算法包含额外的机制来识别缺失的条目，并在选举过程中或之后不久将它们传输给新的领导者。不幸的是，这会导致相当多的附加机制和复杂性。Raft使用了一种更简单的方法，它保证从每一个新的leader被选举的那一刻起，所有以前的承诺条目都存在于leader上，而不需要将这些条目转移到leader上。这意味着日志条目只在一个方向上流动，从领导者到追随者，并且领导者永远不会覆盖其日志中的现有条目。</p><p>​Raft使用投票过程来阻止候选人赢得选举，除非其日志包含所有已提交的条目。候选人必须与集群的大多数成员联系才能当选，这意味着每个提交的条目必须至少出现在其中一台服务器中。如果候选日志至少与大多数日志中的任何其他日志一样最新(“最新”的定义在下面)，那么它将保存所有已提交的条目。RequestVote RPC实现了这个限制:RPC包含关于候选人日志的信息，如果投票人自己的日志比候选人的日志更新，投票人就拒绝投票。</p><p>​Raft通过比较日志中最后条目的索引和期限来确定两个日志中哪一个是最新的。如果日志的最后条目具有不同的术语，那么具有后一个术语的日志是最新的。如果日志以相同的期限结束，那么哪个日志越长，哪个日志就越最新。</p><h4 id="V-4-2-提交以前的条目"><a href="#V-4-2-提交以前的条目" class="headerlink" title="V.4.2 提交以前的条目"></a>V.4.2 提交以前的条目</h4><p><img src="/../imgs/raft-1/image-20240315215118470.png" alt="图8"></p><p>​如5.3节所述，leader知道，一旦条目被存储在大多数服务器上，它当前期限的条目就被提交。如果leader在提交条目之前崩溃，未来的leader将尝试完成对条目的复制。然而，一个leader不能立即得出结论，一个前一个term的条目一旦存储在大多数服务器上就被提交了。图8说明了一种情况，其中旧日志条目存储在大多数服务器上，但仍然可以被未来的领导者覆盖。</p><p>​为了消除图8所示的问题，Raft不会通过计算副本来提交以前条目中的日志条目。通过计算副本，只提交leader当前任期内的日志条目;一旦以这种方式提交了当前项中的一个条目，那么由于日志匹配属性，所有先前的条目都将间接提交。在某些情况下，leader可以安全地得出一个较旧的日志条目已提交的结论(例如，如果该条目存储在每个服务器上)，但是Raft为了简单起见采用了更保守的方法。</p><p>​Raft在承诺规则中引入了这种额外的复杂性，因为当leader复制前一项的条目时，日志条目保留其原始的条目编号。在其他共识算法中，如果一个新的leader从先前的“term”中重复复制条目，它必须使用新的“term number”。Raft的方法可以更容易地推断日志条目，因为它们在不同的时间和日志中保持相同的项数。此外，Raft中的新leader发送的以前条目的日志条目比其他算法少(其他算法必须发送冗余的日志条目来重新编号，然后才能提交)。</p><h4 id="V-4-3-安全论证"><a href="#V-4-3-安全论证" class="headerlink" title="V.4.3 安全论证"></a>V.4.3 安全论证</h4><p><img src="/../imgs/raft-1/image-20240315215633177.png" alt="图9:如果S1(任期T的领导者)从其任期提交了一个新的日志条目，并且S5被选为下一个任期U的领导者，那么必须至少有一个服务器(S3)接受该日志条目并投票给S5。"></p><p>​给定完整的Raft算法，我们现在可以更精确地论证Leader完备性成立(这个论证是基于安全证明;参见9.2节)。我们假设领先者完备性不成立，然后我们证明了一个矛盾。假设任期T的leader (leaderT)提交了一个来自其术语的日志条目，但是该日志条目没有被某个未来术语的leader存储。考虑最小的任期 U &gt; T，其leader (leaderU)不存储条目。</p><ol><li>承诺的条目必须在其选举时从领导u的日志中消失(领导永远不会删除或覆盖条目)。</li><li>leaderT在大多数集群上复制条目，而leaderU收到大多数集群的投票。因此，至少有一个服务器(“投票人”)接受了来自leaderT的条目并投票给了leadu，如图9所示。选民是达成矛盾的关键。</li><li>投票人必须在投票给leadt之前接受leadt的承诺条目;否则，它将拒绝来自leaderT的AppendEntries请求(其当前项将高于T)。</li><li>投票人在投票给领导u时仍然存储该条目，因为每个介入的领导都包含该条目(假设)，领导永远不会删除条目，而追随者只有在与领导冲突时才删除条目。</li><li>投票人将其选票授予了leaderU，因此leaderU的日志必须与投票人的日志一样是最新的。这导致了两个矛盾之一。</li><li>首先，如果投票者和leaderU共享相同的最后一个日志项，那么leaderU的日志必须至少和投票者的日志一样长，所以它的日志包含投票者日志中的每一个条目。这是一个矛盾，因为选民包含承诺的条目，而领导人被认为没有。</li><li>否则，领导人u的上一个对数项一定大于选民的对数项。而且，它比T大，因为投票人的最后一个日志项至少是T(它包含来自项T的承诺条目)。创建leadu的最后一个日志项的较早的领导者必须在其日志中包含承诺条目(通过假设)。那么，根据日志匹配属性，leaderU的日志必须也包含提交的条目，这是一个矛盾。</li><li>这就解决了矛盾。因此，所有大于T的项的前导必须包含所有在T项中提交的来自T项的项。</li><li>Log Matching Property保证未来的leader也将包含间接提交的条目，如图8(d)中的索引2。</li></ol><p>​间接地，如图8(d)中的索引2。给定Leader完整性属性，我们可以证明图3中的状态机安全属性，该属性表明，如果服务器在给定索引上应用了一个日志条目到其状态机，那么其他服务器将不会为相同的索引应用不同的日志条目。当服务器将一个日志条目应用到它的状态机时，它的日志必须与该条目之前的领导日志相同，并且该条目必须提交。现在考虑任何服务器应用给定日志索引的最低期限;日志完整性属性保证所有较高项的leader将存储相同的日志条目，因此在较低项中应用索引的服务器将应用相同的值。因此，状态机安全属性保持不变。</p><p>​最后，Raft要求服务器按照日志索引顺序应用条目。结合状态机安全属性，这意味着所有服务器将以相同的顺序向其状态机应用完全相同的日志条目集。</p><h3 id="V-5-追随者和候选人崩溃"><a href="#V-5-追随者和候选人崩溃" class="headerlink" title="V.5 追随者和候选人崩溃"></a>V.5 追随者和候选人崩溃</h3><p>​到目前为止，我们关注的是领导者的失败。跟随者和候选者崩溃比领导者崩溃更容易处理，它们的处理方式是一样的。如果一个follower或candidate崩溃，那么以后发送给它的RequestVote和AppendEntries rpc将失败。Raft通过无限重试来处理这些失败;如果崩溃的服务器重新启动，那么RPC将成功完成。如果服务器在完成RPC之后但在响应之前崩溃，那么它将在重新启动后再次接收相同的RPC。Raft rpc是幂等的，所以这不会造成伤害。例如，如果追随者接收到一个AppendEntries请求，该请求包含其日志中已经存在的日志条目，那么它将忽略新请求中的这些条目。</p><h3 id="V-6-时间和可用性"><a href="#V-6-时间和可用性" class="headerlink" title="V.6 时间和可用性"></a>V.6 时间和可用性</h3><p>​我们对Raft的要求之一是安全性不能依赖于时间:系统不能仅仅因为某些事件发生得比预期的快或慢而产生不正确的结果。然而，可用性(系统及时响应客户机的能力)必须不可避免地依赖于时间。例如，如果消息交换的时间比服务器崩溃之间的典型时间长，候选人就不会坚持足够长的时间来赢得选举;没有稳定的领导，Raft就无法前进。</p><p>​领袖选举是Raft中最关键的环节。只要系统满足以下时间要求，Raft就能够选出并维持一个稳定的leader:</p><p>​<font color='red'>broadcastTime≪ electionTimeout ≪ MTBF</font> </p><p>​在这个不等式中，broadcastTime是服务器向集群中的每个服务器并行发送rpc并接收它们的响应所需的平均时间;electionTime-out是5.2节中描述的选举超时;MTBF是单个服务器的平均故障间隔时间。广播时间应该比选举超时时间少一个数量级，这样领导者才能可靠地发送心跳消息，以防止追随者开始选举;考虑到用于选举暂停的随机方法，这种不平等也使得分裂投票不太可能。选举超时应该比MTBF小几个数量级，这样系统才能稳步前进。当leader崩溃时，系统将在选举超时期间不可用;我们希望这只代表总时间的一小部分。</p><p>​广播时间和MTBF是底层系统的属性，而选举超时是我们必须选择的。Raft的rpc通常要求接收方将信息持久化到稳定的存储中，因此广播时间可能在0.5ms到20ms之间，具体取决于存储技术。因此，选举超时可能在10ms到500ms之间。典型的服务器mtbf是几个月或更长时间，这很容易满足时间需求。</p><h2 id="VI-集群成员变更"><a href="#VI-集群成员变更" class="headerlink" title="VI 集群成员变更"></a>VI 集群成员变更</h2><p><img src="/../imgs/raft-1/image-20240315220334863.png" alt="图10"></p><p>​到目前为止，我们已经假设集群配置(参与共识算法的服务器集)是固定的。在实践中，有时需要更改配置，例如在服务器发生故障时更换服务器或更改复制的程度。虽然这可以通过使整个集群脱机、更新配置文件、然后重新启动集群来实现，但这会使集群在转换期间不可用。此外，如果有任何手动步骤，则有操作员出错的风险。为了避免这些问题，我们决定将配置更改自动化，并将其合并到Raft共识算法中。</p><p>​为了保证配置变更机制的安全性，在过渡期间不可能出现两名领导人在同一任期内当选的情况。不幸的是，服务器直接从旧配置切换到新配置的任何方法都是不安全的。一次自动切换所有服务器是不可能的，因此集群可能在转换期间分裂成两个独立的多数(参见图10)。</p><p>​为了确保安全，配置更改必须使用两阶段方法。有多种方法可以实现这两个阶段。例如，一些系统(例如，[22])使用第一阶段禁用旧配置，因此它不能处理客户端请求;然后，第二阶段启用新配置。在Raft中，集群首先切换到我们称之为联合共识的过渡配置;一旦联合共识被提交，系统就会转换到新的配置。联合共识结合了新旧两种配置:</p><ul><li>日志条目被复制到两种配置中的所有服务器。</li><li>任一配置中的任何服务器都可以作为leader。</li><li>协议(对于选举和进入承诺)需要从旧的和新的配置中分离多数。</li></ul><p>​联合共识允许单个服务器在不同的时间在配置之间转换，而不会出现安全问题。此外，联合共识允许集群在整个配置更改期间继续为客户机请求提供服务。</p><p>​集群配置使用复制日志中的特殊条目进行存储和通信;图11说明了配置更改过程。当leader接收到将配置从Cold更改为C（new）的请求时，它将联合共识(图中为C（old,new）)的配置存储为日志条目，并使用前面描述的机制复制该条目。一旦给定的服务器将新的配置条目添加到其日志中，它就会在以后的所有决策中使用该配置(服务器总是在其日志中使用最新的配置，而不管该条目是否已提交)。这意味着领导者将使用C（old,new）的规则来确定何时提交C（old,new）的日志条目。如果leader崩溃，根据获胜的候选人是否收到了Cold,new，来选择一个新的leader。无论如何，在此期间，中国不能做出单方面的决定。</p><p><img src="/../imgs/raft-1/image-20240315225354334.png" alt="图11"></p><p>​一旦提交了Cold,new，两个服务器都不能在未经对方批准的情况下做出决定，并且Leader完整性属性确保只有具有C（old,new）日志条目的服务器才能被选为Leader。现在，leader可以安全地创建描述C（new）的日志条目并将其复制到集群中。同样，一旦看到此配置，该配置将在每个服务器上生效。当在C（new）规则下提交新配置时，旧配置是不相关的，不在新配置中的服务器可以关闭。如图11所示，不存在C（old）和C（new）同时做出单边决策的情况;这保证了安全。</p><p>​对于重新配置，还有三个问题需要解决。第一个问题是，新服务器最初可能不存储任何日志条目。如果以这种状态将它们添加到集群中，它们可能需要一段时间才能赶上进度，在此期间可能无法提交新的日志条目。为了避免可用性差距，Raft在配置更改之前引入了一个额外的阶段，在这个阶段中，新服务器作为无投票成员加入集群(leader向它们复制日志条目，但它们不被认为是majority)。一旦新服务器赶上了集群的其余部分，就可以按照上面的描述进行重新配置。</p><p>​第二个问题是集群领导者可能不是新配置的一部分。在这种情况下，leader一旦提交了C（new）日志条目，就会退出(返回到follower状态)。这意味着会有一段时间(当它正在提交C(new)时)，当leader管理一个不包括它自己的集群时;它复制日志条目，但不认为自己占多数。leader转换发生在C（new）提交时，因为这是新配置可以独立操作的第一个点(总是可以从C(new)中选择leader)。在此之前，可能只有来自C(old)的服务器可以被选为leader。</p><p>​第三个问题是被移除的服务器(不在C(new)中的服务器)可能会破坏集群。这些服务器将不会接收到心跳，因此它们将超时并开始新的选举。然后，它们将发送带有新术语号的RequestVote rpc，这将导致当前的领导者恢复到追随者状态。新的领导人最终会被选举出来，但是被移除的服务器会再次超时，这个过程会重复，导致可用性差。</p><p>​为了防止这个问题，当服务器认为当前的leader存在时，它们会忽略RequestVote rpc。具体地说，如果服务器在听取当前领导者的最小选举超时时间内收到RequestVote RPC，则它不会更新其任期或授予其投票。这不会影响正常的选举，其中每个服务器在开始选举之前至少等待最小的选举超时。然而，它有助于避免被移除的服务器造成的中断:如果一个leader能够将心跳传送到它的集群，那么它就不会被更大的term number所取代。</p><h2 id="VII-日志压缩"><a href="#VII-日志压缩" class="headerlink" title="VII 日志压缩"></a>VII 日志压缩</h2><p>​Raft的日志在正常运行期间会增长，以包含更多的客户端请求，但在实际系统中，它不能无限制地增长。随着日志变长，它会占用更多的空间，并且需要更多的时间来重放。如果没有某种机制来丢弃日志中积累的过时信息，这将最终导致可用性问题。</p><p>​快照是最简单的压缩方法。在快照中，整个当前系统状态被写入稳定存储上的快照，然后直到该点的整个日志被丢弃。快照在Chubby和ZooKeeper中使用，本节的其余部分描述了Raft中的快照。</p><p>​增量压缩方法，如日志清理和日志结构合并树，也是可能的。它们一次对一小部分数据进行操作，因此它们随着时间的推移更均匀地分散了压缩的负载。它们首先选择一个数据区域，该区域累积了许多已删除和覆盖的对象，然后更紧凑地重写该区域的活动对象，并释放该区域。与快照相比，这需要大量额外的机制和复杂性，快照通过始终对整个数据集进行操作来简化问题。虽然日志清理需要修改Raft，但状态机可以使用与快照相同的接口实现LSM树。</p><p><img src="/../imgs/raft-1/image-20240315225801111.png" alt="图12"></p><p>​图12显示了Raft中快照的基本思想。每个服务器独立地获取快照，只覆盖其日志中提交的条目。大部分工作包括状态机将其当前状态写入快照。Raft还在快照中包含少量元数据:最后包含的索引是快照替换的日志中最后一个条目的索引(状态机应用的最后一个条目)，最后包含的术语是该条目的术语。保留这些内容是为了支持对快照之后的第一个日志条目进行AppendEntries一致性检查，因为该条目需要之前的日志索引和期限。为了启用集群成员变更(第6节)，快照还包括日志中上次包含索引时的最新配置。一旦服务器完成对快照的写入，它可能会删除直到最后包含的索引的所有日志条目，以及任何先前的快照。</p><p>​虽然服务器通常会独立地拍摄快照，但领导者偶尔必须向落后的追随者发送快照。当领导者已经丢弃了它需要发送给追随者的下一个日志条目时，就会发生这种情况。幸运的是，在正常操作中不太可能出现这种情况:跟随领导者的追随者已经有了这个条目。但是，异常缓慢的追随者或加入集群的新服务器(第6节)不会这样做。让这样的追随者与时俱进的方法是，领导者通过网络向其发送快照。</p><p><img src="/../imgs/raft-1/image-20240315225927519.png" alt="图13:InstallSnapshot RPC的摘要。快照被分成块进行传输;这为follower提供了每个块的生命迹象，因此它可以重置其选举计时器。"></p><p>​leader使用一个名为InstallSnapshot的新RPC向远远落后的follower发送快照;参见图13。当跟踪者接收到带有此RPC的快照时，它必须决定如何处理其现有的日志条目。通常，快照将包含收件人日志中尚未包含的新信息。在这种情况下，追随者丢弃其整个日志;它全部被快照取代，并且可能有与快照冲突的未提交条目。如果跟随者接收到描述其日志前缀的快照(由于重传或错误)，则快照所涵盖的日志条目将被删除，但快照后面的条目仍然有效，必须保留。</p><p>​这种快照方法违背了Raft的强领导原则，因为追随者可以在领导者不知情的情况下拍摄快照。然而，我们认为这种离开是合理的。虽然有一个领导者有助于在达成共识时避免冲突的决策，但在快照时已经达成了共识，因此没有决策冲突。数据仍然只能从领导者流向追随者，现在只有追随者可以重组他们的数据。</p><p>​我们考虑了另一种基于领导者的方法，其中只有领导者创建快照，然后将此快照发送给其每个追随者。然而，这有两个缺点。首先，将快照发送给每个关注者会浪费网络带宽并减慢快照进程。每个follower都已经拥有了生成自己的快照所需的信息，对于服务器来说，从其本地状态生成快照通常比通过网络发送和接收快照要便宜得多。其次，领导人的执行将更加复杂。例如，领导者需要向追随者发送快照，同时向他们复制新的日志条目，以便不阻止新的客户机请求。</p><p>​还有两个问题会影响快照性能。首先，服务器必须决定何时快照。如果服务器快照太频繁，会浪费磁盘带宽和能量;如果它的快照频率太低，就有耗尽存储容量的风险，并且会增加重新启动期间重播日志所需的时间。一个简单的策略是在日志达到固定大小(以字节为单位)时拍摄快照。如果将此大小设置为明显大于快照的预期大小，则用于快照的磁盘带宽开销将很小。</p><p>​第二个性能问题是，编写快照可能会花费大量时间，我们不希望这会延迟正常操作。解决方案是使用写时复制(copy-on-write)技术，这样就可以接受新的更新，而不会影响正在写入的快照。例如，用函数数据结构构建的状态机自然支持这一点。或者，可以使用操作系统的写时复制支持(例如Linux上的fork)来创建整个状态机的内存快照(我们的实现使用这种方法)。</p><h2 id="IIX-客户端交互"><a href="#IIX-客户端交互" class="headerlink" title="IIX 客户端交互"></a>IIX 客户端交互</h2><p>​本节描述客户端如何与Raft交互，包括客户端如何找到集群领导者以及Raft如何支持线性化语义。这些问题适用于所有基于共识的系统，Raft的解决方案与其他系统类似。</p><p>​Raft的客户将他们所有的请求发送给leader。当客户机第一次启动时，它连接到一个随机选择的服务器。如果客户端的第一选择不是leader，服务器将拒绝客户端的请求，并提供最近收到的leader的信息(AppendEntries请求包括leader的网络地址)。如果leader崩溃，客户端请求将超时;然后客户端使用随机选择的服务器再次尝试。</p><p>​Raft的目标是实现可线性化的语义(每个操作在调用和响应之间的某个点上似乎是瞬间执行的，只执行一次)。然而，正如目前所描述的，Raft可以多次执行命令:例如，如果leader在提交日志条目之后崩溃，但在响应客户端之前，客户端将使用新的leader重试命令，导致它被执行第二次。解决方案是让客户端为每个命令分配唯一的序列号。然后，状态机跟踪为每个客户机处理的最新序列号，以及相关的响应。如果它接收到一个序列号已经被执行的命令，它会立即响应而不重新执行请求。</p><p>​可以在不向日志中写入任何内容的情况下处理只读操作。然而，如果没有额外的措施，这将有返回陈旧数据的风险，因为响应请求的leader可能已经被它不知道的新leader所取代。可linearizable读一定不能返回陈旧的数据，Raft需要两个额外的预防措施来保证这一点，而不使用日志。首先，leader必须拥有提交条目的最新信息。Leader完整性属性保证Leader拥有所有已提交的条目，但在其任期开始时，Leader可能不知道哪些是已提交的条目。为了找出答案，它需要提交其任期中的一个条目。Raft通过让每个leader在其任期开始时提交一个空白的无操作条目到日志中来处理这个问题。其次，leader必须在处理一个只读请求之前检查它是否已经被废弃(如果一个最近的leader被选举出来，它的信息可能是陈旧的)。Raft通过让leader在响应只读请求之前与大多数集群交换心跳消息来处理这个问题。或者，leader可以依赖心跳机制来提供一种形式的租约[9]，但这将依赖于安全的定时(它假设有界时钟倾斜)。</p><h2 id="IX-执行与评估"><a href="#IX-执行与评估" class="headerlink" title="IX 执行与评估"></a>IX 执行与评估</h2><p>​我们已经将Raft作为复制状态机的一部分实现，该状态机存储RAMCloud的配置信息，并协助RAMCloud协调器的故障转移。Raft实现包含大约2000行c++代码，不包括测试、注释或空白行。源代码是免费提供的。根据本文的草稿，目前大约有25个独立的第三方开源的Raft实现[34]处于不同的开发阶段。此外，许多公司正在部署基于raft的系统。</p><p>​本节的其余部分使用三个标准来评估Raft:可理解性、正确性和性能。</p><h3 id="IX-1-可理解性"><a href="#IX-1-可理解性" class="headerlink" title="IX.1 可理解性"></a>IX.1 可理解性</h3><p><img src="/../imgs/raft-1/image-20240315230558611.png" alt="图15"></p><p>​为了衡量Raft相对于Paxos的可理解性，我们对斯坦福大学高级操作系统课程和加州大学伯克利分校分布式计算课程的高年级本科生和研究生进行了一项实验研究。我们录制了Raft和Paxos的视频讲座，并制作了相应的小测验。Raft讲座涵盖了这篇论文的内容，除了原木的压缩;Paxos讲座涵盖了足够的材料来创建一个等效的复制状态机，包括单命令Paxos、多命令Paxos、重新配置和实践中需要的一些优化(例如领导者选举)。这些测试测试了学生对算法的基本理解，也要求他们对极端情况进行推理。每个学生看了一个视频，做了相应的测试，看了第二个视频，做了第二个测试。大约一半的参与者先做了Paxos部分，另一半先做了Raft部分，以解释个人在表现和从第一部分研究中获得的经验上的差异。我们比较了参与者在每个测验中的得分，以确定参与者是否对Raft有更好的理解。</p><p>​我们试图在Paxos和Raft之间进行尽可能公平的比较。实验在两个方面对Paxos有利:43名参与者中有15人报告说他们之前有过Paxos的一些经验，Paxos的视频比Raft的视频长14%。如表1所示，我们已采取措施减轻潜在的偏倚来源。我们所有的资料都可以查阅。</p><p>​平均而言，参与者在Raft测试中的得分比Paxos测试高4.9分(在可能的60分中，Raft的平均得分为25.7分，Paxos的平均得分为20.8分);图14显示了他们的个人分数。配对t检验表明，在95%的置信度下，Raft分数的真实分布均值至少比Paxos分数的真实分布均值大2.5分。</p><p>​我们还创建了一个线性回归模型，可以根据三个因素预测新学生的测验分数:他们参加的测验，他们之前Paxos的经验程度，以及他们学习算法的顺序。该模型预测，测验的选择会产生12.5分的差异，从而有利于Raft。这明显高于观察到的4.9分的差异，因为许多实际学生之前都有Paxos的经验，这对Paxos有很大帮助，而对Raft的帮助略小。奇怪的是，该模型还预测，已经参加过Paxos测试的人在Raft上的得分要低6.3分;虽然我们不知道为什么，但这在统计上确实很重要。</p><p>​我们还在测试结束后对参与者进行了调查，看看他们觉得哪种算法更容易实现或解释;这些结果如图15所示。绝大多数参与者表示Raft更容易实现和解释(每个问题41个中有33个)。然而，这些自我报告的感觉可能不如参与者的测验分数可靠，参与者可能因为我们的假设(Raft更容易理解)而有偏见。</p><h3 id="IX-2-正确性"><a href="#IX-2-正确性" class="headerlink" title="IX.2 正确性"></a>IX.2 正确性</h3><p>​我们已经开发了第5节中描述的共识机制的正式规范和安全性证明。正式规范[31]使用TLA+规范语言[17]使得图2中总结的信息完全精确。它大约有400行，是证明的主体。对于任何实现Raft的人来说，它本身也很有用。我们已经用TLA证明系统[7]机械地证明了对数完备性。然而，这种证明依赖于没有经过机械检查的不变量(例如，我们还没有证明规范的类型安全性)。此外，我们已经写了一个状态机安全属性的非正式证明[31]，它是完整的(它只依赖于规范)和相对精确的(大约3500字长)。</p><h3 id="IX-3-性能"><a href="#IX-3-性能" class="headerlink" title="IX.3 性能"></a>IX.3 性能</h3><p><img src="/../imgs/raft-1/image-20240315230821442.png" alt="图16:检测和替换崩溃的leader的时间。顶部的图改变了选举超时的随机性，底部的图缩放了最小的选举超时。每条线代表1000次试验(“150-150ms”的100次试验除外)，对应于一个特定的选举超时选择;例如，“150-155ms”表示在150ms到155ms之间随机且均匀地选择选举超时。这些测量是在一个由5个服务器组成的集群上进行的，广播时间大约为15毫秒。对于包含9台服务器的集群，结果类似。"></p><p>​Raft的性能与Paxos等其他共识算法类似。对于性能来说，最重要的情况是当一个已建立的leader复制新的日志条目时。Raft使用最少数量的消息(从leader到一半集群的单次往返)实现了这一点。也有可能进一步提高Raft的性能。例如，它很容易支持批处理和流水线请求，以获得更高的吞吐量和更低的延迟。文献中对其他算法提出了各种优化;其中许多可以应用到Raft中，但我们将其留给未来的工作。</p><p>​我们使用Raft实现来衡量Raft领导者选举算法的性能，并回答了两个问题。首先，选举过程会很快趋同吗?其次，在leader崩溃后可以实现的最小停机时间是多少?</p><p>​为了测量leader的选举，我们反复地使一个由5个服务器组成的集群的leader崩溃，并计算检测到崩溃和选举新leader所花费的时间(参见图16)。为了产生最坏的情况，每个试验中的服务器具有不同的日志长度，因此一些候选人没有资格成为领导者。此外，为了鼓励分裂投票，我们的测试脚本在终止其进程之前触发了来自leader的心跳rpc的同步广播(这近似于leader在崩溃之前复制新日志条目的行为)。leader在心跳间隔内均匀随机崩溃，心跳间隔为所有测试的最小选举超时的一半。因此，最小的可能停机时间大约是最小选举超时的一半。</p><p>​图16中最上面的图表显示，选举超时中的少量随机化足以避免选举中的分裂投票。在没有随机性的情况下，在我们的测试中，由于许多选票分裂，领导人选举持续花费超过10秒的时间。仅仅增加5ms的随机性就有很大帮助，导致停机时间中值为287ms。使用更多的随机性可以改善最坏情况下的行为:当随机性为50ms时，最坏情况下的完成时间(超过1000次试验)为513ms。</p><p>​图16底部的图表显示，可以通过减少选举超时来减少停机时间。在选举超时为12-24ms的情况下，平均只需35ms就能选出一个leader(最长的一次试验花费了152ms)。然而，将超时时间降低到超过这个点违反了Raft的时间要求:在其他服务器开始新的选举之前，领导者很难广播心跳。这可能导致不必要的领导更改，并降低整个系统的可用性。我们建议使用保守的选举超时，例如150-300ms;这样的暂停不太可能导致不必要的领导人变动，而且仍然会提供良好的可用性。</p><h2 id="X-总结"><a href="#X-总结" class="headerlink" title="X 总结"></a>X 总结</h2><p>​算法的设计通常以正确性、效率和&#x2F;或简洁性为主要目标。虽然这些都是有价值的目标，但我们相信可理解性同样重要。在开发人员将算法转化为实际实现之前，其他目标都无法实现，而实际实现将不可避免地偏离并扩展已发布的形式。除非开发人员对算法有深刻的理解，并且能够创建关于它的直觉，否则他们很难在实现中保留其理想的属性。</p><p>​在本文中，我们讨论了分布式共识的问题，其中一个被广泛接受但难以理解的算法Paxos多年来一直挑战着学生和开发人员。我们开发了一种新的算法Raft，我们已经证明它比Paxos更容易理解。我们也相信Raft为系统构建提供了更好的基础。将可理解性作为主要设计目标改变了我们设计《Raft》的方式;随着设计的进展，我们发现自己重复使用了一些技术，比如分解问题和简化状态空间。这些技术不仅提高了Raft的可理解性，而且使我们更容易相信它的正确性。</p>]]></content>
    
    
    <categories>
      
      <category>mit6.824</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式系统</tag>
      
      <tag>mit6.824</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>mapreduce</title>
    <link href="/2024/03/14/mapreduce/"/>
    <url>/2024/03/14/mapreduce/</url>
    
    <content type="html"><![CDATA[<h1 id="MapReduce-在大型集群上的简易数据处理"><a href="#MapReduce-在大型集群上的简易数据处理" class="headerlink" title="MapReduce:在大型集群上的简易数据处理"></a>MapReduce:在大型集群上的简易数据处理</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>​MapReduce是一种用于处理和生成大型数据集的编程模型和相关实现。用户使用map函数处理kv对，生成一个中间value和中间key，使用reduce函数merge所有的中间kv键。很多现实世界任务都可以用这个模型来表示。</p><p>​用这种函数式风格编写的程序被自动并行化，并在大量的商用机器上执行。运行时系统负责对输入数据进行分区、在一组机器上调度程序的执行、处理机器故障以及管理所需的机器间通信等细节。这让程序员不需要理解并行和分布式系统就能很轻易地使用大型分布式系统的资源。</p><h2 id="1-介绍-sweat-drops"><a href="#1-介绍-sweat-drops" class="headerlink" title="1 介绍:sweat_drops:"></a>1 介绍:sweat_drops:</h2><p>​在过去的五年中，作者和谷歌的许多其他人已经实现了数百种特殊用途的计算，这些计算处理大量的原始数据，如抓取的文档、web请求日志等，以计算各种派生数据，如倒排索引、web文档的图形结构的各种表示、每个主机抓取的页面数量的摘要、给定一天中最频繁的查询集等。大多数这样的计算在概念上是直截了当的。然而，输入数据通常很大，计算必须分布在数百或数千台机器上，以便在合理的时间内完成。如何并行化计算、分布数据和处理故障等问题，使得原始的简单计算用大量复杂的代码来处理这些问题变得模糊不清。</p><p>​作为对这种复杂性的反应，我们设计了一个新的抽象，它允许我们表达我们试图执行的简单计算，但隐藏了库中并行化、容错、数据分布和负载平衡的混乱细节。我们的抽象受到Lisp和其他函数式语言中map和reduce原语的启发。我们意识到，大多数计算涉及对输入中每个逻辑“记录”应用map操作，以计算一组中间键&#x2F;值对，然后对共享同一键的所有值应用reduce操作，以便适当地组合派生数据。通过使用带有用户指定map和reduce操作的功能模型，我们能够轻松并行化大型计算，并将重新执行作为主要容错机制。</p><p>​这个工作的主要贡献是一个简单但强大的支持大规模计算的自动并行化和分布的接口。与此接口的实现相结合，在大型商用pc集群上实现高性能。第2节描述了基本的编程模型，并给出了几个示例。第3节描述了针对基于集群的计算环境量身定制的MapReduce接口的实现。第4节描述了我们认为有用的编程模型的几个改进。第5节对各种任务的实现进行了性能度量。第6节探讨了MapReduce在Google中的使用，包括我们使用它作为重写我们的生产索引系统的基础的经验。第7节讨论了相关的和未来的工作。</p><h2 id="2-编程模型-sweat-drops"><a href="#2-编程模型-sweat-drops" class="headerlink" title="2 编程模型:sweat_drops:"></a>2 编程模型:sweat_drops:</h2><p>​计算需要一组kv对输入，并且输出一组kv对。<strong>mapreduce</strong>主要是两个函数：<strong>Map</strong>和<strong>Reduce</strong>。</p><p>​<strong>Map</strong>接受一个输入对并且产生一个中间kv对。MapReduce库将与中间key<strong>I</strong>相同的的所有中间值分组，并且把它们传递到Reduce函数中。</p><p>​<strong>Reduce</strong>函数接受一个中间key<strong>I</strong>和一组与key相对应的value，它将这些value合并起来形成一个可能更小的值集，一般是输出一个key一个value。中间值通过迭代器提供给用户的reduce函数。这允许我们处理大到内存无法容纳的值列表。</p><h3 id="2-1-Example"><a href="#2-1-Example" class="headerlink" title="2.1 Example"></a>2.1 Example</h3><p>​单词计数器，伪代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">map</span>(String key, String value): <br>// key: document name <br>// value: document contents <br><span class="hljs-keyword">for</span> each word w <span class="hljs-keyword">in</span> value: <br>EmitIntermediate(w, <span class="hljs-string">&quot;1&quot;</span>); <br><br>reduce(String key, Iterator values): <br>// key: a word <br>// values: a <span class="hljs-built_in">list</span> of counts <span class="hljs-built_in">int</span> result = <span class="hljs-number">0</span>; <br><span class="hljs-keyword">for</span> each v <span class="hljs-keyword">in</span> values: <br>result += ParseInt(v); <br>Emit(AsString(result));<br></code></pre></td></tr></table></figure><p>​map函数发出每个单词加上相关的出现次数计数,reduce函数将针对特定单词发出的所有计数求和。</p><p>​此外，用户编写代码，用输入和输出文件的名称以及可选的调优参数填充mapreduce规范对象。然后，用户调用MapReduce函数，将规范对象传递给它。用户的代码与MapReduce库(用c++实现)链接在一起。附录A包含这个示例的完整程序文本。</p><h3 id="2-2-Types"><a href="#2-2-Types" class="headerlink" title="2.2 Types"></a>2.2 Types</h3><p>​尽管前面的伪代码是根据字符串输入和输出编写的，但从概念上讲，用户提供的map和reduce函数具有相关的类型:</p><p><img src="/../imgs/mapreduce/image-20240314162209411.png" alt="image-20240314162209411"></p><p>​输入键和值是从与输出键和值不同的域中绘制的。此外，中间键和值与输出键和值来自相同的domain。</p><p>​我们的c++实现将字符串传递给用户定义函数，并将其留给用户代码在字符串和适当类型之间进行转换。</p><h3 id="2-3-More-Examples"><a href="#2-3-More-Examples" class="headerlink" title="2.3 More Examples"></a>2.3 More Examples</h3><p>​Distributed Grep: 如果map函数匹配提供的模式，则会发出一行。reduce函数是一个恒等函数，它只是将提供的中间数据复制到输出。</p><p>​Count of URL Access Frequency: map函数处理web页面请求日志，输出&lt;URL,1&gt;。reduce函数将同一URL的所有值相加，并发出一个&lt; RL,total count&gt;对。</p><p>​Reverse Web-Link Graph: map函数为在名为source的页面中找到的每个指向目标URL的链接输出&lt;target,source&gt;对。reduce函数将与给定目标URL相关联的所有源URL的列表连接起来，并发出对:&lt;target, list(source)&gt;</p><p>​Term-Vector per Host: 术语向量是将文档或一组文档中最重要的单词总结为&lt;word, frequency&gt;对的列表。map函数会针对每个输入文档生成一个&lt;hostname, term vector&gt;对（其中主机名从文档的URL中提取）。reduce函数会合并给定主机下所有文档的术语向量，将它们相加，并丢弃不常见的术语，最终输出&lt;hostname, term vector&gt;对。</p><p>​Inverted Index: map函数解析每个文档，并发出&lt;word,document ID&gt;对的序列。reduce函数接受给定单词的所有对，对相应的文档ID进行排序并发出&lt;word, list(文档ID)&gt;对。所有输出对的集合形成一个简单的倒排索引。很容易增加这个计算来跟踪单词的位置。</p><p>​Distributed Sort: map函数从每个记录中提取键，并发出一个&lt;key,record&gt;对。reduce函数不加更改地发出所有对。这种计算依赖于第4.1节中描述的分区工具和第4.2节中描述的排序属性。</p><h2 id="3-实现"><a href="#3-实现" class="headerlink" title="3 实现"></a>3 实现</h2><p><img src="/../imgs/mapreduce/image-20240314163016983.png" alt="图1：执行概述"></p><p>​MapReduce接口可能有许多不同的实现。正确的选择取决于环境。例如，一种实现可能适用于小型共享内存机器，另一种适用于大型NUMA多处理器，还有一种适用于更大的联网机器集合。</p><p>​本节描述了针对Google广泛使用的计算环境的实现:大型商用pc集群通过交换以太网连接在一起。在我们的环境中:</p><ol><li>机器通常是运行Linux的双处理器x86处理器，每台机器有2-4 GB内存。</li><li>使用的是商用网络硬件——通常在机器级别上是100兆比特&#x2F;秒或1千兆比特&#x2F;秒，但总体对分带宽平均要少得多。</li><li>集群由数百或数千台机器组成，因此机器故障很常见。</li><li>存储由直接连接到单个机器上的廉价IDE磁盘提供。内部开发的分布式文件系统用于管理存储在这些磁盘上的数据。文件系统使用复制在不可靠的硬件之上提供可用性和可靠性。</li><li>用户向调度系统提交作业。每个作业由一组任务组成，并由调度器映射到集群中的一组可用机器。</li></ol><h3 id="3-1-执行概述"><a href="#3-1-执行概述" class="headerlink" title="3.1 执行概述"></a>3.1 执行概述</h3><p>​通过自动将输入数据划分为M段，Map调用可以在多台机器上进行分布式处理。不同的机器可以并行处理输入分割。Reduce调用是通过使用分区函数（例如hash(key) mod R）将中间键空间划分为R块来进行分发的。用户可以指定要使用的分区数量(R)和分区函数。</p><p>​图1显示了我们实现中MapReduce操作的整体流程。当用户程序调用MapReduce函数时，会发生以下一系列动作(图1中的编号标签对应于下面列表中的数字):</p><ol><li>MapReduce库将输入文件从m个16-64mb的小文件，然后，它在一个机器集群上启动该程序的许多副本。</li><li>这个节目的其中一份拷贝是特别的——master。其余的是由master分配工作的worker。有M个map任务和R个reduce任务要分配。主机选择空闲的worker，并为每个worker分配一个map任务或reduce任务。</li><li>被分配映射任务的worker线程读取相应输入分割的内容。它从输入数据中解析键&#x2F;值对，并将每对传递给用户定义的Map函数。Map函数产生的中间键&#x2F;值对在内存中进行缓冲。</li><li>周期性地将缓冲对写入本地磁盘，并通过分区函数划分为R个区域。这些缓冲对在本地磁盘上的位置被传递回主服务器，主服务器负责将这些位置转发给reduce worker。</li><li>当主服务器通知reduce worker有关这些位置时，它使用远程过程调用从map worker的本地磁盘读取缓冲数据。当reduce工作程序读取了所有中间数据后，它按中间键对数据进行排序，以便将所有出现的相同键分组在一起。排序是必要的，因为通常有许多不同的键映射到相同的reduce任务。如果中间数据量太大，内存无法容纳，则使用外部排序。</li><li>reduce worker遍历已排序的中间数据，对于遇到的每个唯一的中间键，它将键和相应的中间值集传递给用户的reduce函数。Reduce函数的输出被附加到这个Reduce分区的最终输出文件中。</li><li>当所有map任务和reduce任务完成后，主程序唤醒用户程序。此时，用户程序中的MapReduce调用返回到用户代码。</li></ol><p>​成功完成后，maprereduce执行的输出在R输出文件中可用(每个reduce任务一个，文件名由用户指定)。通常，用户不需要将这些R输出文件合并到一个文件中——他们经常将这些文件作为输入传递给另一个MapReduce调用，或者从另一个能够处理分区为多个文件的输入的分布式应用程序中使用它们。</p><h3 id="3-2-master数据结构"><a href="#3-2-master数据结构" class="headerlink" title="3.2 master数据结构"></a>3.2 master数据结构</h3><p>​master保留了几个数据结构。对于每个map任务和reduce任务，它存储状态(空闲、正在进行或已完成)以及工作机器的标识(对于非空闲任务)。</p><p>​主节点是将中间文件区域的位置从map任务传播到reduce任务的通道。因此，对于每一个完成的map任务，master存储由map任务产生的R个中间文件区域的位置和大小。当地图任务完成时，会收到对该位置和大小信息的更新。这些信息被逐步推送给正在执行减少任务的工作人员。</p><h3 id="3-3-容错性"><a href="#3-3-容错性" class="headerlink" title="3.3 容错性"></a>3.3 容错性</h3><p>​由于MapReduce库的设计目的是帮助处理使用数百或数千台机器的大量数据，因此库必须优雅地容忍机器故障。</p><h4 id="worker"><a href="#worker" class="headerlink" title="worker"></a>worker</h4><p>​主服务器定期ping每个worker。如果在一定时间内没有收到来自worker的响应，则主程序将该worker标记为失败。该worker完成的任何map任务都将被重置回其初始空闲状态，因此可以在其他worker上进行调度。类似地，在失败的worker上正在进行的任何map任务或reduce任务也被重置为空闲，并有资格重新调度。</p><p>​完成的映射任务在发生故障时重新执行，因为它们的输出存储在故障机器的本地磁盘上，因此无法访问。完成的reduce任务不需要重新执行，因为它们的输出存储在全局文件系统中。</p><p>​当一个映射任务首先由工人a执行，然后由工人B执行(因为a失败了)，所有的执行reduce任务的worker会收到重新执行的通知。任何尚未从worker A读取数据的reduce任务都将从worker B读取数据。</p><p>​MapReduce对大规模worker故障具有弹性。例如，在一次MapReduce操作期间，正在运行的集群上的网络维护导致80台机器组成的组在几分钟内无法访问。MapReduce主节点只是重新执行无法到达的工作机器所做的工作，并继续向前推进，最终完成MapReduce操作。</p><h4 id="master"><a href="#master" class="headerlink" title="master"></a>master</h4><p>​让主写入上述主数据结构的定期检查点是很容易的。如果主任务终止，则可以从最后一个检查点状态开始新的副本。然而，考虑到只有一个主人，它不太可能失败;因此，如果主节点失败，我们当前的实现会中止MapReduce的计算。客户端可以检查这种情况，如果需要的话，可以重试MapReduce操作。</p><h4 id="故障时的语义表现"><a href="#故障时的语义表现" class="headerlink" title="故障时的语义表现"></a>故障时的语义表现</h4><p>​当用户提供的map和reduce操作符是其输入值的确定性函数时，我们的分布式实现产生的输出与整个程序的非错误顺序执行所产生的输出相同。</p><p>​我们依靠map的原子提交和reduce任务输出来实现这个属性。每个正在进行的任务将其输出写入私有临时文件。一个reduce任务生成一个这样的文件，一个map任务生成R个这样的文件(每个reduce任务生成一个)。当map任务完成时，worker向master发送一条消息，并在消息中包含R临时文件的名称。如果主机接收到已经完成的映射任务的完成消息，则忽略该消息。否则，它将在主数据结构中记录R文件的名称。</p><p>​当reduce任务完成时，reduce worker自动将其临时输出文件重命名为最终输出文件。如果在多台机器上执行相同的reduce任务，则将对相同的最终输出文件执行多个重命名调用。我们依赖底层文件系统提供的原子重命名操作来保证最终文件系统状态只包含一次reduce任务执行所产生的数据。</p><p>​我们的绝大多数map和reduce操作符都是确定性的，在这种情况下，我们的语义等同于顺序执行，这使得程序员很容易推断他们的程序行为。当map和&#x2F;或reduce操作符不确定时，我们提供较弱但仍然合理的语义。在存在非确定性操作符的情况下，特定reduce任务R1的输出相当于非确定性程序的顺序执行对R1产生的输出。然而，不同的reduce任务R2的输出可能对应于不确定性程序的不同顺序执行所产生的R2的输出。</p><p>​考虑map任务M和reduce任务R1和R2。设e(Ri)为所提交的Ri的执行(只有一次这样的执行)较弱的语义出现是因为e(R1)可能读取了一次M执行产生的输出，而e(R2)可能读取了另一次M执行产生的输出。</p><h3 id="3-4-Locality"><a href="#3-4-Locality" class="headerlink" title="3.4 Locality"></a>3.4 Locality</h3><p>​网络带宽在我们的计算环境中是一种相对稀缺的资源。我们利用输入数据(由GFS管理)存储在组成集群的机器的本地磁盘这一事实来节省网络带宽。GFS将每个文件划分为64 MB的块，并在不同的机器上存储每个块的几个副本(通常是3个副本)。MapReduce主程序将输入文件的位置信息考虑在内，并尝试在包含相应输入数据副本的机器上调度地图任务。如果失败，它会尝试在该任务输入数据的副本附近调度一个map任务(例如，在与包含数据的机器位于同一网络交换机上的工作机器上)。当在集群中相当一部分worker上运行大型MapReduce操作时，大多数输入数据都是在本地读取的，不消耗网络带宽。</p><h3 id="3-5-任务粒度"><a href="#3-5-任务粒度" class="headerlink" title="3.5 任务粒度"></a>3.5 任务粒度</h3><p>​我们将map阶段细分为M个片段，reduce阶段细分为R个片段，如上所述。理想情况下，M和R应该比工作机器的数量大得多。让每个worker执行许多不同的任务可以改善动态负载平衡，并且还可以在一个worker失败时加快恢复速度:它完成的许多map任务可以分散到所有其他worker机器上。</p><p>​在我们的实现中，M和R的大小是有实际限制的，因为主机必须做出O(M + R)个调度决策，并如上所述在内存中保持O(M * R)个状态。(然而，内存使用的恒定因素很小:状态的O(M * R)块由每个map任务&#x2F;reduce任务对大约一个字节的数据组成。)</p><p>​此外，R经常受到用户的约束，因为每个reduce任务的输出最终都在一个单独的输出文件中。在实践中，我们倾向于选择M，这样每个单独的任务大约有16 MB到64 MB的输入数据(这样上面描述的局部性优化是最有效的)，我们让R是我们期望使用的工作机器数量的一个小倍数。我们经常使用2000台工作机器，在M &#x3D; 200000和R &#x3D; 5000的情况下执行MapReduce计算。</p><h3 id="3-6-备份任务"><a href="#3-6-备份任务" class="headerlink" title="3.6 备份任务"></a>3.6 备份任务</h3><p>​导致MapReduce操作总时间延长的常见原因之一是“掉队者”:在计算过程中，一台机器花了很长时间才完成最后几个map或reduce任务中的一个。掉队者的出现有很多原因。例如，具有坏磁盘的机器可能会遇到频繁的可纠正错误，从而使其读取性能从30 MB&#x2F;s降低到1 MB&#x2F;s。集群调度系统可能已经调度了机器上的其他任务，由于CPU、内存、本地磁盘或网络带宽的竞争，导致它执行MapReduce代码的速度更慢。我们最近遇到的一个问题是机器初始化代码中的一个错误，它导致处理器缓存被禁用:受影响的机器上的计算速度减慢了一百多倍。</p><p>​我们有一个通用的机制来缓解掉队者的问题。当一个MapReduce操作接近完成时，master调度剩余正在执行的任务执行备份。每当主执行或备份执行完成时，任务就被标记为已完成。我们已经对这种机制进行了调优，使它通常只增加操作所使用的计算资源几个百分点。我们发现这大大减少了完成大型MapReduce操作的时间。例如，当备份任务机制被禁用时，5.3节中描述的排序程序要多花44%的时间来完成。</p><h2 id="4-改进"><a href="#4-改进" class="headerlink" title="4 改进"></a>4 改进</h2><p>​虽然简单编写Map和Reduce函数提供的基本功能足以满足大多数需求，但我们发现一些扩展很有用。本节将介绍这些特性。</p><h3 id="4-1-分区函数"><a href="#4-1-分区函数" class="headerlink" title="4.1 分区函数"></a>4.1 分区函数</h3><p>​MapReduce的用户可以指定他们想要的reduce任务&#x2F;输出文件数量(R)。使用中间键上的分区函数在这些任务之间对数据进行分区。提供了一个默认使用哈希函数进行分区(例如“hash(key) mod R”)，通常会产生相当均衡的分区结果。然而，在某些情况下，根据键值的其他函数对数据进行分区是有用的。例如，当输出键为url时，我们希望将同一主机上所有条目都放置在同一个输出文件中。为了支持这种情况，MapReduce库允许用户提供特殊的分区函数。例如，使用“hash(Hostname(urlkey)) mod R”作为分区函数将导致来自同一主机的所有url最终出现在相同的输出文件中。</p><h3 id="4-2-排序保证"><a href="#4-2-排序保证" class="headerlink" title="4.2 排序保证"></a>4.2 排序保证</h3><p>​保证在给定分区内，中间键&#x2F;值对按键或递增顺序处理。这种排序保证可以很容易地为每个分区生成排序的输出文件，当输出文件格式需要支持有效的按键随机访问查找时，或者输出的用户发现对数据进行排序很方便时，这是很有用的。</p><h3 id="4-3-Combiner"><a href="#4-3-Combiner" class="headerlink" title="4.3 Combiner"></a>4.3 Combiner</h3><p>​在某些情况下，每个map任务产生的中间键存在显著的重复，并且用户指定的Reduce函数是可交换的和关联的。第2.1节中的单词计数就是一个很好的例子。由于词频倾向于遵循Zipf分布，每个地图任务将产生成百上千条形式为&lt;the, 1&gt;的记录。所有这些计数将通过网络发送到一个Reduce任务，然后由Reduce函数将它们加在一起生成一个数字。我们允许用户指定一个可选的Combiner函数，该函数在数据通过网络发送之前对其进行部分合并。</p><p>​Combiner函数在每台执行映射任务的机器上执行。通常使用相同的代码来实现combiner和reduce函数。reduce函数和组合函数之间的唯一区别是MapReduce库如何处理函数的输出。reduce函数的输出被写入最终的输出文件。组合函数的输出被写入中间文件，该中间文件将被发送给reduce任务。</p><p>​部分组合显著加快了某些类型的MapReduce操作。附录A包含一个使用组合器的示例。</p><h3 id="4-4-输入和输出类型"><a href="#4-4-输入和输出类型" class="headerlink" title="4.4 输入和输出类型"></a>4.4 输入和输出类型</h3><p>​MapReduce库支持以几种不同的格式读取输入数据。比如，“text”模式输入将每行视为一个键&#x2F;值对:键是文件中的偏移量，值是该行的内容。另一种常见的支持格式存储按键排序的键&#x2F;值对序列。每个输入类型实现都知道如何将自己分割成有意义的范围，以便作为单独的map任务进行处理(例如，文本模式的范围分割确保范围分割仅在行边界发生)。用户可以通过提供简单阅读器界面的实现来添加对新输入类型的支持，尽管大多数用户只使用少数预定义输入类型中的一种。</p><p>​读取器不一定需要提供从文件读取的数据。例如，很容易定义从数据库或从内存中映射的数据结构中读取记录的读取器。</p><p>​以类似的方式，我们支持一组输出类型来生成不同格式的数据，并且用户代码很容易添加对新输出类型的支持。</p><h3 id="4-5-副作用"><a href="#4-5-副作用" class="headerlink" title="4.5 副作用"></a>4.5 副作用</h3><p>​在某些情况下，MapReduce的用户发现从他们的map和&#x2F;或reduce操作符生成辅助文件作为附加输出是很方便的。我们依靠应用程序编写器使这些副作用原子化和幂等化。通常，应用程序写入临时文件，并在完全生成该文件后自动重命名该文件。</p><p>​我们不支持单个任务生成的多个输出文件的原子两阶段提交。因此，产生具有跨文件一致性要求的多个输出文件的任务应该是确定性的。这种限制在实践中从来没有成为问题。</p><h3 id="4-6-跳过坏记录"><a href="#4-6-跳过坏记录" class="headerlink" title="4.6 跳过坏记录"></a>4.6 跳过坏记录</h3><p>​有时，用户代码中的错误会导致Map或Reduce函数在某些记录上崩溃。这样的bug会导致MapReduce操作无法完成。通常的做法是修复漏洞，但有时这是不可行的;也许这个bug是在一个第三方库中，源代码是不可用的。此外，有时忽略一些记录也是可以接受的，例如在对大型数据集进行统计分析时。我们提供了一种可选的执行模式，其中MapReduce库检测哪些记录导致确定性崩溃，并跳过这些记录，以便向前推进。</p><p>​每个工作进程安装一个信号处理程序，用于捕获分段违反和总线错误。在调用用户Map或Reduce操作之前，mapreduce库将参数的序列号存储在一个全局变量中。如果用户代码生成一个信号，信号处理程序发送一个包含序列号的“最后喘息”UDP数据包到MapReduce主服务器。当主服务器在一个特定的记录上看到多个失败时，它表明在下一次重新执行相应的Map或Reduce任务时应该跳过该记录。</p><h3 id="4-7-本地执行"><a href="#4-7-本地执行" class="headerlink" title="4.7 本地执行"></a>4.7 本地执行</h3><p>​Map或Reduce函数中的调试问题可能很棘手，因为实际的计算发生在分布式系统中，通常在数千台机器上，工作分配决策是由主机动态做出的。为了方便调试、分析和小规模测试，我们开发了MapReduce库的另一种实现，它在本地机器上顺序地执行MapReduce操作的所有工作。控件提供给用户，这样计算就可以限制在特定的地图任务上。用户用一个特殊的标志来调用他们的程序，然后可以很容易地使用他们认为有用的任何调试或测试工具(例如gdb)。</p><h3 id="4-8-状态信息"><a href="#4-8-状态信息" class="headerlink" title="4.8 状态信息"></a>4.8 状态信息</h3><p>​主服务器运行一个内部HTTP服务器，并导出一组状态页供人们使用。状态页显示计算的进度，例如已经完成了多少个任务、正在进行多少个任务、输入字节数、中间数据字节数、输出字节数、处理速率等。这些页面还包含到每个任务生成的标准错误和标准输出文件的链接。用户可以使用这些数据来预测计算需要多长时间，以及是否应该在计算中添加更多的资源。这些页面还可用于确定何时计算比预期慢得多。</p><p>​此外，顶级状态页显示哪些工人失败了，以及他们失败时正在处理哪些映射和减少任务。当试图诊断用户代码中的错误时，此信息非常有用。</p><h3 id="4-9-Counters"><a href="#4-9-Counters" class="headerlink" title="4.9 Counters"></a>4.9 Counters</h3><p>​MapReduce库提供了一个计数器工具来计算各种事件的发生次数。例如，用户代码可能想要计算处理的单词总数或索引的德语文档的数量等。</p><p>​要使用此功能，用户代码创建一个命名计数器对象，然后在Map和&#x2F;或Reduce函数中适当地增加计数器。例如:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs Python">Counter* uppercase; <br>uppercase = GetCounter(<span class="hljs-string">&quot;uppercase&quot;</span>); <br><span class="hljs-built_in">map</span>(String name, String contents): <br><span class="hljs-keyword">for</span> each word w <span class="hljs-keyword">in</span> contents: <br><span class="hljs-keyword">if</span> (IsCapitalized(w)): <br>uppercase-&gt;Increment(); <br>EmitIntermediate(w, <span class="hljs-string">&quot;1&quot;</span>);<br></code></pre></td></tr></table></figure><p>​来自各个工作机器的计数器值定期传播到主机器(在ping响应的基础上)。master从成功的map和reduce任务中聚合计数器值，并在MapReduce操作完成时返回给用户代码。当前计数器的值也显示在主状态页面上，以便人们可以观看实时计算的进度。在聚合计数器值时，主服务器消除了重复执行相同映射或reduce任务的影响，以避免重复计数。(重复执行可能来自我们使用备份任务和由于失败而重新执行任务。</p><p>)</p><p>​一些计数器值由MapReduce库自动维护，例如处理的输入键&#x2F;值对的数量和产生的输出键&#x2F;值对的数量。</p><p>​用户发现计数器功能对于安全检查MapReduce操作的行为很有用。例如，在一些MapReduce操作中，用户代码可能希望确保生成的输出对的数量恰好等于处理的输入对的数量，或者处理的德语文档的比例在处理的文档总数的某个可容忍的比例之内。</p><h2 id="5-Performance"><a href="#5-Performance" class="headerlink" title="5 Performance"></a>5 Performance</h2><p>主要是一些性能的测试，就分析图片吧</p><p>集群配置：所有的程序都在一个由大约1800台机器组成的集群上执行。每台机器都有两个2GHz英特尔至强处理器，支持超线程，4GB内存，两个160GB IDE磁盘和千兆以太网链路。这些机器被安排在一个两级树状交换网络中，根节点的总带宽约为100- 200gbps。所有的机器都在同一个托管设施中，因此任何一对机器之间的往返时间都小于1毫秒。在4GB内存中，大约有1-1.5GB是由集群上运行的其他任务保留的。这些程序是在一个周末的下午执行的，当时cpu、磁盘和网络大多处于空闲状态。</p><p><img src="/../imgs/mapreduce/image-20240314175218619.png" alt="图2:随时间变化的数据传输速率"></p><p>图2显示了计算随时间的进展。y轴表示扫描输入数据的速率。当更多的机器被分配到这个MapReduce计算时，速率逐渐回升，当分配了1764个worker时，速率超过30GB&#x2F;s。当地图任务完成时，速率开始下降，并在计算后80秒左右达到零。整个计算从开始到结束大约需要150秒。这包括大约一分钟的启动开销。开销是由于将程序传播到所有工作机器，以及延迟与GFS交互以打开1000个输入文件集并获得局部性优化所需的信息。</p><p><img src="/../imgs/mapreduce/image-20240314175700641.png" alt="图3:排序程序的不同执行随时间变化的数据传输速率"></p><p>图3 (a)显示了排序程序正常执行的进度。左上角的图表显示了读取输入的速率。速率峰值约为13gb &#x2F;s，并且很快就会消失，因为所有的map任务在200秒内就完成了。注意，输入速率小于grep。这是因为排序映射任务花费大约一半的时间和I&#x2F;O带宽将中间输出写入本地磁盘。grep对应的中间输出的大小可以忽略不计。</p><p>左中图显示了数据通过网络从map任务发送到reduce任务的速率。当第一个map任务完成时，shuffle就开始了。图中的第一个驼峰是第一批大约1700个reduce任务(整个MapReduce被分配了大约1700台机器，每台机器一次最多执行一个reduce任务)。在大约300秒的计算中，第一批reduce任务中的一些完成了，我们开始为剩余的reduce任务转移数据。所有的洗牌在计算后大约600秒完成</p><p>左下角的图表显示了reduce任务将排序后的数据写入最终输出文件的速率。在第一个洗牌周期的结束和写入周期的开始之间有一个延迟，因为机器忙于对中间数据进行排序。继续以大约2-4 GB&#x2F;s的速率写一段时间。所有的写操作在计算完成后大约850秒完成。包括启动开销在内，整个计算耗时891秒。这与目前TeraSort基准测试1057秒的最佳报告结果相似。</p><p>在图3 (b)中，我们展示了禁用备份任务的排序程序的执行。执行流与图3 (a)中所示的类似，除了有一个非常长的尾，几乎没有任何写活动发生。960秒后，除5个reduce任务外，其余的reduce任务都完成了。然而，这些最后几名落伍者直到300秒后才完成比赛。整个计算耗时1283秒，运行时间增加了44%。</p><p>在图3 (c)中，我们展示了排序程序的执行，在计算开始几分钟后，我们故意杀死了1746个工作进程中的200个。底层集群调度器立即重新启动这些机器上的新工作进程(因为只有进程被终止，机器仍然正常运行)。</p><h2 id="6-相关工作"><a href="#6-相关工作" class="headerlink" title="6 相关工作"></a>6 相关工作</h2><p>​许多系统提供了受限的编程模型，并利用这些约束自动并行化计算。例如，可以在N个处理器上使用并行前缀计算，在log N时间内对N个元素数组的所有前缀计算一个关联函数。MapReduce可以被认为是基于我们在现实世界中大量计算的经验对这些模型的简化和提炼。更重要的是，我们提供了可扩展到数千个处理器的容错实现。相比之下，大多数并行处理系统只在较小的规模上实现，并将处理机器故障的细节留给程序员。</p><p>​批量同步编程和一些MPI原语提供了更高级的抽象，使程序员更容易编写并行程序。这些系统和MapReduce之间的一个关键区别是，MapReduce利用一个受限的编程模型来自动并行化用户程序，并提供透明的容错。</p><p>​我们的局部性优化从活动磁盘等技术中获得灵感，其中计算被推进到靠近本地磁盘的处理元素中，以减少通过I&#x2F;O子系统或网络发送的数据量。我们在直接连接少量磁盘的普通处理器上运行，而不是直接在磁盘控制器处理器上运行，但一般方法是相似的。</p><p>​我们的备份任务机制类似于夏洛特系统中采用的急切调度机制。简单的渴望调度的缺点之一是，如果一个给定的任务导致重复的失败，整个计算无法完成。我们用跳过坏记录的机制修复了这个问题的一些实例。</p><p>​MapReduce的实现依赖于内部集群管理系统，该系统负责在大量共享机器上分发和运行用户任务。集群管理系统虽然不是本文的重点，但在精神上与Condor等其他系统相似。</p><p>​排序工具是MapReduce库的一部分，在操作上类似于NOW-Sort。源机器(map worker)对要排序的数据进行分区，并将其发送给R个reduce worker中的一个。每个reduce worker在本地(如果可能的话，在内存中)对其数据进行排序。当然NOW-Sort没有用户自定义的Map和Reduce函数，而这些函数使我们的库具有广泛的适用性。</p><p>​River提供了一种编程模型，其中进程通过在分布式队列上发送数据来相互通信。与MapReduce一样，River系统即使在异构硬件或系统扰动引入的不均匀性存在的情况下，也试图提供良好的平均情况性能。River通过仔细地调度磁盘和网络传输来实现这一点，以实现平衡的完成时间。mapreduce采用了不同的方法。通过限制编程模型，MapReduce框架能够将问题划分为大量细粒度任务。这些任务在可用的worker上动态调度，以便更快的worker处理更多的任务。受限制的编程模型还允许我们在作业结束时安排任务的冗余执行，这大大减少了存在不一致性(例如缓慢或卡住的工人)的完成时间。</p><p>​BAD-FS有一个与MapReduce非常不同的编程模型，而且与MapReduce不同的是，它的目标是在广域网上执行工作。然而，有两个基本的相似之处。(1)两个系统都使用冗余执行来恢复故障造成的数据丢失。(2)两个系统都使用位置感知调度来减少在拥挤的网络链路上发送的数据量。</p><p>​TACC是一种简化高可用性网络业务构建的系统。与MapReduce一样，它依赖于重新执行作为实现容错的机制。</p><h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7 总结"></a>7 总结</h2><p>​MapReduce编程模型已经在Google成功地用于许多不同的目的。我们把这一成功归因于几个原因。首先，该模型易于使用，即使对于没有并行和分布式系统经验的程序员也是如此，因为它隐藏了并行化、容错、局部优化和负载平衡的细节。其次，大量的问题很容易表达为MapReduce计算。例如，MapReduce用于为Google的生产网络搜索服务生成数据，用于排序、数据挖掘、机器学习和许多其他系统。第三，我们已经开发了一个MapReduce的实现，它可以扩展到由数千台机器组成的大型机器集群。该实现有效地利用了这些机器资源，因此适合用于Google遇到的许多大型计算问题。</p><p>​我们从这项工作中学到了一些东西。首先，限制编程模型使其易于并行化和分布计算，并使此类计算具有容错性。第二，网络带宽是一种稀缺资源。因此，我们系统中的许多优化都以减少通过网络发送的数据量为目标:局域优化允许我们从本地磁盘读取数据，并将中间数据的单个副本写入本地磁盘以节省网络带宽。第三，冗余执行可用于减少慢机的影响，并处理机器故障和数据丢失</p><h2 id="A-Word-Frequency"><a href="#A-Word-Frequency" class="headerlink" title="A Word Frequency"></a>A Word Frequency</h2><p>本节包含一个程序，该程序计算在命令行指定的一组输入文件中每个唯一单词的出现次数。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;mapreduce/mapreduce.h&quot;</span> </span><br><span class="hljs-comment">// User’s map function </span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">WordCounter</span> : <span class="hljs-keyword">public</span> Mapper &#123; <br><span class="hljs-keyword">public</span>: <br><span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">Map</span><span class="hljs-params">(<span class="hljs-type">const</span> MapInput&amp; input)</span> </span>&#123; <br><span class="hljs-type">const</span> string&amp; text = input.<span class="hljs-built_in">value</span>(); <br><span class="hljs-type">const</span> <span class="hljs-type">int</span> n = text.<span class="hljs-built_in">size</span>(); <br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; ) &#123; <br><span class="hljs-comment">// Skip past leading whitespace </span><br><span class="hljs-keyword">while</span> ((i &lt; n) &amp;&amp; <span class="hljs-built_in">isspace</span>(text[i])) <br>i++; <br>                <span class="hljs-comment">// Find word end </span><br>                <span class="hljs-type">int</span> start = i; <br>                <span class="hljs-keyword">while</span> ((i &lt; n) &amp;&amp; !<span class="hljs-built_in">isspace</span>(text[i])) <br>                i++; <br>                <span class="hljs-keyword">if</span> (start &lt; i) <br>                <span class="hljs-built_in">Emit</span>(text.<span class="hljs-built_in">substr</span>(start,i-start),<span class="hljs-string">&quot;1&quot;</span>); <br>&#125; <br>&#125; <br>&#125;; <br><span class="hljs-built_in">REGISTER_MAPPER</span>(WordCounter); <br><span class="hljs-comment">// User’s reduce function </span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Adder</span> : <span class="hljs-keyword">public</span> Reducer &#123; <br><span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">Reduce</span><span class="hljs-params">(ReduceInput* input)</span> </span>&#123; <br><span class="hljs-comment">// Iterate over all entries with the </span><br><span class="hljs-comment">// same key and add the values </span><br>int64 value = <span class="hljs-number">0</span>; <br><span class="hljs-keyword">while</span> (!input-&gt;<span class="hljs-built_in">done</span>()) &#123; <br>value += <span class="hljs-built_in">StringToInt</span>(input-&gt;<span class="hljs-built_in">value</span>()); <br>input-&gt;<span class="hljs-built_in">NextValue</span>(); <br>&#125; <br><br><span class="hljs-comment">// Emit sum for input-&gt;key() </span><br><span class="hljs-built_in">Emit</span>(<span class="hljs-built_in">IntToString</span>(value)); <br>&#125; <br>&#125;; <br><span class="hljs-built_in">REGISTER_REDUCER</span>(Adder); <br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-type">int</span> argc, <span class="hljs-type">char</span>** argv)</span> </span>&#123; <br><span class="hljs-built_in">ParseCommandLineFlags</span>(argc, argv); <br><br>MapReduceSpecification spec; <br><span class="hljs-comment">// Store list of input files into &quot;spec&quot; </span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt; argc; i++) &#123; <br>MapReduceInput* input = spec.<span class="hljs-built_in">add_input</span>(); <br>input-&gt;<span class="hljs-built_in">set_format</span>(<span class="hljs-string">&quot;text&quot;</span>); <br>input-&gt;<span class="hljs-built_in">set_filepattern</span>(argv[i]); <br>input-&gt;<span class="hljs-built_in">set_mapper_class</span>(<span class="hljs-string">&quot;WordCounter&quot;</span>); <br>&#125; <br><span class="hljs-comment">// Specify the output files: </span><br><span class="hljs-comment">///gfs/test/freq-00000-of-00100 </span><br><span class="hljs-comment">///gfs/test/freq-00001-of-00100 </span><br><span class="hljs-comment">//... </span><br>MapReduceOutput* out = spec.<span class="hljs-built_in">output</span>(); <br>out-&gt;<span class="hljs-built_in">set_filebase</span>(<span class="hljs-string">&quot;/gfs/test/freq&quot;</span>); <br>out-&gt;<span class="hljs-built_in">set_num_tasks</span>(<span class="hljs-number">100</span>); <br>out-&gt;<span class="hljs-built_in">set_format</span>(<span class="hljs-string">&quot;text&quot;</span>); <br>out-&gt;<span class="hljs-built_in">set_reducer_class</span>(<span class="hljs-string">&quot;Adder&quot;</span>); <br><br><span class="hljs-comment">// Optional: do partial sums within map </span><br><span class="hljs-comment">// tasks to save network bandwidth </span><br>out-&gt;<span class="hljs-built_in">set_combiner_class</span>(<span class="hljs-string">&quot;Adder&quot;</span>); <br><br><span class="hljs-comment">// Tuning parameters: use at most 2000 </span><br><span class="hljs-comment">// machines and 100 MB of memory per task </span><br>spec.<span class="hljs-built_in">set_machines</span>(<span class="hljs-number">2000</span>); <br>spec.<span class="hljs-built_in">set_map_megabytes</span>(<span class="hljs-number">100</span>); <br>spec.<span class="hljs-built_in">set_reduce_megabytes</span>(<span class="hljs-number">100</span>); <br><span class="hljs-comment">// Now run it MapReduceResult result; </span><br><span class="hljs-keyword">if</span> (!<span class="hljs-built_in">MapReduce</span>(spec, &amp;result)) <span class="hljs-built_in">abort</span>(); <br><span class="hljs-comment">// Done: ’result’ structure contains info </span><br><span class="hljs-comment">// about counters, time taken, number of </span><br><span class="hljs-comment">// machines used, etc. </span><br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>; <br>&#125; <br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>mit6.824</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式系统</tag>
      
      <tag>mit6.824</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>14th-March</title>
    <link href="/2024/03/14/14th-March/"/>
    <url>/2024/03/14/14th-March/</url>
    
    <content type="html"><![CDATA[<h1 id="To-do-List"><a href="#To-do-List" class="headerlink" title="To-do List"></a>To-do List</h1><ul><li><p><input checked="" disabled="" type="checkbox"> 算法</p><ul><li><input checked="" disabled="" type="checkbox"> 链表和分治</li></ul></li><li><p><input disabled="" type="checkbox"> 项目</p><ul><li><input checked="" disabled="" type="checkbox"> cmu15445</li><li><input disabled="" type="checkbox"> mit6.824</li><li><input disabled="" type="checkbox"> mit6.081</li></ul></li><li><p><input disabled="" type="checkbox"> 八股</p><ul><li><input checked="" disabled="" type="checkbox"> 操作系统</li><li><input checked="" disabled="" type="checkbox"> 计算机网络</li><li><input disabled="" type="checkbox"> 数据库</li><li><input disabled="" type="checkbox"> redis</li></ul></li><li><p><input checked="" disabled="" type="checkbox"> 日常总结</p></li></ul><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p>今天主要是分治和链表的操作的结合，虽然没有什么很难的知识点，但却是是难了很多</p><h4 id="1-排序链表"><a href="#1-排序链表" class="headerlink" title="1.排序链表"></a>1.<a href="https://leetcode.cn/problems/sort-list/description/?envType=study-plan-v2&envId=top-interview-150">排序链表</a></h4><p>题面：</p><p><img src="/../imgs/14th-March/image-20240314203533498.png" alt="lc排序链表"></p><p>题解：</p><p>​还记得合并两个有序链表，，，所以可以找到链表的中点，将链表拆成两个子链表<font color=red>(!快慢指针找中点)</font>,然后对两个子链表分别排序，最后再合并</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">//分治</span><br><span class="hljs-function">ListNode* <span class="hljs-title">sortList</span><span class="hljs-params">(ListNode* head, ListNode* tail)</span> </span>&#123;<br>       <span class="hljs-keyword">if</span> (head == <span class="hljs-literal">nullptr</span>) &#123;<br>           <span class="hljs-keyword">return</span> head;<br>       &#125;<br>       <span class="hljs-keyword">if</span> (head-&gt;next == tail) &#123;<br>           head-&gt;next = <span class="hljs-literal">nullptr</span>;<br>           <span class="hljs-keyword">return</span> head;<br>       &#125;<br>       ListNode* slow = head, *fast = head;<br>       <span class="hljs-keyword">while</span> (fast != tail) &#123;<br>           slow = slow-&gt;next;<br>           fast = fast-&gt;next;<br>           <span class="hljs-keyword">if</span> (fast != tail) &#123;<br>               fast = fast-&gt;next;<br>           &#125;<br>       &#125;<br>       ListNode* mid = slow;<br>       <span class="hljs-keyword">return</span> <span class="hljs-built_in">merge</span>(<span class="hljs-built_in">sortList</span>(head, mid), <span class="hljs-built_in">sortList</span>(mid, tail));<br>   &#125;<br>   <span class="hljs-comment">//合并两个有序链表</span><br>   <span class="hljs-function">ListNode* <span class="hljs-title">merge</span><span class="hljs-params">(ListNode* head1, ListNode* head2)</span> </span>&#123;<br>       ListNode* dummyHead = <span class="hljs-keyword">new</span> <span class="hljs-built_in">ListNode</span>(<span class="hljs-number">0</span>);<br>       ListNode* temp = dummyHead, *temp1 = head1, *temp2 = head2;<br>       <span class="hljs-keyword">while</span> (temp1 != <span class="hljs-literal">nullptr</span> &amp;&amp; temp2 != <span class="hljs-literal">nullptr</span>) &#123;<br>           <span class="hljs-keyword">if</span> (temp1-&gt;val &lt;= temp2-&gt;val) &#123;<br>               temp-&gt;next = temp1;<br>               temp1 = temp1-&gt;next;<br>           &#125; <span class="hljs-keyword">else</span> &#123;<br>               temp-&gt;next = temp2;<br>               temp2 = temp2-&gt;next;<br>           &#125;<br>           temp = temp-&gt;next;<br>       &#125;<br>       <span class="hljs-keyword">if</span> (temp1 != <span class="hljs-literal">nullptr</span>) &#123;<br>           temp-&gt;next = temp1;<br>       &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (temp2 != <span class="hljs-literal">nullptr</span>) &#123;<br>           temp-&gt;next = temp2;<br>       &#125;<br>       <span class="hljs-keyword">return</span> dummyHead-&gt;next;<br>   &#125;<br></code></pre></td></tr></table></figure><h4 id="2-环形子数组的最大和"><a href="#2-环形子数组的最大和" class="headerlink" title="2.环形子数组的最大和"></a>2.<a href="https://leetcode.cn/problems/maximum-sum-circular-subarray/solutions/2350660/huan-xing-zi-shu-zu-de-zui-da-he-by-leet-elou/?envType=study-plan-v2&envId=top-interview-150">环形子数组的最大和</a></h4><p><img src="/../imgs/14th-March/image-20240314205127381.png" alt="环形子数组的最大和"></p><p>题解：</p><p>​。。。明明说有什么<strong>Kadane</strong>算法，但是确实一点都没看到 还是普通的滑窗感觉（抄的官解，懒得写了主要是）</p><p>​</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">maxSubarraySumCircular</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = nums.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">leftMax</span><span class="hljs-params">(n)</span></span>;<br>        leftMax[<span class="hljs-number">0</span>] = nums[<span class="hljs-number">0</span>];<br>        <span class="hljs-type">int</span> leftSum = nums[<span class="hljs-number">0</span>];<br>        <span class="hljs-type">int</span> pre = nums[<span class="hljs-number">0</span>];<br>        <span class="hljs-type">int</span> res = nums[<span class="hljs-number">0</span>];<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt; n; i++) &#123;<br>            pre = <span class="hljs-built_in">max</span>(pre + nums[i], nums[i]);<br>            res = <span class="hljs-built_in">max</span>(res, pre);<br>            leftSum += nums[i];<br>            leftMax[i] = <span class="hljs-built_in">max</span>(leftMax[i - <span class="hljs-number">1</span>], leftSum);<br>        &#125;<br><br>        <span class="hljs-type">int</span> rightSum = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = n - <span class="hljs-number">1</span>; i &gt; <span class="hljs-number">0</span>; i--) &#123;<br>            rightSum += nums[i];<br>            res = <span class="hljs-built_in">max</span>(res, rightSum + leftMax[i - <span class="hljs-number">1</span>]);<br>        &#125;<br>        <span class="hljs-keyword">return</span> res;<br>    &#125;<br></code></pre></td></tr></table></figure><h2 id="项目"><a href="#项目" class="headerlink" title="项目"></a>项目</h2><p>今天主要是过了一边mapreduce，花了一下午。。。</p><p>中午主要把445的p3 task1解决了</p><p>seqscan insert delete indexscan</p><h2 id="八股"><a href="#八股" class="headerlink" title="八股"></a>八股</h2><h3 id="计算机网络"><a href="#计算机网络" class="headerlink" title="计算机网络"></a>计算机网络</h3><p><strong>DNS解析过程</strong></p><ol><li>先查询浏览器缓存是否有该域名对应的IP地址。</li><li>如果浏览器缓存中没有，会去计算机本地的Host文件中查询是否有对应的缓存。</li><li>如果Host文件中也没有则会向<strong>本地的DNS服务器</strong>发起一个DNS查询请求。</li><li>如果本地DNS解析器有该域名的IP地址，就会直接返回，进入过没有缓存该域名的解析记录，它会向<strong>根DNS服务器</strong>发出查询请求。根DNS服务器并不负责解析域名，但它能告诉本地DNS解析器应该向哪个顶级域名的DNS服务器继续查询。</li><li>本地DNS解析器接着向指定的<strong>顶级域名DNS服务器</strong>发出查询请求。权威DNS服务器是负责存储特定域名和IP地址映射的服务器。当权威DNS服务器收到查询请求时，它会查找”example.com“域名对应的IP地址，并将结果返回给本地DNS解析器。</li><li>本地DNS解析器将收到的IP地址返回给浏览器，并且还会将域名解析结果缓存在本地，以便下次访问时更快地相应。</li><li>浏览器发起连接：本地DNS解析器已经将IP地址返回给您的计算机，您的浏览器可以使用该IP地址与目标服务器建立连接，开始获取网页内容。</li></ol><p><img src="/../imgs/14th-March/image-20240314211600938.png" alt="DNS解析过程（1）"></p><p><img src="/../imgs/14th-March/image-20240314211634503.png" alt="DNS解析过程（2）"></p><p><img src="/../imgs/14th-March/image-20240314211744604.png" alt="DNS解析过程（3）"></p><h4 id="递归查询和迭代查询"><a href="#递归查询和迭代查询" class="headerlink" title="递归查询和迭代查询"></a>递归查询和迭代查询</h4><p>（1）递归查询</p><p>在递归查询中，DNS客户端向上层DNS服务器发起查询请求，并要求这些服务器直接提供完整的解析结果。递归查询的特点是，DNS客户端只需要发送一个查询请求，然后等待完整的解析结果。上层DNS服务器会自行查询下一级的服务器，并将最终结果返回给DNS客户端。</p><p>（2）迭代查询</p><p>在迭代查询中，DNS客户端向上层DNS服务器发起查询请求，但不要求直接提供完整的解析结果。相反，DNS客户端只是询问上层服务器⼀个更⾼级的域名服务器的地址，然后再⾃⾏向那个更⾼级的服务器发起查询请求，以此类推，直到获取完整的解析结果为⽌。</p><p>递归查询适合普通⽤户和客户端，⽽迭代查询适⽤于DNS服务器之间的通信。</p><h3 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h3><h4 id="调度算法"><a href="#调度算法" class="headerlink" title="调度算法"></a>调度算法</h4><p><img src="/../imgs/14th-March/image-20240314212242097.png" alt="调度算法总结"></p><p>（1）先来先服务（<strong>FCFS</strong>）</p><p>每次从就绪队列选择最先进入队列的进程，然后一直运行，知道进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。</p><p>这种算法虽然看上去公平，但是如果有一个长作业需要处理，后面的短作业需要处理很长时间。</p><p>先来先服务的特点是算法简单，对长作业比较有利，对短作业不利，适用于CPU繁忙型的系统，而不适用于I&#x2F;O繁忙型作业的系统。</p><p><img src="/../imgs/14th-March/image-20240314212552297.png" alt="FCFS"></p><p>（2）最短作业优先（SJF）</p><p>最短作业优先调度算法从就绪队列中选择一个估计运行时间最短的作业，将之调入到内存中运行，这有利于提高系统的吞吐量。</p><p>但是这对长作业十分不利，由于调度程序总是优先调度短作业，将会导致长作业长期不被调度，此外该算法也没有考虑到作业的紧迫程度，因此不能保证紧迫性作业会被及时处理。</p><p><img src="/../imgs/14th-March/image-20240314212803783.png" alt="SJF"></p><p>（3）高响应比优先调度算法</p><p>每次进行进程调度时，先计算<strong>响应比优先级</strong>，然后把<strong>响应比优先级</strong>最高的进程投入运行<br>$$<br>\text{优先权} &#x3D; \frac{\text{等待时间} + \text{要求服务时间}}{\text{要求服务时间}}<br>$$<br>根据公式可以知道</p><ul><li>作业的等待时间相同时，如果要求服务时间越短，则响应比更高，有利于短作业执行</li><li>当要求服务时间相同时，响应比由等待时间决定，如果等待时间越长，则响应比越高</li><li>对于长作业，作业的响应比可以随着等待时间的增加而提高</li></ul><p>（4）时间片轮转调度算法</p><p>每个进程被分配⼀个时间段，称为时间⽚（<strong>Quantum</strong>），即允许该进程在该时间段中运⾏。</p><ul><li>如果时间⽚⽤完，进程还在运⾏，那么将会把此进程从 CPU 释放出来，并把 CPU 分配给另外⼀个进程；</li><li>如果该进程在时间⽚结束前阻塞或结束，则 CPU立即进⾏切换；</li></ul><p>另外，时间⽚的⻓度就是⼀个很关键的点：</p><ul><li>如果时间片设的太短会导致过多的进程上下文切换，降低了CPU效率；</li><li>如果设的太长又可能引起对短作业进程的响应时间变长。</li></ul><p>一般来说，时间片设为20~50ms通常是一个比较合理的折中值。</p><p><img src="/../imgs/14th-March/image-20240314213700722.png" alt="时间片轮转"></p><p>（5）最高优先级调度算法</p><p>从就绪队列中选择最高优先级的进程进行运行，但进程的优先级可以分为静态优先级和动态优先级</p><ul><li>静态优先级：优先级在创建进程时已经确定，在进程运行期间保持不变，确定静态优先级的主要依据又进程类型，对资源的要求，用户要求。</li><li>动态优先级：进程运行过程中，根据进程运行时间和等待时间等因素调整进程的优先级</li></ul><p>但这种算法可能会导致低优先级的进程永远不被执行</p><p><img src="/../imgs/14th-March/image-20240314214039380.png" alt="最高优先级调度"></p><p>（6）多级队列调度算法</p><p>上⾯的各种调度算法是固定且单⼀的，⽆法满⾜系统中不同⽤户对进程调度策略的不同要求，多级队列调度算法在系统中设置多个就绪队列，将不同类型或性质的进程固定分配到不同的就绪队列，每个队列可以实施不同的调度算法。</p><p>（7）多级反馈队列调度算法</p><p>多级反馈队列调度算法融合了时间⽚轮转调度算法和优先级调度算法，通过动态调整进程的优先级和时间⽚⼤⼩，多级反馈队列调度算法可以兼顾多⽅⾯的系统⽬标</p><p>多级反馈队列调度算法的实现思想如下：</p><ul><li>设置多个就绪队列，并为每个队列赋予不同的优先级。第1级队列的优先级最⾼，第2级队列的优先级次之，其余队列的优先级逐个降低。</li><li>赋予各个队列的进程运⾏时间⽚的⼤⼩各不相同。在优先级越⾼的队列中，每个进程的时间⽚就越⼩。例如，第 i+1 级队列的时间⽚要⽐第i级队列的时间⽚⻓1倍。</li><li>每个队列都采⽤FCFS算法。当新进程进⼊内存后，⾸先将它放⼊第1级队列的末尾，按FCFS原则等待调度。当轮到该进程执⾏时，如它能在该时间⽚内完成，便可撤离系统。若它在⼀个时间⽚结束时尚未完成，调度程序将其转⼊第2级队列的末尾等待调度：若它在第2级队列中运⾏⼀个时间⽚后仍未完成，再将它放⼊第3级队列…，依此类推。当进程最后被降到第n级队列后，在第n级队列中便采⽤时间⽚轮转⽅式运⾏。</li><li>按队列优先级调度。仅当第1级队列为空时，才调度第2级队列中的进程运⾏；仅当第 1~i-1 级队列均为空时，才会调度第i级队列中的进程运⾏。若处理机正在执⾏第i级队列中的某进程时，⼜有新进程进⼊任⼀优先级较⾼的队列，此时须⽴即把正在运⾏的进程放回到第级队列的末尾，⽽把处理机分配给新到的⾼优先级进程。</li></ul><p>多级反馈队列的优势有以下几点：</p><ul><li>终端型作业用户：短作业优先。</li><li>短批处理作业用户：周转时间较短</li><li>长批处理作业用户：经过前面几个队列得到部分执行，不会长期得不到处理。</li></ul><p><img src="/../imgs/14th-March/image-20240314214242047.png" alt="多级反馈队列调度"></p><h4 id="Golang"><a href="#Golang" class="headerlink" title="Golang"></a>Golang</h4><h4 id="数组与切片有什么异同"><a href="#数组与切片有什么异同" class="headerlink" title="数组与切片有什么异同"></a>数组与切片有什么异同</h4><p>slice的底层数据是数组，slice是对数组的封装，它描述一个数组的片段。两者都可以通过下标来访问单个元素。</p><p>数组是定长的，长度定义好之后，不能再更改。在Go中，数组是不常见的，因为其长度是类型的一部分，限制了它的表达能力，比如[3]int和[4]int就是不同的类型。</p><p>而切片则非常灵活，它可以动态地扩容。切片的类型与长度无关。</p><p>数组就是一片连续的内存，slice实际上是一个结构体，包含三个字段：长度、容量、底层数组。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> slice <span class="hljs-keyword">struct</span> &#123;<br>array unsafe.Pointer <span class="hljs-comment">// 元素指针</span><br><span class="hljs-built_in">len</span>   <span class="hljs-type">int</span> <span class="hljs-comment">// 长度 </span><br><span class="hljs-built_in">cap</span>   <span class="hljs-type">int</span> <span class="hljs-comment">// 容量</span><br>&#125;<br></code></pre></td></tr></table></figure><p>slice的数据结构如下：</p><p><img src="/../imgs/14th-March/0.png" alt="切片数据结构"></p><p>注意，底层数组是可以被多个slice同时指向的，因此对一个slice的元素进行操作是有可能影响到其他slice的。</p><p>【引申1】 [3]int 和 [4]int 是同一个类型吗？</p><p>不是。因为数组的长度是类型的一部分，这是与 slice 不同的一点。</p><p>【引申2】 下面的代码输出是什么？</p><p>说明：例子来自<strong>《Go学习笔记》第四版</strong>，P43页。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> <span class="hljs-string">&quot;fmt&quot;</span><br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>slice := []<span class="hljs-type">int</span>&#123;<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>&#125;<br>s1 := slice[<span class="hljs-number">2</span>:<span class="hljs-number">5</span>]<br>s2 := s1[<span class="hljs-number">2</span>:<span class="hljs-number">6</span>:<span class="hljs-number">7</span>]<br><br>s2 = <span class="hljs-built_in">append</span>(s2, <span class="hljs-number">100</span>)<br>s2 = <span class="hljs-built_in">append</span>(s2, <span class="hljs-number">200</span>)<br><br>s1[<span class="hljs-number">2</span>] = <span class="hljs-number">20</span><br><br>fmt.Println(s1)<br>fmt.Println(s2)<br>fmt.Println(slice)<br>&#125;<br></code></pre></td></tr></table></figure><p>结果：</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs tap">[2<span class="hljs-number"> 3 </span>20]<br>[4<span class="hljs-number"> 5 </span>6<span class="hljs-number"> 7 </span>100 200]<br>[0<span class="hljs-number"> 1 </span>2<span class="hljs-number"> 3 </span>20<span class="hljs-number"> 5 </span>6<span class="hljs-number"> 7 </span>100 9]<br></code></pre></td></tr></table></figure><p><code>s1</code>从slice索引2（闭区间）到索引5（开区间），长度为3，容器默认到数组结尾，为8.<code>s2</code>从<code>s1</code>的索引2闭区间到索引6（开区间），容量到索引7（开区间），为5</p><p><img src="/../imgs/14th-March/1.png" alt="slice origin"></p><p>接着，向 <code>s2</code> 尾部追加一个元素 100：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs go">s2 = <span class="hljs-built_in">append</span>(s2, <span class="hljs-number">100</span>)<br></code></pre></td></tr></table></figure><p><code>s2</code> 容量刚好够，直接追加。不过，这会修改原始数组对应位置的元素。这一改动，数组和 <code>s1</code> 都可以看得到。</p><p><img src="/../imgs/14th-March/2.png" alt="append 100"></p><p>再次向 <code>s2</code> 追加元素200：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs go">s2 = <span class="hljs-built_in">append</span>(s2, <span class="hljs-number">100</span>)<br></code></pre></td></tr></table></figure><p>这时，<code>s2</code> 的容量不够用，该扩容了。于是，<code>s2</code> 另起炉灶，将原来的元素复制新的位置，扩大自己的容量。并且为了应对未来可能的 <code>append</code> 带来的再一次扩容，<code>s2</code> 会在此次扩容的时候多留一些 <code>buffer</code>，将新的容量将扩大为原始容量的2倍，也就是10了。</p><p><img src="/../imgs/14th-March/3.png" alt="append 200"></p><p>最后，修改 <code>s1</code> 索引为2位置的元素：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs go">s1[<span class="hljs-number">2</span>] = <span class="hljs-number">20</span><br></code></pre></td></tr></table></figure><p>这次只会影响原始数组相应位置的元素。它影响不到 <code>s2</code> 了，人家已经远走高飞了。</p><p><img src="/../imgs/14th-March/4.png" alt="s1[2]=20"></p><p>打印 <code>s1</code> 的时候，只会打印出 <code>s1</code> 长度以内的元素。所以，只会打印出3个元素，虽然它的底层数组不止3个元素。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>周六上午十点蚂蚁笔试，下午两点饿了么笔试（不是很匹配其实），周日看能不能面得物</p><p>感觉markdown还是不太熟练 啥时候进修一下子</p>]]></content>
    
    
    <categories>
      
      <category>diary</category>
      
    </categories>
    
    
    <tags>
      
      <tag>diary</tag>
      
      <tag>算法</tag>
      
      <tag>八股</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>13th-March</title>
    <link href="/2024/03/13/13th-March/"/>
    <url>/2024/03/13/13th-March/</url>
    
    <content type="html"><![CDATA[<h2 id="To-do-List"><a href="#To-do-List" class="headerlink" title="To-do List"></a>To-do List</h2><ul><li><p><input checked="" disabled="" type="checkbox"> 算法</p><ul><li><input checked="" disabled="" type="checkbox"> bfs &amp;&amp; trie树</li></ul></li><li><p><input disabled="" type="checkbox"> 项目</p><ul><li><input checked="" disabled="" type="checkbox"> cmu15445</li><li><input disabled="" type="checkbox"> mit6.824</li><li><input disabled="" type="checkbox"> mit6.081</li></ul></li><li><p><input disabled="" type="checkbox"> 八股</p><ul><li><input checked="" disabled="" type="checkbox"> 操作系统</li><li><input checked="" disabled="" type="checkbox"> 计算机网络</li><li><input disabled="" type="checkbox"> 数据库</li><li><input disabled="" type="checkbox"> redis</li></ul></li><li><p><input checked="" disabled="" type="checkbox"> 日常总结</p></li></ul><h3 id="1-算法"><a href="#1-算法" class="headerlink" title="1.算法"></a>1.算法</h3><h4 id="I-bfs"><a href="#I-bfs" class="headerlink" title="I.bfs"></a>I.bfs</h4><p><a href="https://leetcode.cn/problems/word-ladder/description/?envType=study-plan-v2&envId=top-interview-150">单词接龙</a></p><p>题面：<img src="/../imgs/13th-March/image-20240313171436208.png" alt="image-20240313171436208"></p><p>解答：其实都是很经典的队列bfs 和其他同类型的其他两个几乎一样 但是我也不知道为什么他是hard </p><p>用队列存储状态 然后再递归 理解bfs的精髓就好</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">while</span> (!q.<span class="hljs-built_in">empty</span>()) &#123;<br>            <span class="hljs-type">int</span> sz = q.<span class="hljs-built_in">size</span>();<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; sz; i++) &#123;<br>                string curr = q.<span class="hljs-built_in">front</span>();<br>                q.<span class="hljs-built_in">pop</span>();<br>                <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; l; j++) &#123;<br>                    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> k = <span class="hljs-number">0</span>; k &lt; <span class="hljs-number">26</span>; k++) &#123;<br>                        <span class="hljs-keyword">if</span> (<span class="hljs-string">&#x27;a&#x27;</span> + k != curr[j]) &#123;<br>                            string next = curr;<br>                            next[j] = <span class="hljs-string">&#x27;a&#x27;</span> + k;<br>                            <span class="hljs-keyword">if</span> (!visited.<span class="hljs-built_in">count</span>(next) &amp;&amp; cnt.<span class="hljs-built_in">count</span>(next)) &#123;<br>                                <span class="hljs-keyword">if</span> (next == end) &#123;<br>                                    <span class="hljs-keyword">return</span> step;<br>                                &#125;<br>                                q.<span class="hljs-built_in">emplace</span>(next);<br>                                visited.<span class="hljs-built_in">emplace</span>(next);<br>                            &#125;<br>                        &#125;<br>                    &#125;<br>                &#125;<br>            &#125;<br>            step++;<br>        &#125;<br></code></pre></td></tr></table></figure><h4 id="II-Trie树"><a href="#II-Trie树" class="headerlink" title="II.Trie树"></a>II.Trie树</h4><p><a href="https://leetcode.cn/problems/word-search-ii/description/?envType=study-plan-v2&envId=top-interview-150">单词搜索II</a></p><p>题面：</p><p><img src="/../imgs/13th-March/image-20240313171824850.png" alt="image-20240313171824850"></p><p>题解：就不放经典的Trie了，这个才是真正的应用，将每个单词insert，再遍历整个二维数组用dfs，能访问到的就加入答案</p><p>Trie模板：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">TrieNode</span> &#123;<br>    string word;<br>    unordered_map&lt;<span class="hljs-type">char</span>,TrieNode *&gt; children; <span class="hljs-comment">//还有就是可以用vector存 size26</span><br>    <span class="hljs-built_in">TrieNode</span>() &#123;<br>        <span class="hljs-keyword">this</span>-&gt;word = <span class="hljs-string">&quot;&quot;</span>;<br>    &#125;<br>&#125;;<br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">insert</span><span class="hljs-params">(TrieNode *root,<span class="hljs-type">const</span> string &amp; word)</span> </span>&#123;<br>    TrieNode *node = root;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> c : word) &#123;<br>        <span class="hljs-keyword">if</span> (!node-&gt;children.<span class="hljs-built_in">count</span>(c)) &#123;<br>            node-&gt;children[c] = <span class="hljs-keyword">new</span> <span class="hljs-built_in">TrieNode</span>();<br>        &#125;<br>        node = node-&gt;children[c];<br>    &#125;<br>    node-&gt;word = word;<br>&#125;<br></code></pre></td></tr></table></figure><p>dfs代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">dfs</span><span class="hljs-params">(vector&lt;vector&lt;<span class="hljs-type">char</span>&gt;&gt;&amp; board, <span class="hljs-type">int</span> x, <span class="hljs-type">int</span> y, TrieNode * root, set&lt;string&gt; &amp; res)</span> </span>&#123;<br>        <span class="hljs-type">char</span> ch = board[x][y];        <br>        <span class="hljs-keyword">if</span> (!root-&gt;children.<span class="hljs-built_in">count</span>(ch)) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>        &#125;<br>        root = root-&gt;children[ch];<br>        <span class="hljs-keyword">if</span> (root-&gt;word.<span class="hljs-built_in">size</span>() &gt; <span class="hljs-number">0</span>) &#123;<br>            res.<span class="hljs-built_in">insert</span>(root-&gt;word);<br>        &#125;<br><br>        board[x][y] = <span class="hljs-string">&#x27;#&#x27;</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">4</span>; ++i) &#123;<br>            <span class="hljs-type">int</span> nx = x + dirs[i][<span class="hljs-number">0</span>];<br>            <span class="hljs-type">int</span> ny = y + dirs[i][<span class="hljs-number">1</span>];<br>            <span class="hljs-keyword">if</span> (nx &gt;= <span class="hljs-number">0</span> &amp;&amp; nx &lt; board.<span class="hljs-built_in">size</span>() &amp;&amp; ny &gt;= <span class="hljs-number">0</span> &amp;&amp; ny &lt; board[<span class="hljs-number">0</span>].<span class="hljs-built_in">size</span>()) &#123;<br>                <span class="hljs-keyword">if</span> (board[nx][ny] != <span class="hljs-string">&#x27;#&#x27;</span>) &#123;<br>                    <span class="hljs-built_in">dfs</span>(board, nx, ny, root,res);<br>                &#125;<br>            &#125;<br>        &#125;<br>        board[x][y] = ch;<br><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;      <br>    &#125;<br></code></pre></td></tr></table></figure><h3 id="2-项目"><a href="#2-项目" class="headerlink" title="2.项目"></a>2.项目</h3><h4 id="cmu15445"><a href="#cmu15445" class="headerlink" title="cmu15445"></a>cmu15445</h4><p>进度：p3task1 大概看了一下 主要是query plan？ 到时候再看怎么看看代码</p><h3 id="3-八股"><a href="#3-八股" class="headerlink" title="3.八股"></a>3.八股</h3><h4 id="计算机网络"><a href="#计算机网络" class="headerlink" title="计算机网络"></a>计算机网络</h4><p>（1）在浏览器中输入URL并按下回车之后会发生什么</p><p>第一步：输入URL并解析</p><p>对URL进行解析，获得协议、主机、端口、路径等信息，并构造一个HTTP请求（强制缓存 or 协商缓存）</p><p>第二步：DNS域名解析</p><p>将域名解析为对应的IP地址</p><p>第三步：建立TCP三次握手链接</p><p>Q：为什么是三次，不是两次、四次？握手丢失会发生什么，过程中可以携带数据吗</p><p>第四步：浏览器发送HTTP&#x2F;HTTPS请求到web服务器</p><p>Q：HTTP&#x2F;HTTPS的区别，请求状态码1xx-5xx</p><p>第五步：服务器处理HTTP请求并返回HTTP报文</p><p>服务器接收请求并将其传递给请求处理程序并发送HTTP响应，内容：请求的网页以及状态码、压缩类型、如何缓存的页面、设置的cookie；</p><p>第六步：浏览器渲染页面</p><p>第七步：断开连接TCP4次握手</p><p><img src="/../imgs/13th-March/image-20240313182738368.png" alt="image-20240313182738368"></p><h4 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h4><h5 id="进程和线程"><a href="#进程和线程" class="headerlink" title="进程和线程"></a>进程和线程</h5><h6 id="1-进程基础"><a href="#1-进程基础" class="headerlink" title="1.进程基础"></a>1.进程基础</h6><p>(1)进程的概念</p><p>我们编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当我们运行这个可执行文件后，它就会被装载到内存中，接着CPU会执行程序中的每一条指令，那么这个运行中的程序，就被称为 <strong>[进程]（process)</strong></p><p>所以说，进程是具有独立功能的程序在一个数据集合上运行的过程，是系统进行资源分配和调度的一个独立单位。</p><p>（2）进程控制块（PCB）</p><p>系统通过<strong>PCB</strong>来描述进程的基本情况和运行状态，进而控制和管理进程，它是进程存在的唯一标识，包括：进程描述信息、进程控制和管理信息、进程资源分配清单、CPU相关信息</p><p><strong>PCB</strong>通常是通过链表的方式进行组织，把具有相同状态的进程链在一起，组成各种队列。</p><p>（3）并发与并行</p><p>单个处理核在很短时间内分别执行多个进程，成为并发</p><p>多个处理核同时执行多个进程称为并行</p><p>对于并发来说，CPU需要从一个进程切换到另一个进程，在切换前必须要记录当前进程中运行的状态信息，以备下次切换回来的时候可以恢复执行</p><p><img src="/../imgs/13th-March/image-20240313193807222.png" alt="image-20240313193807222"></p><p>（4）进程的状态切换</p><p>我们知道了并发会执行进程的切换，这就需要进程有运行状态和停止状态，实际上某个进程在某个时刻所处的态分为一下三种：</p><ul><li><p><strong>运行态</strong>：该时刻进程占用CPU</p></li><li><p><strong>就绪态</strong>：可运行，由于其他进程处于运行状态而暂停运行</p></li><li><p><strong>阻塞态</strong>：该进程正在等待某一事件的发生（如IO操作）而暂时停止运行</p><p><img src="/../imgs/13th-March/image-20240313194129133.png" alt="image-20240313194129133"></p></li></ul><p>如果有大量处于阻塞状态的进程，进程可能会占用着物理内存空间，所以系统通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存，那么就需要一个新的状态，来描述进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态。这跟阻塞状态是不一样的，阻塞是等待某个时间的返回。</p><p>分为阻塞挂起和阻塞就绪状态</p><p>（5）进程的上下文切换</p><p>一个进程切换到另一个进程运行，称为进程的上下文切换，<strong>进程的上下文切换</strong>不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括内核堆栈、寄存器等内核空间的资源。</p><p>（6）进程的创建</p><p>一个进程可以创建另一个进程，此时创建者为父进程，被创建的进程为子进程，操作系统创建一个新进程的过程如下：</p><ul><li>为新进程分配一个独特的进程控制块（PCB）</li><li>为新进程分配所需要的资源，如内存、CPU时间等</li><li>初始化进程控制块（PCB）的各种字段，包括状态、优先级、寄存器初始值等。</li><li>将其状态设置为就绪状态，使其能够被调度执行。进程进入就绪队列，等待分配处理器时间。</li></ul><p>（7）进程的终止</p><ul><li>根据标识符，查找需要终止的进程的PCB</li><li>如果进程处于执行状态，则立即终止该进程的执行，然后将处理器资源分配给其他进程</li><li>如果还有子进程，则将其子进程交给1号进程接管</li><li>将该进程所拥有的全部资源都归还给操作系统</li><li>将其从PCB所在队列中删除</li></ul><p>（8）进程的阻塞</p><ul><li>找到被阻塞进程的标识符对应的PCB</li><li>如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行</li><li>将该PCB插入到等待队列中，将处理机资源调度给其他就绪进程</li></ul><p>（9）进程的唤醒</p><ul><li>在该事件的阻塞队列中找到相应进程的PCB</li><li>将其从阻塞队列中移出，并置为就绪状态</li><li>将PCB插入到就绪队列中，等待调度程序调度</li></ul><h6 id="2-线程基础"><a href="#2-线程基础" class="headerlink" title="2.线程基础"></a>2.线程基础</h6><p>（1）什么是线程？</p><p>线程是“轻量级线程”，是进程中的一个实体，是程序执行的最小单位，也是被系统独立调度和分配的基本单位。</p><p>线程是进程当中的一条执行流程，同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程各自都有一套独立的寄存器和栈，这样可以确保线程的控制流是相互独立的。</p><p>（2）线程的特点</p><ul><li>线程是一个“轻量级线程”，一个进程中可以有多个线程，线程不拥有系统资源，但是也有PCB，创建线程使用的底层函数和进程一样，都是clone</li><li>各个线程之间可以并发执行</li><li>同一个进程中的各个线程共享该进程所拥有的资源</li><li>进程可以蜕变成线程</li></ul><p>实际上，无论是创建进程的fork，还是创建线程的pthread_create，底层实现都是调用同一个内核函数clone</p><p>linux内核是不区分线程和进程的，只在用户层面上进行区分。所以，线程所有操作函数pthread_*是库函数，而非系统调用</p><p>（3）进程和线程的比较</p><p>​<strong>进程是资源（包括内存、打开的文件等）分配的单位，线程是CPU调度的单位</strong></p><hr><ul><li>资源：进程是系统中拥有资源的基本单位，而线程不拥有系统资源（只有寄存器和栈），但线程可以访问隶属进程的系统资源</li><li>调度：线程切换的代价远低于进程，在同一个进程中，线程的切换不会引起进程切换，而从一个进程中的线程切换到另一个进程的线程中，会引起进程切换</li><li>并发：进程可以并发执行，而一个进程中的多个线程之间也能并发执行，甚至不同进程中的线程也能并发执行，从而是的操作系统拥有更好的并发性，提高了系统资源的利用率和系统的吞吐量</li><li>独立性：每个进程都拥有独⽴的地址空间和资源、除了共享全局变量，不允许其他进程访问。某进程中的线程对其他进程都不可⻅，同⼀进程中的不同线程是为了提⾼并发性以及进⾏相互之间的合作⽽创建的，它们共享进程的地址空间和资源。</li><li>系统开销：线程所需要的开销比进程小</li></ul><p>（4）线程的状态：</p><ul><li>执行状态</li><li>就绪状态</li><li>阻塞状态</li></ul><p>（5）线程的实现</p><ol><li>用户线程：用户空间实现的线程，操作系统不直接参与</li><li>内核线程：操作系统管理、调度，PCB存放在内核中</li><li>轻量级线程：内核支持的用户线程</li></ol><p>（6）线程共享资源</p><ul><li>文件描述符表</li><li>每种信号的处理方式</li><li>当前工作目录</li><li>用户ID和组ID</li></ul><p>（7）线程非共享资源</p><ul><li>线程id</li><li>处理器现场和栈指针</li><li>独立的栈空间</li><li>errno变量（？这是什么）</li><li>信号屏蔽字</li><li>调度优先级</li></ul><p>（8）线程的优缺点</p><p><strong>优点:</strong></p><ul><li>提高程序并发性</li><li>开销小</li><li>数据通信、共享数据方便</li></ul><p><strong>缺点:</strong></p><ul><li>库函数，不稳定</li><li>调试、编写困难、gdb不支持</li><li>对信号支持不好</li></ul><p>（9）线程如何减少开销</p><ol><li>线程创建快、进程创建需要资源管理信息，比如内存管理信息和文件管理信息，而线程创建后是共享其所属进程的资源管理信息</li><li>线程终止时间快，需回收的仅有少量寄存器和私有的栈区</li><li>线程切换快，因为线程切换仅涉及到少量寄存器和栈区，而进程上下文切换有CPU寄存器和程序寄存器、虚拟内存空间、页表切换等</li><li>线程因为创建时共享了其所属进程绝大多数资源，因此天生具有很好的线程间通信交互效率</li></ol><h3 id="4-总结"><a href="#4-总结" class="headerlink" title="4.总结"></a>4.总结</h3><p>投递进度</p><table><thead><tr><th>公司</th><th>进度</th><th>备注</th></tr></thead><tbody><tr><td>字节</td><td>简历评估</td><td></td></tr><tr><td>快手</td><td>系统研发存储 已投</td><td></td></tr><tr><td>携程</td><td>已投</td><td></td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>diary</category>
      
    </categories>
    
    
    <tags>
      
      <tag>diary</tag>
      
      <tag>算法</tag>
      
      <tag>八股</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>12th-March</title>
    <link href="/2024/03/12/12th-March/"/>
    <url>/2024/03/12/12th-March/</url>
    
    <content type="html"><![CDATA[<h2 id="To-do-List"><a href="#To-do-List" class="headerlink" title="To-do List"></a>To-do List</h2><ul><li><p><input checked="" disabled="" type="checkbox"> 算法</p><ul><li><input checked="" disabled="" type="checkbox"> graph</li></ul></li><li><p><input disabled="" type="checkbox"> 项目</p><ul><li><input checked="" disabled="" type="checkbox"> cmu15445</li><li><input disabled="" type="checkbox"> mit6.824</li><li><input disabled="" type="checkbox"> mit6.081</li></ul></li><li><p><input disabled="" type="checkbox"> 八股</p><ul><li><input disabled="" type="checkbox"> 操作系统</li><li><input disabled="" type="checkbox"> 计算机网络</li><li><input disabled="" type="checkbox"> 数据库</li><li><input disabled="" type="checkbox"> redis</li></ul></li><li><p><input disabled="" type="checkbox"> 日常总结</p></li></ul><h3 id="1-算法"><a href="#1-算法" class="headerlink" title="1.算法"></a>1.算法</h3><h4 id="图论"><a href="#图论" class="headerlink" title="图论"></a>图论</h4><p>(1)<a href="https://leetcode.cn/problems/surrounded-regions/description/?envType=study-plan-v2&envId=top-interview-150">leetcode被围绕的区域</a></p><p>题面：<img src="/../imgs/12th-March/image-20240312215015214.png" alt="image-20240312215015214"></p><p>解答：从边缘的点开始dfs，先标记为’A’,再重新遍历修改</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">dfs</span><span class="hljs-params">(vector&lt;vector&lt;<span class="hljs-type">char</span>&gt;&gt; &amp;board, <span class="hljs-type">int</span> i, <span class="hljs-type">int</span> j)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (i &lt; <span class="hljs-number">0</span> || i &gt;= n || j &lt; <span class="hljs-number">0</span> || j &gt;= m || board[i][j] != <span class="hljs-string">&#x27;O&#x27;</span>) &#123;<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        board[i][j] = <span class="hljs-string">&#x27;A&#x27;</span>;<br>        <span class="hljs-keyword">if</span> (i - <span class="hljs-number">1</span> &gt;= <span class="hljs-number">0</span> &amp;&amp; board[i<span class="hljs-number">-1</span>][j] == <span class="hljs-string">&#x27;O&#x27;</span>) <span class="hljs-built_in">dfs</span>(board, i - <span class="hljs-number">1</span>, j);<br>        <span class="hljs-keyword">if</span> (j - <span class="hljs-number">1</span> &gt;= <span class="hljs-number">0</span> &amp;&amp; board[i][j<span class="hljs-number">-1</span>] == <span class="hljs-string">&#x27;O&#x27;</span>) <span class="hljs-built_in">dfs</span>(board, i, j - <span class="hljs-number">1</span>);<br>        <span class="hljs-keyword">if</span> (i + <span class="hljs-number">1</span> &lt; n &amp;&amp; board[i+<span class="hljs-number">1</span>][j] == <span class="hljs-string">&#x27;O&#x27;</span>) <span class="hljs-built_in">dfs</span>(board, i + <span class="hljs-number">1</span>, j);<br>        <span class="hljs-keyword">if</span> (j + <span class="hljs-number">1</span> &lt; m &amp;&amp; board[i][j+<span class="hljs-number">1</span>] == <span class="hljs-string">&#x27;O&#x27;</span>) <span class="hljs-built_in">dfs</span>(board, i, j + <span class="hljs-number">1</span>);<br>    &#125;<br></code></pre></td></tr></table></figure><p>(2)<a href="https://leetcode.cn/problems/course-schedule/description/?envType=study-plan-v2&envId=top-interview-150">leetcode课程表</a></p><p>题面：</p><p><img src="/../imgs/12th-March/image-20240312215238605.png" alt="image-20240312215238605"></p><p>题解：主要是拓扑排序，要是自己写可能就记录每个点的入度？然后从0开始，再一个一个遍历。但是其他题解是dfs，仔细想了想确实精妙。从一个点开始dfs，遍历他所有的节点，然后记录状态，最后记录当前节点，并放入答案中。</p><p>dfs重要代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">dfs</span><span class="hljs-params">(<span class="hljs-type">int</span> u)</span> </span>&#123;<br>        visited[u] = <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> v: edges[u]) &#123;<br>            <span class="hljs-keyword">if</span> (visited[v] == <span class="hljs-number">0</span>) &#123;<br>                <span class="hljs-built_in">dfs</span>(v);<br>                <span class="hljs-keyword">if</span> (!valid) &#123;<br>                    <span class="hljs-keyword">return</span>;<br>                &#125;<br>            &#125;<br>            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (visited[v] == <span class="hljs-number">1</span>) &#123;<br>                valid = <span class="hljs-literal">false</span>;<br>                <span class="hljs-keyword">return</span>;<br>            &#125;<br>        &#125;<br>        visited[u] = <span class="hljs-number">2</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="2-项目"><a href="#2-项目" class="headerlink" title="2.项目"></a>2.项目</h3><h4 id="cmu15445"><a href="#cmu15445" class="headerlink" title="cmu15445"></a>cmu15445</h4><p>Query Planning</p><p>emmm懒得总结了 大概就是说logical优化和physical优化</p><h3 id="3-八股"><a href="#3-八股" class="headerlink" title="3.八股"></a>3.八股</h3><p>今天没看。。。下次再说</p><h3 id="4-总结"><a href="#4-总结" class="headerlink" title="4.总结"></a>4.总结</h3><p>今天搞的有点少。。主要是晚上全在鼓捣这玩意，先好好准备一下周末的蚂蚁笔试，饿了么也可以</p><p>投递进度</p><table><thead><tr><th>公司</th><th>进度</th><th>备注</th></tr></thead><tbody><tr><td>腾讯</td><td>已投递</td><td>等捞？</td></tr><tr><td>字节</td><td>已投递</td><td></td></tr><tr><td>百度</td><td>无消息 已投递</td><td></td></tr><tr><td>蚂蚁</td><td>3.16笔试</td><td></td></tr><tr><td>美团</td><td>笔试完</td><td></td></tr><tr><td>阿里云</td><td>已投递</td><td></td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>diary</category>
      
    </categories>
    
    
    <tags>
      
      <tag>diary</tag>
      
      <tag>算法</tag>
      
      <tag>八股</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
